{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "import config\n",
    "from ctpn_model import CTPN_Model, RPN_CLS_Loss, RPN_REGR_Loss\n",
    "from data.dataset import ICDARDataset\n",
    "\n",
    "# dataset_download:https://rrc.cvc.uab.es/?ch=8&com=downloads\n",
    "random_seed = 2020\n",
    "torch.random.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "epochs = 30\n",
    "lr = 1e-3\n",
    "resume_epoch = 0\n",
    "\n",
    "\n",
    "def save_checkpoint(state, epoch, loss_cls, loss_regr, loss, ext='pth'):\n",
    "    check_path = os.path.join(config.checkpoints_dir,\n",
    "                              f'v3_ctpn_ep{epoch:02d}_'\n",
    "                              f'{loss_cls:.4f}_{loss_regr:.4f}_{loss:.4f}.{ext}')\n",
    "\n",
    "    try:\n",
    "        torch.save(state, check_path)\n",
    "    except BaseException as e:\n",
    "        print(e)\n",
    "        print('fail to save to {}'.format(check_path))\n",
    "    print('saving to {}'.format(check_path))\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exist pretrained  False\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "checkpoints_weight = config.pretrained_weights\n",
    "print('exist pretrained ',os.path.exists(checkpoints_weight))\n",
    "if os.path.exists(checkpoints_weight):\n",
    "    pretrained = False\n",
    "    print(pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CTPN_Model(\n",
       "  (base_layers): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace)\n",
       "  )\n",
       "  (rpn): basic_conv(\n",
       "    (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu): ReLU(inplace)\n",
       "  )\n",
       "  (brnn): GRU(512, 128, batch_first=True, bidirectional=True)\n",
       "  (lstm_fc): basic_conv(\n",
       "    (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (relu): ReLU(inplace)\n",
       "  )\n",
       "  (rpn_class): basic_conv(\n",
       "    (conv): Conv2d(512, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (rpn_regress): basic_conv(\n",
       "    (conv): Conv2d(512, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = ICDARDataset(config.icdar19_mlt_img_dir, config.icdar19_mlt_gt_dir)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=config.num_workers)\n",
    "model = CTPN_Model()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "##################################################\n",
      "Ep:1/29--Batch:0/3832\n",
      "batch: loss_cls:0.7080--loss_regr:0.1501--loss:0.8580\n",
      "Epoch: loss_cls:0.7080--loss_regr:0.1501--loss:0.8580\n",
      "\n",
      "Ep:1/29--Batch:100/3832\n",
      "batch: loss_cls:0.6947--loss_regr:0.1345--loss:0.8292\n",
      "Epoch: loss_cls:0.6958--loss_regr:0.2062--loss:0.9020\n",
      "\n",
      "Ep:1/29--Batch:200/3832\n",
      "batch: loss_cls:0.6944--loss_regr:0.2911--loss:0.9855\n",
      "Epoch: loss_cls:0.6925--loss_regr:0.2059--loss:0.8985\n",
      "\n",
      "Ep:1/29--Batch:300/3832\n",
      "batch: loss_cls:0.6951--loss_regr:0.1475--loss:0.8426\n",
      "Epoch: loss_cls:0.6906--loss_regr:0.2145--loss:0.9051\n",
      "\n",
      "Ep:1/29--Batch:400/3832\n",
      "batch: loss_cls:0.6960--loss_regr:0.1753--loss:0.8713\n",
      "Epoch: loss_cls:0.6890--loss_regr:0.2118--loss:0.9008\n",
      "\n",
      "Ep:1/29--Batch:500/3832\n",
      "batch: loss_cls:0.6966--loss_regr:0.1386--loss:0.8352\n",
      "Epoch: loss_cls:0.6877--loss_regr:0.2082--loss:0.8960\n",
      "\n",
      "Ep:1/29--Batch:600/3832\n",
      "batch: loss_cls:0.6893--loss_regr:0.2495--loss:0.9388\n",
      "Epoch: loss_cls:0.6858--loss_regr:0.2190--loss:0.9048\n",
      "\n",
      "Ep:1/29--Batch:700/3832\n",
      "batch: loss_cls:0.6985--loss_regr:0.1457--loss:0.8442\n",
      "Epoch: loss_cls:0.6853--loss_regr:0.2172--loss:0.9024\n",
      "\n",
      "Ep:1/29--Batch:800/3832\n",
      "batch: loss_cls:0.6982--loss_regr:0.1135--loss:0.8117\n",
      "Epoch: loss_cls:0.6854--loss_regr:0.2156--loss:0.9010\n",
      "\n",
      "Ep:1/29--Batch:900/3832\n",
      "batch: loss_cls:0.6993--loss_regr:0.1965--loss:0.8958\n",
      "Epoch: loss_cls:0.6845--loss_regr:0.2108--loss:0.8953\n",
      "\n",
      "Ep:1/29--Batch:1000/3832\n",
      "batch: loss_cls:0.6194--loss_regr:0.2114--loss:0.8308\n",
      "Epoch: loss_cls:0.6831--loss_regr:0.2095--loss:0.8926\n",
      "\n",
      "Ep:1/29--Batch:1100/3832\n",
      "batch: loss_cls:0.7010--loss_regr:0.2685--loss:0.9694\n",
      "Epoch: loss_cls:0.6829--loss_regr:0.2114--loss:0.8943\n",
      "\n",
      "Ep:1/29--Batch:1200/3832\n",
      "batch: loss_cls:0.7030--loss_regr:0.2206--loss:0.9236\n",
      "Epoch: loss_cls:0.6813--loss_regr:0.2118--loss:0.8930\n",
      "\n",
      "Ep:1/29--Batch:1300/3832\n",
      "batch: loss_cls:0.7041--loss_regr:0.1712--loss:0.8753\n",
      "Epoch: loss_cls:0.6810--loss_regr:0.2111--loss:0.8921\n",
      "\n",
      "Ep:1/29--Batch:1400/3832\n",
      "batch: loss_cls:0.7052--loss_regr:0.2534--loss:0.9586\n",
      "Epoch: loss_cls:0.6803--loss_regr:0.2106--loss:0.8909\n",
      "\n",
      "Ep:1/29--Batch:1500/3832\n",
      "batch: loss_cls:0.7052--loss_regr:0.1690--loss:0.8742\n",
      "Epoch: loss_cls:0.6806--loss_regr:0.2099--loss:0.8904\n",
      "\n",
      "Ep:1/29--Batch:1600/3832\n",
      "batch: loss_cls:0.5856--loss_regr:0.2160--loss:0.8016\n",
      "Epoch: loss_cls:0.6805--loss_regr:0.2114--loss:0.8919\n",
      "\n",
      "Ep:1/29--Batch:1700/3832\n",
      "batch: loss_cls:0.7058--loss_regr:0.2432--loss:0.9490\n",
      "Epoch: loss_cls:0.6803--loss_regr:0.2139--loss:0.8942\n",
      "\n",
      "Ep:1/29--Batch:1800/3832\n",
      "batch: loss_cls:0.6330--loss_regr:0.1373--loss:0.7704\n",
      "Epoch: loss_cls:0.6797--loss_regr:0.2139--loss:0.8936\n",
      "\n",
      "Ep:1/29--Batch:1900/3832\n",
      "batch: loss_cls:0.7072--loss_regr:0.2745--loss:0.9817\n",
      "Epoch: loss_cls:0.6792--loss_regr:0.2183--loss:0.8975\n",
      "\n",
      "Ep:1/29--Batch:2000/3832\n",
      "batch: loss_cls:0.6365--loss_regr:0.2012--loss:0.8378\n",
      "Epoch: loss_cls:0.6787--loss_regr:0.2181--loss:0.8968\n",
      "\n",
      "Ep:1/29--Batch:2100/3832\n",
      "batch: loss_cls:0.7091--loss_regr:0.1748--loss:0.8838\n",
      "Epoch: loss_cls:0.6783--loss_regr:0.2175--loss:0.8958\n",
      "\n",
      "Ep:1/29--Batch:2200/3832\n",
      "batch: loss_cls:0.5714--loss_regr:0.1307--loss:0.7021\n",
      "Epoch: loss_cls:0.6779--loss_regr:0.2165--loss:0.8944\n",
      "\n",
      "Ep:1/29--Batch:2300/3832\n",
      "batch: loss_cls:0.7103--loss_regr:0.1813--loss:0.8916\n",
      "Epoch: loss_cls:0.6776--loss_regr:0.2160--loss:0.8936\n",
      "\n",
      "Ep:1/29--Batch:2400/3832\n",
      "batch: loss_cls:0.6604--loss_regr:0.2175--loss:0.8780\n",
      "Epoch: loss_cls:0.6776--loss_regr:0.2167--loss:0.8943\n",
      "\n",
      "Ep:1/29--Batch:2500/3832\n",
      "batch: loss_cls:0.7106--loss_regr:0.1611--loss:0.8718\n",
      "Epoch: loss_cls:0.6774--loss_regr:0.2154--loss:0.8928\n",
      "\n",
      "Ep:1/29--Batch:2600/3832\n",
      "batch: loss_cls:0.5510--loss_regr:2.3269--loss:2.8779\n",
      "Epoch: loss_cls:0.6770--loss_regr:0.2155--loss:0.8925\n",
      "\n",
      "Ep:1/29--Batch:2700/3832\n",
      "batch: loss_cls:0.7129--loss_regr:0.2747--loss:0.9876\n",
      "Epoch: loss_cls:0.6769--loss_regr:0.2151--loss:0.8920\n",
      "\n",
      "Ep:1/29--Batch:2800/3832\n",
      "batch: loss_cls:0.7107--loss_regr:0.1371--loss:0.8478\n",
      "Epoch: loss_cls:0.6769--loss_regr:0.2157--loss:0.8926\n",
      "\n",
      "Ep:1/29--Batch:2900/3832\n",
      "batch: loss_cls:0.7123--loss_regr:0.1746--loss:0.8869\n",
      "Epoch: loss_cls:0.6768--loss_regr:0.2154--loss:0.8923\n",
      "\n",
      "Ep:1/29--Batch:3000/3832\n",
      "batch: loss_cls:0.7127--loss_regr:0.1531--loss:0.8658\n",
      "Epoch: loss_cls:0.6767--loss_regr:0.2149--loss:0.8916\n",
      "\n",
      "Ep:1/29--Batch:3100/3832\n",
      "batch: loss_cls:0.7156--loss_regr:0.2125--loss:0.9281\n",
      "Epoch: loss_cls:0.6765--loss_regr:0.2160--loss:0.8924\n",
      "\n",
      "Ep:1/29--Batch:3200/3832\n",
      "batch: loss_cls:0.5623--loss_regr:0.0686--loss:0.6309\n",
      "Epoch: loss_cls:0.6764--loss_regr:0.2156--loss:0.8920\n",
      "\n",
      "Ep:1/29--Batch:3300/3832\n",
      "batch: loss_cls:0.7138--loss_regr:0.1841--loss:0.8980\n",
      "Epoch: loss_cls:0.6763--loss_regr:0.2147--loss:0.8911\n",
      "\n",
      "Ep:1/29--Batch:3400/3832\n",
      "batch: loss_cls:0.6650--loss_regr:0.1736--loss:0.8386\n",
      "Epoch: loss_cls:0.6763--loss_regr:0.2150--loss:0.8914\n",
      "\n",
      "Ep:1/29--Batch:3500/3832\n",
      "batch: loss_cls:0.7116--loss_regr:0.1331--loss:0.8447\n",
      "Epoch: loss_cls:0.6764--loss_regr:0.2147--loss:0.8911\n",
      "\n",
      "Ep:1/29--Batch:3600/3832\n",
      "batch: loss_cls:0.6224--loss_regr:0.2081--loss:0.8306\n",
      "Epoch: loss_cls:0.6762--loss_regr:0.2147--loss:0.8909\n",
      "\n",
      "Ep:1/29--Batch:3700/3832\n",
      "batch: loss_cls:0.7103--loss_regr:0.1372--loss:0.8475\n",
      "Epoch: loss_cls:0.6761--loss_regr:0.2143--loss:0.8904\n",
      "\n",
      "Ep:1/29--Batch:3800/3832\n",
      "batch: loss_cls:0.7150--loss_regr:0.2061--loss:0.9211\n",
      "Epoch: loss_cls:0.6759--loss_regr:0.2143--loss:0.8902\n",
      "\n",
      "Epoch:1--0.6760--0.2142--0.8901\n",
      "saving to ../../checkpoints/v3_ctpn_ep01_0.6760_0.2142_0.8901.pth\n",
      "Epoch 2/30\n",
      "##################################################\n",
      "Ep:2/29--Batch:0/3832\n",
      "batch: loss_cls:0.7149--loss_regr:0.1657--loss:0.8806\n",
      "Epoch: loss_cls:0.7149--loss_regr:0.1657--loss:0.8806\n",
      "\n",
      "Ep:2/29--Batch:100/3832\n",
      "batch: loss_cls:0.7161--loss_regr:0.1001--loss:0.8162\n",
      "Epoch: loss_cls:0.6783--loss_regr:0.1889--loss:0.8671\n",
      "\n",
      "Ep:2/29--Batch:200/3832\n",
      "batch: loss_cls:0.7133--loss_regr:0.3031--loss:1.0164\n",
      "Epoch: loss_cls:0.6794--loss_regr:0.1883--loss:0.8677\n",
      "\n",
      "Ep:2/29--Batch:300/3832\n",
      "batch: loss_cls:0.7116--loss_regr:0.1245--loss:0.8361\n",
      "Epoch: loss_cls:0.6792--loss_regr:0.1965--loss:0.8757\n",
      "\n",
      "Ep:2/29--Batch:400/3832\n",
      "batch: loss_cls:0.7060--loss_regr:0.1420--loss:0.8480\n",
      "Epoch: loss_cls:0.6784--loss_regr:0.1930--loss:0.8714\n",
      "\n",
      "Ep:2/29--Batch:500/3832\n",
      "batch: loss_cls:0.7116--loss_regr:0.1233--loss:0.8349\n",
      "Epoch: loss_cls:0.6774--loss_regr:0.1886--loss:0.8661\n",
      "\n",
      "Ep:2/29--Batch:600/3832\n",
      "batch: loss_cls:0.7016--loss_regr:0.2527--loss:0.9543\n",
      "Epoch: loss_cls:0.6755--loss_regr:0.2006--loss:0.8761\n",
      "\n",
      "Ep:2/29--Batch:700/3832\n",
      "batch: loss_cls:0.7129--loss_regr:0.0994--loss:0.8123\n",
      "Epoch: loss_cls:0.6767--loss_regr:0.1986--loss:0.8753\n",
      "\n",
      "Ep:2/29--Batch:800/3832\n",
      "batch: loss_cls:0.7124--loss_regr:0.0953--loss:0.8077\n",
      "Epoch: loss_cls:0.6779--loss_regr:0.1964--loss:0.8742\n",
      "\n",
      "Ep:2/29--Batch:900/3832\n",
      "batch: loss_cls:0.7135--loss_regr:0.1627--loss:0.8761\n",
      "Epoch: loss_cls:0.6779--loss_regr:0.1916--loss:0.8695\n",
      "\n",
      "Ep:2/29--Batch:1000/3832\n",
      "batch: loss_cls:0.5407--loss_regr:0.0878--loss:0.6285\n",
      "Epoch: loss_cls:0.6762--loss_regr:0.1898--loss:0.8660\n",
      "\n",
      "Ep:2/29--Batch:1100/3832\n",
      "batch: loss_cls:0.7042--loss_regr:0.2884--loss:0.9926\n",
      "Epoch: loss_cls:0.6763--loss_regr:0.1918--loss:0.8681\n",
      "\n",
      "Ep:2/29--Batch:1200/3832\n",
      "batch: loss_cls:0.6651--loss_regr:0.0778--loss:0.7428\n",
      "Epoch: loss_cls:0.6748--loss_regr:0.1915--loss:0.8663\n",
      "\n",
      "Ep:2/29--Batch:1300/3832\n",
      "batch: loss_cls:0.7151--loss_regr:0.1301--loss:0.8452\n",
      "Epoch: loss_cls:0.6750--loss_regr:0.1902--loss:0.8652\n",
      "\n",
      "Ep:2/29--Batch:1400/3832\n",
      "batch: loss_cls:0.7170--loss_regr:0.2497--loss:0.9666\n",
      "Epoch: loss_cls:0.6745--loss_regr:0.1894--loss:0.8640\n",
      "\n",
      "Ep:2/29--Batch:1500/3832\n",
      "batch: loss_cls:0.7085--loss_regr:0.1397--loss:0.8482\n",
      "Epoch: loss_cls:0.6753--loss_regr:0.1882--loss:0.8635\n",
      "\n",
      "Ep:2/29--Batch:1600/3832\n",
      "batch: loss_cls:0.5487--loss_regr:0.1326--loss:0.6813\n",
      "Epoch: loss_cls:0.6753--loss_regr:0.1894--loss:0.8647\n",
      "\n",
      "Ep:2/29--Batch:1700/3832\n",
      "batch: loss_cls:0.7198--loss_regr:0.2054--loss:0.9252\n",
      "Epoch: loss_cls:0.6754--loss_regr:0.1915--loss:0.8669\n",
      "\n",
      "Ep:2/29--Batch:1800/3832\n",
      "batch: loss_cls:0.6167--loss_regr:0.0937--loss:0.7103\n",
      "Epoch: loss_cls:0.6751--loss_regr:0.1911--loss:0.8663\n",
      "\n",
      "Ep:2/29--Batch:1900/3832\n",
      "batch: loss_cls:0.7144--loss_regr:0.2437--loss:0.9581\n",
      "Epoch: loss_cls:0.6747--loss_regr:0.1951--loss:0.8698\n",
      "\n",
      "Ep:2/29--Batch:2000/3832\n",
      "batch: loss_cls:0.6014--loss_regr:0.1539--loss:0.7553\n",
      "Epoch: loss_cls:0.6744--loss_regr:0.1946--loss:0.8689\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:2/29--Batch:2100/3832\n",
      "batch: loss_cls:0.6981--loss_regr:0.0927--loss:0.7908\n",
      "Epoch: loss_cls:0.6742--loss_regr:0.1940--loss:0.8682\n",
      "\n",
      "Ep:2/29--Batch:2200/3832\n",
      "batch: loss_cls:0.6510--loss_regr:0.1999--loss:0.8509\n",
      "Epoch: loss_cls:0.6740--loss_regr:0.1930--loss:0.8670\n",
      "\n",
      "Ep:2/29--Batch:2300/3832\n",
      "batch: loss_cls:0.7160--loss_regr:0.1458--loss:0.8618\n",
      "Epoch: loss_cls:0.6739--loss_regr:0.1922--loss:0.8660\n",
      "\n",
      "Ep:2/29--Batch:2400/3832\n",
      "batch: loss_cls:0.5929--loss_regr:0.1628--loss:0.7557\n",
      "Epoch: loss_cls:0.6740--loss_regr:0.1929--loss:0.8669\n",
      "\n",
      "Ep:2/29--Batch:2500/3832\n",
      "batch: loss_cls:0.7111--loss_regr:0.1213--loss:0.8324\n",
      "Epoch: loss_cls:0.6739--loss_regr:0.1916--loss:0.8655\n",
      "\n",
      "Ep:2/29--Batch:2600/3832\n",
      "batch: loss_cls:0.5349--loss_regr:2.2870--loss:2.8219\n",
      "Epoch: loss_cls:0.6736--loss_regr:0.1914--loss:0.8650\n",
      "\n",
      "Ep:2/29--Batch:2700/3832\n",
      "batch: loss_cls:0.7169--loss_regr:0.2294--loss:0.9464\n",
      "Epoch: loss_cls:0.6738--loss_regr:0.1908--loss:0.8646\n",
      "\n",
      "Ep:2/29--Batch:2800/3832\n",
      "batch: loss_cls:0.6835--loss_regr:0.1101--loss:0.7936\n",
      "Epoch: loss_cls:0.6738--loss_regr:0.1913--loss:0.8651\n",
      "\n",
      "Ep:2/29--Batch:2900/3832\n",
      "batch: loss_cls:0.7251--loss_regr:0.1420--loss:0.8672\n",
      "Epoch: loss_cls:0.6736--loss_regr:0.1907--loss:0.8643\n",
      "\n",
      "Ep:2/29--Batch:3000/3832\n",
      "batch: loss_cls:0.7115--loss_regr:0.1422--loss:0.8537\n",
      "Epoch: loss_cls:0.6734--loss_regr:0.1901--loss:0.8635\n",
      "\n",
      "Ep:2/29--Batch:3100/3832\n",
      "batch: loss_cls:0.7230--loss_regr:0.2101--loss:0.9331\n",
      "Epoch: loss_cls:0.6732--loss_regr:0.1913--loss:0.8646\n",
      "\n",
      "Ep:2/29--Batch:3200/3832\n",
      "batch: loss_cls:0.5494--loss_regr:0.0814--loss:0.6307\n",
      "Epoch: loss_cls:0.6731--loss_regr:0.1909--loss:0.8640\n",
      "\n",
      "Ep:2/29--Batch:3300/3832\n",
      "batch: loss_cls:0.7182--loss_regr:0.1507--loss:0.8689\n",
      "Epoch: loss_cls:0.6732--loss_regr:0.1901--loss:0.8632\n",
      "\n",
      "Ep:2/29--Batch:3400/3832\n",
      "batch: loss_cls:0.6489--loss_regr:0.1577--loss:0.8066\n",
      "Epoch: loss_cls:0.6733--loss_regr:0.1904--loss:0.8637\n",
      "\n",
      "Ep:2/29--Batch:3500/3832\n",
      "batch: loss_cls:0.7085--loss_regr:0.0970--loss:0.8054\n",
      "Epoch: loss_cls:0.6732--loss_regr:0.1901--loss:0.8633\n",
      "\n",
      "Ep:2/29--Batch:3600/3832\n",
      "batch: loss_cls:0.6059--loss_regr:0.1324--loss:0.7384\n",
      "Epoch: loss_cls:0.6730--loss_regr:0.1900--loss:0.8631\n",
      "\n",
      "Ep:2/29--Batch:3700/3832\n",
      "batch: loss_cls:0.6719--loss_regr:0.0893--loss:0.7612\n",
      "Epoch: loss_cls:0.6729--loss_regr:0.1898--loss:0.8627\n",
      "\n",
      "Ep:2/29--Batch:3800/3832\n",
      "batch: loss_cls:0.7050--loss_regr:0.1541--loss:0.8591\n",
      "Epoch: loss_cls:0.6728--loss_regr:0.1900--loss:0.8629\n",
      "\n",
      "Epoch:2--0.6728--0.1899--0.8627\n",
      "saving to ../../checkpoints/v3_ctpn_ep02_0.6728_0.1899_0.8627.pth\n",
      "Epoch 3/30\n",
      "##################################################\n",
      "Ep:3/29--Batch:0/3832\n",
      "batch: loss_cls:0.7035--loss_regr:0.1296--loss:0.8331\n",
      "Epoch: loss_cls:0.7035--loss_regr:0.1296--loss:0.8331\n",
      "\n",
      "Ep:3/29--Batch:100/3832\n",
      "batch: loss_cls:0.7170--loss_regr:0.0853--loss:0.8023\n",
      "Epoch: loss_cls:0.6734--loss_regr:0.1688--loss:0.8422\n",
      "\n",
      "Ep:3/29--Batch:200/3832\n",
      "batch: loss_cls:0.7225--loss_regr:0.2919--loss:1.0144\n",
      "Epoch: loss_cls:0.6731--loss_regr:0.1670--loss:0.8401\n",
      "\n",
      "Ep:3/29--Batch:300/3832\n",
      "batch: loss_cls:0.7132--loss_regr:0.0980--loss:0.8112\n",
      "Epoch: loss_cls:0.6732--loss_regr:0.1749--loss:0.8481\n",
      "\n",
      "Ep:3/29--Batch:400/3832\n",
      "batch: loss_cls:0.6392--loss_regr:0.0795--loss:0.7186\n",
      "Epoch: loss_cls:0.6717--loss_regr:0.1712--loss:0.8429\n",
      "\n",
      "Ep:3/29--Batch:500/3832\n",
      "batch: loss_cls:0.6944--loss_regr:0.0896--loss:0.7840\n",
      "Epoch: loss_cls:0.6697--loss_regr:0.1679--loss:0.8376\n",
      "\n",
      "Ep:3/29--Batch:600/3832\n",
      "batch: loss_cls:0.7045--loss_regr:0.2720--loss:0.9764\n",
      "Epoch: loss_cls:0.6678--loss_regr:0.1796--loss:0.8474\n",
      "\n",
      "Ep:3/29--Batch:700/3832\n",
      "batch: loss_cls:0.7242--loss_regr:0.0891--loss:0.8133\n",
      "Epoch: loss_cls:0.6695--loss_regr:0.1782--loss:0.8477\n",
      "\n",
      "Ep:3/29--Batch:800/3832\n",
      "batch: loss_cls:0.7126--loss_regr:0.0671--loss:0.7797\n",
      "Epoch: loss_cls:0.6701--loss_regr:0.1768--loss:0.8469\n",
      "\n",
      "Ep:3/29--Batch:900/3832\n",
      "batch: loss_cls:0.7151--loss_regr:0.1854--loss:0.9006\n",
      "Epoch: loss_cls:0.6700--loss_regr:0.1727--loss:0.8427\n",
      "\n",
      "Ep:3/29--Batch:1000/3832\n",
      "batch: loss_cls:0.5622--loss_regr:0.2173--loss:0.7795\n",
      "Epoch: loss_cls:0.6675--loss_regr:0.1709--loss:0.8384\n",
      "\n",
      "Ep:3/29--Batch:1100/3832\n",
      "batch: loss_cls:0.7219--loss_regr:0.1946--loss:0.9165\n",
      "Epoch: loss_cls:0.6683--loss_regr:0.1726--loss:0.8409\n",
      "\n",
      "Ep:3/29--Batch:1200/3832\n",
      "batch: loss_cls:0.6659--loss_regr:0.0614--loss:0.7273\n",
      "Epoch: loss_cls:0.6664--loss_regr:0.1722--loss:0.8386\n",
      "\n",
      "Ep:3/29--Batch:1300/3832\n",
      "batch: loss_cls:0.7115--loss_regr:0.1447--loss:0.8563\n",
      "Epoch: loss_cls:0.6660--loss_regr:0.1714--loss:0.8373\n",
      "\n",
      "Ep:3/29--Batch:1400/3832\n",
      "batch: loss_cls:0.7267--loss_regr:0.1943--loss:0.9210\n",
      "Epoch: loss_cls:0.6654--loss_regr:0.1709--loss:0.8363\n",
      "\n",
      "Ep:3/29--Batch:1500/3832\n",
      "batch: loss_cls:0.7081--loss_regr:0.1243--loss:0.8324\n",
      "Epoch: loss_cls:0.6656--loss_regr:0.1699--loss:0.8355\n",
      "\n",
      "Ep:3/29--Batch:1600/3832\n",
      "batch: loss_cls:0.5109--loss_regr:0.1161--loss:0.6271\n",
      "Epoch: loss_cls:0.6658--loss_regr:0.1711--loss:0.8368\n",
      "\n",
      "Ep:3/29--Batch:1700/3832\n",
      "batch: loss_cls:0.7590--loss_regr:0.1691--loss:0.9282\n",
      "Epoch: loss_cls:0.6652--loss_regr:0.1732--loss:0.8384\n",
      "\n",
      "Ep:3/29--Batch:1800/3832\n",
      "batch: loss_cls:0.5582--loss_regr:0.0985--loss:0.6567\n",
      "Epoch: loss_cls:0.6642--loss_regr:0.1730--loss:0.8372\n",
      "\n",
      "Ep:3/29--Batch:1900/3832\n",
      "batch: loss_cls:0.7108--loss_regr:0.2246--loss:0.9354\n",
      "Epoch: loss_cls:0.6639--loss_regr:0.1773--loss:0.8412\n",
      "\n",
      "Ep:3/29--Batch:2000/3832\n",
      "batch: loss_cls:0.5740--loss_regr:0.1459--loss:0.7199\n",
      "Epoch: loss_cls:0.6633--loss_regr:0.1768--loss:0.8401\n",
      "\n",
      "Ep:3/29--Batch:2100/3832\n",
      "batch: loss_cls:0.6597--loss_regr:0.0652--loss:0.7248\n",
      "Epoch: loss_cls:0.6630--loss_regr:0.1764--loss:0.8394\n",
      "\n",
      "Ep:3/29--Batch:2200/3832\n",
      "batch: loss_cls:0.5752--loss_regr:0.1889--loss:0.7641\n",
      "Epoch: loss_cls:0.6621--loss_regr:0.1756--loss:0.8377\n",
      "\n",
      "Ep:3/29--Batch:2300/3832\n",
      "batch: loss_cls:0.7134--loss_regr:0.1344--loss:0.8477\n",
      "Epoch: loss_cls:0.6621--loss_regr:0.1752--loss:0.8373\n",
      "\n",
      "Ep:3/29--Batch:2400/3832\n",
      "batch: loss_cls:0.6357--loss_regr:0.1732--loss:0.8089\n",
      "Epoch: loss_cls:0.6618--loss_regr:0.1760--loss:0.8378\n",
      "\n",
      "Ep:3/29--Batch:2500/3832\n",
      "batch: loss_cls:0.6701--loss_regr:0.1233--loss:0.7934\n",
      "Epoch: loss_cls:0.6616--loss_regr:0.1750--loss:0.8366\n",
      "\n",
      "Ep:3/29--Batch:2600/3832\n",
      "batch: loss_cls:0.5042--loss_regr:2.2788--loss:2.7830\n",
      "Epoch: loss_cls:0.6611--loss_regr:0.1748--loss:0.8359\n",
      "\n",
      "Ep:3/29--Batch:2700/3832\n",
      "batch: loss_cls:0.7148--loss_regr:0.1484--loss:0.8632\n",
      "Epoch: loss_cls:0.6610--loss_regr:0.1744--loss:0.8354\n",
      "\n",
      "Ep:3/29--Batch:2800/3832\n",
      "batch: loss_cls:0.5411--loss_regr:0.0972--loss:0.6383\n",
      "Epoch: loss_cls:0.6611--loss_regr:0.1752--loss:0.8363\n",
      "\n",
      "Ep:3/29--Batch:2900/3832\n",
      "batch: loss_cls:0.7212--loss_regr:0.1218--loss:0.8430\n",
      "Epoch: loss_cls:0.6610--loss_regr:0.1748--loss:0.8358\n",
      "\n",
      "Ep:3/29--Batch:3000/3832\n",
      "batch: loss_cls:0.6839--loss_regr:0.1400--loss:0.8239\n",
      "Epoch: loss_cls:0.6603--loss_regr:0.1744--loss:0.8346\n",
      "\n",
      "Ep:3/29--Batch:3100/3832\n",
      "batch: loss_cls:0.6919--loss_regr:0.1558--loss:0.8477\n",
      "Epoch: loss_cls:0.6603--loss_regr:0.1756--loss:0.8359\n",
      "\n",
      "Ep:3/29--Batch:3200/3832\n",
      "batch: loss_cls:0.5221--loss_regr:0.0864--loss:0.6085\n",
      "Epoch: loss_cls:0.6601--loss_regr:0.1754--loss:0.8356\n",
      "\n",
      "Ep:3/29--Batch:3300/3832\n",
      "batch: loss_cls:0.7235--loss_regr:0.1637--loss:0.8872\n",
      "Epoch: loss_cls:0.6602--loss_regr:0.1747--loss:0.8349\n",
      "\n",
      "Ep:3/29--Batch:3400/3832\n",
      "batch: loss_cls:0.6099--loss_regr:0.1419--loss:0.7518\n",
      "Epoch: loss_cls:0.6604--loss_regr:0.1752--loss:0.8356\n",
      "\n",
      "Ep:3/29--Batch:3500/3832\n",
      "batch: loss_cls:0.6471--loss_regr:0.0702--loss:0.7172\n",
      "Epoch: loss_cls:0.6598--loss_regr:0.1748--loss:0.8346\n",
      "\n",
      "Ep:3/29--Batch:3600/3832\n",
      "batch: loss_cls:0.5882--loss_regr:0.1352--loss:0.7235\n",
      "Epoch: loss_cls:0.6601--loss_regr:0.1749--loss:0.8350\n",
      "\n",
      "Ep:3/29--Batch:3700/3832\n",
      "batch: loss_cls:0.5593--loss_regr:0.0781--loss:0.6373\n",
      "Epoch: loss_cls:0.6595--loss_regr:0.1748--loss:0.8343\n",
      "\n",
      "Ep:3/29--Batch:3800/3832\n",
      "batch: loss_cls:0.7028--loss_regr:0.1414--loss:0.8442\n",
      "Epoch: loss_cls:0.6598--loss_regr:0.1752--loss:0.8350\n",
      "\n",
      "Epoch:3--0.6598--0.1751--0.8349\n",
      "saving to ../../checkpoints/v3_ctpn_ep03_0.6598_0.1751_0.8349.pth\n",
      "Epoch 4/30\n",
      "##################################################\n",
      "Ep:4/29--Batch:0/3832\n",
      "batch: loss_cls:0.6767--loss_regr:0.1317--loss:0.8083\n",
      "Epoch: loss_cls:0.6767--loss_regr:0.1317--loss:0.8083\n",
      "\n",
      "Ep:4/29--Batch:100/3832\n",
      "batch: loss_cls:0.6837--loss_regr:0.0817--loss:0.7654\n",
      "Epoch: loss_cls:0.6611--loss_regr:0.1605--loss:0.8216\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:4/29--Batch:200/3832\n",
      "batch: loss_cls:0.7421--loss_regr:0.3954--loss:1.1375\n",
      "Epoch: loss_cls:0.6565--loss_regr:0.1584--loss:0.8149\n",
      "\n",
      "Ep:4/29--Batch:300/3832\n",
      "batch: loss_cls:0.7325--loss_regr:0.1093--loss:0.8418\n",
      "Epoch: loss_cls:0.6581--loss_regr:0.1685--loss:0.8266\n",
      "\n",
      "Ep:4/29--Batch:400/3832\n",
      "batch: loss_cls:0.4871--loss_regr:0.0833--loss:0.5703\n",
      "Epoch: loss_cls:0.6552--loss_regr:0.1642--loss:0.8194\n",
      "\n",
      "Ep:4/29--Batch:500/3832\n",
      "batch: loss_cls:0.5570--loss_regr:0.0552--loss:0.6122\n",
      "Epoch: loss_cls:0.6485--loss_regr:0.1611--loss:0.8096\n",
      "\n",
      "Ep:4/29--Batch:600/3832\n",
      "batch: loss_cls:0.7223--loss_regr:0.2678--loss:0.9901\n",
      "Epoch: loss_cls:0.6474--loss_regr:0.1721--loss:0.8195\n",
      "\n",
      "Ep:4/29--Batch:700/3832\n",
      "batch: loss_cls:0.7337--loss_regr:0.0919--loss:0.8255\n",
      "Epoch: loss_cls:0.6487--loss_regr:0.1706--loss:0.8193\n",
      "\n",
      "Ep:4/29--Batch:800/3832\n",
      "batch: loss_cls:0.7336--loss_regr:0.0821--loss:0.8157\n",
      "Epoch: loss_cls:0.6486--loss_regr:0.1696--loss:0.8182\n",
      "\n",
      "Ep:4/29--Batch:900/3832\n",
      "batch: loss_cls:0.6960--loss_regr:0.1536--loss:0.8496\n",
      "Epoch: loss_cls:0.6487--loss_regr:0.1653--loss:0.8140\n",
      "\n",
      "Ep:4/29--Batch:1000/3832\n",
      "batch: loss_cls:0.5379--loss_regr:0.1979--loss:0.7357\n",
      "Epoch: loss_cls:0.6467--loss_regr:0.1639--loss:0.8106\n",
      "\n",
      "Ep:4/29--Batch:1100/3832\n",
      "batch: loss_cls:0.7310--loss_regr:0.2001--loss:0.9311\n",
      "Epoch: loss_cls:0.6486--loss_regr:0.1659--loss:0.8145\n",
      "\n",
      "Ep:4/29--Batch:1200/3832\n",
      "batch: loss_cls:0.7390--loss_regr:0.2658--loss:1.0048\n",
      "Epoch: loss_cls:0.6475--loss_regr:0.1659--loss:0.8134\n",
      "\n",
      "Ep:4/29--Batch:1300/3832\n",
      "batch: loss_cls:0.6866--loss_regr:0.1508--loss:0.8374\n",
      "Epoch: loss_cls:0.6464--loss_regr:0.1652--loss:0.8116\n",
      "\n",
      "Ep:4/29--Batch:1400/3832\n",
      "batch: loss_cls:0.7479--loss_regr:0.1900--loss:0.9380\n",
      "Epoch: loss_cls:0.6457--loss_regr:0.1645--loss:0.8103\n",
      "\n",
      "Ep:4/29--Batch:1500/3832\n",
      "batch: loss_cls:0.6534--loss_regr:0.1455--loss:0.7989\n",
      "Epoch: loss_cls:0.6459--loss_regr:0.1631--loss:0.8090\n",
      "\n",
      "Ep:4/29--Batch:1600/3832\n",
      "batch: loss_cls:0.4688--loss_regr:0.0854--loss:0.5542\n",
      "Epoch: loss_cls:0.6463--loss_regr:0.1641--loss:0.8104\n",
      "\n",
      "Ep:4/29--Batch:1700/3832\n",
      "batch: loss_cls:0.7382--loss_regr:0.1612--loss:0.8994\n",
      "Epoch: loss_cls:0.6454--loss_regr:0.1660--loss:0.8114\n",
      "\n",
      "Ep:4/29--Batch:1800/3832\n",
      "batch: loss_cls:0.5066--loss_regr:0.0973--loss:0.6039\n",
      "Epoch: loss_cls:0.6440--loss_regr:0.1656--loss:0.8096\n",
      "\n",
      "Ep:4/29--Batch:1900/3832\n",
      "batch: loss_cls:0.7409--loss_regr:0.2133--loss:0.9542\n",
      "Epoch: loss_cls:0.6437--loss_regr:0.1700--loss:0.8137\n",
      "\n",
      "Ep:4/29--Batch:2000/3832\n",
      "batch: loss_cls:0.5370--loss_regr:0.1422--loss:0.6793\n",
      "Epoch: loss_cls:0.6434--loss_regr:0.1696--loss:0.8130\n",
      "\n",
      "Ep:4/29--Batch:2100/3832\n",
      "batch: loss_cls:0.6357--loss_regr:0.0415--loss:0.6772\n",
      "Epoch: loss_cls:0.6432--loss_regr:0.1692--loss:0.8124\n",
      "\n",
      "Ep:4/29--Batch:2200/3832\n",
      "batch: loss_cls:0.5325--loss_regr:0.1634--loss:0.6959\n",
      "Epoch: loss_cls:0.6414--loss_regr:0.1687--loss:0.8101\n",
      "\n",
      "Ep:4/29--Batch:2300/3832\n",
      "batch: loss_cls:0.7033--loss_regr:0.1765--loss:0.8798\n",
      "Epoch: loss_cls:0.6411--loss_regr:0.1681--loss:0.8092\n",
      "\n",
      "Ep:4/29--Batch:2400/3832\n",
      "batch: loss_cls:0.5816--loss_regr:0.1281--loss:0.7096\n",
      "Epoch: loss_cls:0.6412--loss_regr:0.1690--loss:0.8102\n",
      "\n",
      "Ep:4/29--Batch:2500/3832\n",
      "batch: loss_cls:0.6136--loss_regr:0.1292--loss:0.7428\n",
      "Epoch: loss_cls:0.6405--loss_regr:0.1680--loss:0.8085\n",
      "\n",
      "Ep:4/29--Batch:2600/3832\n",
      "batch: loss_cls:0.4641--loss_regr:2.3059--loss:2.7699\n",
      "Epoch: loss_cls:0.6402--loss_regr:0.1679--loss:0.8081\n",
      "\n",
      "Ep:4/29--Batch:2700/3832\n",
      "batch: loss_cls:0.6821--loss_regr:0.2406--loss:0.9227\n",
      "Epoch: loss_cls:0.6401--loss_regr:0.1674--loss:0.8075\n",
      "\n",
      "Ep:4/29--Batch:2800/3832\n",
      "batch: loss_cls:0.4953--loss_regr:0.1097--loss:0.6050\n",
      "Epoch: loss_cls:0.6399--loss_regr:0.1681--loss:0.8080\n",
      "\n",
      "Ep:4/29--Batch:2900/3832\n",
      "batch: loss_cls:0.6794--loss_regr:0.1190--loss:0.7983\n",
      "Epoch: loss_cls:0.6402--loss_regr:0.1676--loss:0.8078\n",
      "\n",
      "Ep:4/29--Batch:3000/3832\n",
      "batch: loss_cls:0.6098--loss_regr:0.1402--loss:0.7500\n",
      "Epoch: loss_cls:0.6392--loss_regr:0.1672--loss:0.8064\n",
      "\n",
      "Ep:4/29--Batch:3100/3832\n",
      "batch: loss_cls:0.6560--loss_regr:0.1754--loss:0.8314\n",
      "Epoch: loss_cls:0.6395--loss_regr:0.1685--loss:0.8080\n",
      "\n",
      "Ep:4/29--Batch:3200/3832\n",
      "batch: loss_cls:0.4866--loss_regr:0.0863--loss:0.5729\n",
      "Epoch: loss_cls:0.6394--loss_regr:0.1684--loss:0.8077\n",
      "\n",
      "Ep:4/29--Batch:3300/3832\n",
      "batch: loss_cls:0.7076--loss_regr:0.1571--loss:0.8647\n",
      "Epoch: loss_cls:0.6396--loss_regr:0.1678--loss:0.8074\n",
      "\n",
      "Ep:4/29--Batch:3400/3832\n",
      "batch: loss_cls:0.5823--loss_regr:0.1211--loss:0.7034\n",
      "Epoch: loss_cls:0.6399--loss_regr:0.1683--loss:0.8082\n",
      "\n",
      "Ep:4/29--Batch:3500/3832\n",
      "batch: loss_cls:0.4636--loss_regr:0.0715--loss:0.5351\n",
      "Epoch: loss_cls:0.6390--loss_regr:0.1680--loss:0.8070\n",
      "\n",
      "Ep:4/29--Batch:3600/3832\n",
      "batch: loss_cls:0.5283--loss_regr:0.1327--loss:0.6610\n",
      "Epoch: loss_cls:0.6392--loss_regr:0.1680--loss:0.8072\n",
      "\n",
      "Ep:4/29--Batch:3700/3832\n",
      "batch: loss_cls:0.4574--loss_regr:0.0702--loss:0.5276\n",
      "Epoch: loss_cls:0.6385--loss_regr:0.1680--loss:0.8065\n",
      "\n",
      "Ep:4/29--Batch:3800/3832\n",
      "batch: loss_cls:0.6662--loss_regr:0.1532--loss:0.8193\n",
      "Epoch: loss_cls:0.6388--loss_regr:0.1683--loss:0.8072\n",
      "\n",
      "Epoch:4--0.6390--0.1683--0.8073\n",
      "saving to ../../checkpoints/v3_ctpn_ep04_0.6390_0.1683_0.8073.pth\n",
      "Epoch 5/30\n",
      "##################################################\n",
      "Ep:5/29--Batch:0/3832\n",
      "batch: loss_cls:0.6426--loss_regr:0.1242--loss:0.7668\n",
      "Epoch: loss_cls:0.6426--loss_regr:0.1242--loss:0.7668\n",
      "\n",
      "Ep:5/29--Batch:100/3832\n",
      "batch: loss_cls:0.6364--loss_regr:0.0987--loss:0.7352\n",
      "Epoch: loss_cls:0.6280--loss_regr:0.1547--loss:0.7828\n",
      "\n",
      "Ep:5/29--Batch:200/3832\n",
      "batch: loss_cls:0.7584--loss_regr:0.2995--loss:1.0578\n",
      "Epoch: loss_cls:0.6276--loss_regr:0.1529--loss:0.7805\n",
      "\n",
      "Ep:5/29--Batch:300/3832\n",
      "batch: loss_cls:0.7303--loss_regr:0.0998--loss:0.8302\n",
      "Epoch: loss_cls:0.6347--loss_regr:0.1633--loss:0.7980\n",
      "\n",
      "Ep:5/29--Batch:400/3832\n",
      "batch: loss_cls:0.3843--loss_regr:0.0814--loss:0.4656\n",
      "Epoch: loss_cls:0.6326--loss_regr:0.1593--loss:0.7919\n",
      "\n",
      "Ep:5/29--Batch:500/3832\n",
      "batch: loss_cls:0.4844--loss_regr:0.0872--loss:0.5715\n",
      "Epoch: loss_cls:0.6227--loss_regr:0.1570--loss:0.7797\n",
      "\n",
      "Ep:5/29--Batch:600/3832\n",
      "batch: loss_cls:0.7358--loss_regr:0.2517--loss:0.9875\n",
      "Epoch: loss_cls:0.6216--loss_regr:0.1665--loss:0.7881\n",
      "\n",
      "Ep:5/29--Batch:700/3832\n",
      "batch: loss_cls:0.7411--loss_regr:0.0830--loss:0.8241\n",
      "Epoch: loss_cls:0.6274--loss_regr:0.1655--loss:0.7929\n",
      "\n",
      "Ep:5/29--Batch:800/3832\n",
      "batch: loss_cls:0.6855--loss_regr:0.0682--loss:0.7537\n",
      "Epoch: loss_cls:0.6281--loss_regr:0.1642--loss:0.7924\n",
      "\n",
      "Ep:5/29--Batch:900/3832\n",
      "batch: loss_cls:0.6575--loss_regr:0.1503--loss:0.8078\n",
      "Epoch: loss_cls:0.6282--loss_regr:0.1594--loss:0.7876\n",
      "\n",
      "Ep:5/29--Batch:1000/3832\n",
      "batch: loss_cls:0.4408--loss_regr:0.1396--loss:0.5805\n",
      "Epoch: loss_cls:0.6253--loss_regr:0.1578--loss:0.7831\n",
      "\n",
      "Ep:5/29--Batch:1100/3832\n",
      "batch: loss_cls:0.7053--loss_regr:0.2520--loss:0.9572\n",
      "Epoch: loss_cls:0.6287--loss_regr:0.1600--loss:0.7887\n",
      "\n",
      "Ep:5/29--Batch:1200/3832\n",
      "batch: loss_cls:0.7641--loss_regr:0.2548--loss:1.0189\n",
      "Epoch: loss_cls:0.6265--loss_regr:0.1596--loss:0.7861\n",
      "\n",
      "Ep:5/29--Batch:1300/3832\n",
      "batch: loss_cls:0.6341--loss_regr:0.1688--loss:0.8029\n",
      "Epoch: loss_cls:0.6256--loss_regr:0.1589--loss:0.7845\n",
      "\n",
      "Ep:5/29--Batch:1400/3832\n",
      "batch: loss_cls:0.7399--loss_regr:0.1810--loss:0.9209\n",
      "Epoch: loss_cls:0.6243--loss_regr:0.1583--loss:0.7826\n",
      "\n",
      "Ep:5/29--Batch:1500/3832\n",
      "batch: loss_cls:0.6277--loss_regr:0.1484--loss:0.7761\n",
      "Epoch: loss_cls:0.6242--loss_regr:0.1574--loss:0.7816\n",
      "\n",
      "Ep:5/29--Batch:1600/3832\n",
      "batch: loss_cls:0.4283--loss_regr:0.1273--loss:0.5556\n",
      "Epoch: loss_cls:0.6251--loss_regr:0.1586--loss:0.7837\n",
      "\n",
      "Ep:5/29--Batch:1700/3832\n",
      "batch: loss_cls:0.8050--loss_regr:0.2010--loss:1.0060\n",
      "Epoch: loss_cls:0.6242--loss_regr:0.1603--loss:0.7845\n",
      "\n",
      "Ep:5/29--Batch:1800/3832\n",
      "batch: loss_cls:0.4430--loss_regr:0.0972--loss:0.5401\n",
      "Epoch: loss_cls:0.6235--loss_regr:0.1598--loss:0.7834\n",
      "\n",
      "Ep:5/29--Batch:1900/3832\n",
      "batch: loss_cls:0.5045--loss_regr:0.1917--loss:0.6963\n",
      "Epoch: loss_cls:0.6231--loss_regr:0.1639--loss:0.7870\n",
      "\n",
      "Ep:5/29--Batch:2000/3832\n",
      "batch: loss_cls:0.5629--loss_regr:0.1470--loss:0.7099\n",
      "Epoch: loss_cls:0.6226--loss_regr:0.1636--loss:0.7862\n",
      "\n",
      "Ep:5/29--Batch:2100/3832\n",
      "batch: loss_cls:0.5762--loss_regr:0.0499--loss:0.6261\n",
      "Epoch: loss_cls:0.6227--loss_regr:0.1633--loss:0.7860\n",
      "\n",
      "Ep:5/29--Batch:2200/3832\n",
      "batch: loss_cls:0.5810--loss_regr:0.1604--loss:0.7414\n",
      "Epoch: loss_cls:0.6219--loss_regr:0.1626--loss:0.7845\n",
      "\n",
      "Ep:5/29--Batch:2300/3832\n",
      "batch: loss_cls:0.6896--loss_regr:0.1440--loss:0.8335\n",
      "Epoch: loss_cls:0.6211--loss_regr:0.1622--loss:0.7833\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:5/29--Batch:2400/3832\n",
      "batch: loss_cls:0.5815--loss_regr:0.1172--loss:0.6986\n",
      "Epoch: loss_cls:0.6212--loss_regr:0.1631--loss:0.7843\n",
      "\n",
      "Ep:5/29--Batch:2500/3832\n",
      "batch: loss_cls:0.6430--loss_regr:0.1169--loss:0.7599\n",
      "Epoch: loss_cls:0.6210--loss_regr:0.1620--loss:0.7831\n",
      "\n",
      "Ep:5/29--Batch:2600/3832\n",
      "batch: loss_cls:0.4403--loss_regr:2.2695--loss:2.7097\n",
      "Epoch: loss_cls:0.6210--loss_regr:0.1618--loss:0.7828\n",
      "\n",
      "Ep:5/29--Batch:2700/3832\n",
      "batch: loss_cls:0.6901--loss_regr:0.2611--loss:0.9512\n",
      "Epoch: loss_cls:0.6209--loss_regr:0.1613--loss:0.7822\n",
      "\n",
      "Ep:5/29--Batch:2800/3832\n",
      "batch: loss_cls:0.4279--loss_regr:0.0826--loss:0.5104\n",
      "Epoch: loss_cls:0.6211--loss_regr:0.1620--loss:0.7831\n",
      "\n",
      "Ep:5/29--Batch:2900/3832\n",
      "batch: loss_cls:0.6501--loss_regr:0.1025--loss:0.7526\n",
      "Epoch: loss_cls:0.6211--loss_regr:0.1615--loss:0.7826\n",
      "\n",
      "Ep:5/29--Batch:3000/3832\n",
      "batch: loss_cls:0.5483--loss_regr:0.1474--loss:0.6957\n",
      "Epoch: loss_cls:0.6200--loss_regr:0.1610--loss:0.7810\n",
      "\n",
      "Ep:5/29--Batch:3100/3832\n",
      "batch: loss_cls:0.6009--loss_regr:0.1827--loss:0.7836\n",
      "Epoch: loss_cls:0.6202--loss_regr:0.1623--loss:0.7825\n",
      "\n",
      "Ep:5/29--Batch:3200/3832\n",
      "batch: loss_cls:0.4669--loss_regr:0.0826--loss:0.5495\n",
      "Epoch: loss_cls:0.6200--loss_regr:0.1621--loss:0.7821\n",
      "\n",
      "Ep:5/29--Batch:3300/3832\n",
      "batch: loss_cls:0.7250--loss_regr:0.1724--loss:0.8974\n",
      "Epoch: loss_cls:0.6207--loss_regr:0.1615--loss:0.7822\n",
      "\n",
      "Ep:5/29--Batch:3400/3832\n",
      "batch: loss_cls:0.4815--loss_regr:0.1011--loss:0.5826\n",
      "Epoch: loss_cls:0.6206--loss_regr:0.1621--loss:0.7827\n",
      "\n",
      "Ep:5/29--Batch:3500/3832\n",
      "batch: loss_cls:0.3541--loss_regr:0.0734--loss:0.4276\n",
      "Epoch: loss_cls:0.6195--loss_regr:0.1617--loss:0.7812\n",
      "\n",
      "Ep:5/29--Batch:3600/3832\n",
      "batch: loss_cls:0.5320--loss_regr:0.1127--loss:0.6448\n",
      "Epoch: loss_cls:0.6203--loss_regr:0.1615--loss:0.7818\n",
      "\n",
      "Ep:5/29--Batch:3700/3832\n",
      "batch: loss_cls:0.4634--loss_regr:0.0781--loss:0.5415\n",
      "Epoch: loss_cls:0.6196--loss_regr:0.1616--loss:0.7812\n",
      "\n",
      "Ep:5/29--Batch:3800/3832\n",
      "batch: loss_cls:0.6443--loss_regr:0.1311--loss:0.7754\n",
      "Epoch: loss_cls:0.6201--loss_regr:0.1620--loss:0.7821\n",
      "\n",
      "Epoch:5--0.6203--0.1619--0.7822\n",
      "saving to ../../checkpoints/v3_ctpn_ep05_0.6203_0.1619_0.7822.pth\n",
      "Epoch 6/30\n",
      "##################################################\n",
      "Ep:6/29--Batch:0/3832\n",
      "batch: loss_cls:0.5700--loss_regr:0.0912--loss:0.6612\n",
      "Epoch: loss_cls:0.5700--loss_regr:0.0912--loss:0.6612\n",
      "\n",
      "Ep:6/29--Batch:100/3832\n",
      "batch: loss_cls:0.6607--loss_regr:0.1035--loss:0.7642\n",
      "Epoch: loss_cls:0.6042--loss_regr:0.1470--loss:0.7511\n",
      "\n",
      "Ep:6/29--Batch:200/3832\n",
      "batch: loss_cls:0.7802--loss_regr:0.3039--loss:1.0840\n",
      "Epoch: loss_cls:0.6014--loss_regr:0.1449--loss:0.7463\n",
      "\n",
      "Ep:6/29--Batch:300/3832\n",
      "batch: loss_cls:0.7647--loss_regr:0.1271--loss:0.8919\n",
      "Epoch: loss_cls:0.6084--loss_regr:0.1559--loss:0.7643\n",
      "\n",
      "Ep:6/29--Batch:400/3832\n",
      "batch: loss_cls:0.3373--loss_regr:0.0699--loss:0.4072\n",
      "Epoch: loss_cls:0.6135--loss_regr:0.1524--loss:0.7658\n",
      "\n",
      "Ep:6/29--Batch:500/3832\n",
      "batch: loss_cls:0.4719--loss_regr:0.1010--loss:0.5729\n",
      "Epoch: loss_cls:0.6037--loss_regr:0.1496--loss:0.7533\n",
      "\n",
      "Ep:6/29--Batch:600/3832\n",
      "batch: loss_cls:0.7478--loss_regr:0.2532--loss:1.0010\n",
      "Epoch: loss_cls:0.6014--loss_regr:0.1605--loss:0.7619\n",
      "\n",
      "Ep:6/29--Batch:700/3832\n",
      "batch: loss_cls:0.7320--loss_regr:0.0879--loss:0.8199\n",
      "Epoch: loss_cls:0.6069--loss_regr:0.1589--loss:0.7658\n",
      "\n",
      "Ep:6/29--Batch:800/3832\n",
      "batch: loss_cls:0.6439--loss_regr:0.0741--loss:0.7180\n",
      "Epoch: loss_cls:0.6081--loss_regr:0.1578--loss:0.7659\n",
      "\n",
      "Ep:6/29--Batch:900/3832\n",
      "batch: loss_cls:0.6722--loss_regr:0.1309--loss:0.8031\n",
      "Epoch: loss_cls:0.6083--loss_regr:0.1533--loss:0.7616\n",
      "\n",
      "Ep:6/29--Batch:1000/3832\n",
      "batch: loss_cls:0.4158--loss_regr:0.1822--loss:0.5979\n",
      "Epoch: loss_cls:0.6067--loss_regr:0.1522--loss:0.7589\n",
      "\n",
      "Ep:6/29--Batch:1100/3832\n",
      "batch: loss_cls:0.7550--loss_regr:0.1864--loss:0.9413\n",
      "Epoch: loss_cls:0.6111--loss_regr:0.1542--loss:0.7653\n",
      "\n",
      "Ep:6/29--Batch:1200/3832\n",
      "batch: loss_cls:0.7684--loss_regr:0.2371--loss:1.0055\n",
      "Epoch: loss_cls:0.6117--loss_regr:0.1544--loss:0.7661\n",
      "\n",
      "Ep:6/29--Batch:1300/3832\n",
      "batch: loss_cls:0.5415--loss_regr:0.1647--loss:0.7062\n",
      "Epoch: loss_cls:0.6110--loss_regr:0.1533--loss:0.7644\n",
      "\n",
      "Ep:6/29--Batch:1400/3832\n",
      "batch: loss_cls:0.6316--loss_regr:0.1449--loss:0.7765\n",
      "Epoch: loss_cls:0.6097--loss_regr:0.1525--loss:0.7622\n",
      "\n",
      "Ep:6/29--Batch:1500/3832\n",
      "batch: loss_cls:0.5082--loss_regr:0.1321--loss:0.6403\n",
      "Epoch: loss_cls:0.6092--loss_regr:0.1518--loss:0.7611\n",
      "\n",
      "Ep:6/29--Batch:1600/3832\n",
      "batch: loss_cls:0.4117--loss_regr:0.1265--loss:0.5382\n",
      "Epoch: loss_cls:0.6098--loss_regr:0.1530--loss:0.7628\n",
      "\n",
      "Ep:6/29--Batch:1700/3832\n",
      "batch: loss_cls:0.7512--loss_regr:0.1862--loss:0.9373\n",
      "Epoch: loss_cls:0.6083--loss_regr:0.1547--loss:0.7630\n",
      "\n",
      "Ep:6/29--Batch:1800/3832\n",
      "batch: loss_cls:0.3805--loss_regr:0.0895--loss:0.4700\n",
      "Epoch: loss_cls:0.6080--loss_regr:0.1543--loss:0.7623\n",
      "\n",
      "Ep:6/29--Batch:1900/3832\n",
      "batch: loss_cls:0.4279--loss_regr:0.1902--loss:0.6180\n",
      "Epoch: loss_cls:0.6073--loss_regr:0.1588--loss:0.7660\n",
      "\n",
      "Ep:6/29--Batch:2000/3832\n",
      "batch: loss_cls:0.4859--loss_regr:0.1311--loss:0.6169\n",
      "Epoch: loss_cls:0.6069--loss_regr:0.1587--loss:0.7656\n",
      "\n",
      "Ep:6/29--Batch:2100/3832\n",
      "batch: loss_cls:0.5303--loss_regr:0.0458--loss:0.5762\n",
      "Epoch: loss_cls:0.6070--loss_regr:0.1583--loss:0.7653\n",
      "\n",
      "Ep:6/29--Batch:2200/3832\n",
      "batch: loss_cls:0.5848--loss_regr:0.1679--loss:0.7528\n",
      "Epoch: loss_cls:0.6054--loss_regr:0.1578--loss:0.7632\n",
      "\n",
      "Ep:6/29--Batch:2300/3832\n",
      "batch: loss_cls:0.7332--loss_regr:0.1180--loss:0.8512\n",
      "Epoch: loss_cls:0.6047--loss_regr:0.1572--loss:0.7619\n",
      "\n",
      "Ep:6/29--Batch:2400/3832\n",
      "batch: loss_cls:0.5280--loss_regr:0.0531--loss:0.5811\n",
      "Epoch: loss_cls:0.6053--loss_regr:0.1578--loss:0.7632\n",
      "\n",
      "Ep:6/29--Batch:2500/3832\n",
      "batch: loss_cls:0.6132--loss_regr:0.1285--loss:0.7417\n",
      "Epoch: loss_cls:0.6042--loss_regr:0.1568--loss:0.7609\n",
      "\n",
      "Ep:6/29--Batch:2600/3832\n",
      "batch: loss_cls:0.4296--loss_regr:2.1732--loss:2.6028\n",
      "Epoch: loss_cls:0.6044--loss_regr:0.1566--loss:0.7610\n",
      "\n",
      "Ep:6/29--Batch:2700/3832\n",
      "batch: loss_cls:0.6848--loss_regr:0.1997--loss:0.8845\n",
      "Epoch: loss_cls:0.6040--loss_regr:0.1564--loss:0.7603\n",
      "\n",
      "Ep:6/29--Batch:2800/3832\n",
      "batch: loss_cls:0.3877--loss_regr:0.0750--loss:0.4627\n",
      "Epoch: loss_cls:0.6043--loss_regr:0.1570--loss:0.7614\n",
      "\n",
      "Ep:6/29--Batch:2900/3832\n",
      "batch: loss_cls:0.6812--loss_regr:0.0958--loss:0.7770\n",
      "Epoch: loss_cls:0.6044--loss_regr:0.1565--loss:0.7609\n",
      "\n",
      "Ep:6/29--Batch:3000/3832\n",
      "batch: loss_cls:0.5836--loss_regr:0.1235--loss:0.7071\n",
      "Epoch: loss_cls:0.6031--loss_regr:0.1559--loss:0.7590\n",
      "\n",
      "Ep:6/29--Batch:3100/3832\n",
      "batch: loss_cls:0.5387--loss_regr:0.1483--loss:0.6871\n",
      "Epoch: loss_cls:0.6033--loss_regr:0.1572--loss:0.7605\n",
      "\n",
      "Ep:6/29--Batch:3200/3832\n",
      "batch: loss_cls:0.5592--loss_regr:0.1336--loss:0.6927\n",
      "Epoch: loss_cls:0.6032--loss_regr:0.1570--loss:0.7602\n",
      "\n",
      "Ep:6/29--Batch:3300/3832\n",
      "batch: loss_cls:0.6962--loss_regr:0.1623--loss:0.8584\n",
      "Epoch: loss_cls:0.6036--loss_regr:0.1564--loss:0.7600\n",
      "\n",
      "Ep:6/29--Batch:3400/3832\n",
      "batch: loss_cls:0.4974--loss_regr:0.1250--loss:0.6224\n",
      "Epoch: loss_cls:0.6039--loss_regr:0.1567--loss:0.7607\n",
      "\n",
      "Ep:6/29--Batch:3500/3832\n",
      "batch: loss_cls:0.3316--loss_regr:0.0501--loss:0.3817\n",
      "Epoch: loss_cls:0.6027--loss_regr:0.1564--loss:0.7591\n",
      "\n",
      "Ep:6/29--Batch:3600/3832\n",
      "batch: loss_cls:0.5065--loss_regr:0.0907--loss:0.5972\n",
      "Epoch: loss_cls:0.6032--loss_regr:0.1563--loss:0.7595\n",
      "\n",
      "Ep:6/29--Batch:3700/3832\n",
      "batch: loss_cls:0.4170--loss_regr:0.0598--loss:0.4768\n",
      "Epoch: loss_cls:0.6027--loss_regr:0.1563--loss:0.7590\n",
      "\n",
      "Ep:6/29--Batch:3800/3832\n",
      "batch: loss_cls:0.6879--loss_regr:0.1321--loss:0.8200\n",
      "Epoch: loss_cls:0.6032--loss_regr:0.1567--loss:0.7599\n",
      "\n",
      "Epoch:6--0.6035--0.1566--0.7601\n",
      "saving to ../../checkpoints/v3_ctpn_ep06_0.6035_0.1566_0.7601.pth\n",
      "Epoch 7/30\n",
      "##################################################\n",
      "Ep:7/29--Batch:0/3832\n",
      "batch: loss_cls:0.5634--loss_regr:0.0991--loss:0.6625\n",
      "Epoch: loss_cls:0.5634--loss_regr:0.0991--loss:0.6625\n",
      "\n",
      "Ep:7/29--Batch:100/3832\n",
      "batch: loss_cls:0.5741--loss_regr:0.0830--loss:0.6571\n",
      "Epoch: loss_cls:0.5896--loss_regr:0.1483--loss:0.7380\n",
      "\n",
      "Ep:7/29--Batch:200/3832\n",
      "batch: loss_cls:0.7898--loss_regr:0.3692--loss:1.1590\n",
      "Epoch: loss_cls:0.5895--loss_regr:0.1441--loss:0.7336\n",
      "\n",
      "Ep:7/29--Batch:300/3832\n",
      "batch: loss_cls:0.7138--loss_regr:0.0981--loss:0.8119\n",
      "Epoch: loss_cls:0.6001--loss_regr:0.1537--loss:0.7538\n",
      "\n",
      "Ep:7/29--Batch:400/3832\n",
      "batch: loss_cls:0.3679--loss_regr:0.0569--loss:0.4247\n",
      "Epoch: loss_cls:0.5992--loss_regr:0.1492--loss:0.7484\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:7/29--Batch:500/3832\n",
      "batch: loss_cls:0.4431--loss_regr:0.0611--loss:0.5043\n",
      "Epoch: loss_cls:0.5905--loss_regr:0.1465--loss:0.7370\n",
      "\n",
      "Ep:7/29--Batch:600/3832\n",
      "batch: loss_cls:0.7830--loss_regr:0.2903--loss:1.0733\n",
      "Epoch: loss_cls:0.5851--loss_regr:0.1566--loss:0.7417\n",
      "\n",
      "Ep:7/29--Batch:700/3832\n",
      "batch: loss_cls:0.7357--loss_regr:0.0869--loss:0.8225\n",
      "Epoch: loss_cls:0.5911--loss_regr:0.1545--loss:0.7456\n",
      "\n",
      "Ep:7/29--Batch:800/3832\n",
      "batch: loss_cls:0.5599--loss_regr:0.0684--loss:0.6283\n",
      "Epoch: loss_cls:0.5913--loss_regr:0.1532--loss:0.7445\n",
      "\n",
      "Ep:7/29--Batch:900/3832\n",
      "batch: loss_cls:0.6375--loss_regr:0.1343--loss:0.7718\n",
      "Epoch: loss_cls:0.5914--loss_regr:0.1488--loss:0.7402\n",
      "\n",
      "Ep:7/29--Batch:1000/3832\n",
      "batch: loss_cls:0.4866--loss_regr:0.1687--loss:0.6553\n",
      "Epoch: loss_cls:0.5904--loss_regr:0.1478--loss:0.7382\n",
      "\n",
      "Ep:7/29--Batch:1100/3832\n",
      "batch: loss_cls:0.7545--loss_regr:0.1723--loss:0.9268\n",
      "Epoch: loss_cls:0.5960--loss_regr:0.1504--loss:0.7464\n",
      "\n",
      "Ep:7/29--Batch:1200/3832\n",
      "batch: loss_cls:0.7639--loss_regr:0.2242--loss:0.9881\n",
      "Epoch: loss_cls:0.5956--loss_regr:0.1502--loss:0.7457\n",
      "\n",
      "Ep:7/29--Batch:1300/3832\n",
      "batch: loss_cls:0.5814--loss_regr:0.2036--loss:0.7850\n",
      "Epoch: loss_cls:0.5947--loss_regr:0.1495--loss:0.7443\n",
      "\n",
      "Ep:7/29--Batch:1400/3832\n",
      "batch: loss_cls:0.5589--loss_regr:0.1403--loss:0.6992\n",
      "Epoch: loss_cls:0.5917--loss_regr:0.1489--loss:0.7406\n",
      "\n",
      "Ep:7/29--Batch:1500/3832\n",
      "batch: loss_cls:0.4291--loss_regr:0.0957--loss:0.5248\n",
      "Epoch: loss_cls:0.5916--loss_regr:0.1477--loss:0.7393\n",
      "\n",
      "Ep:7/29--Batch:1600/3832\n",
      "batch: loss_cls:0.3889--loss_regr:0.1110--loss:0.4999\n",
      "Epoch: loss_cls:0.5917--loss_regr:0.1485--loss:0.7402\n",
      "\n",
      "Ep:7/29--Batch:1700/3832\n",
      "batch: loss_cls:0.7012--loss_regr:0.2175--loss:0.9187\n",
      "Epoch: loss_cls:0.5909--loss_regr:0.1498--loss:0.7407\n",
      "\n",
      "Ep:7/29--Batch:1800/3832\n",
      "batch: loss_cls:0.4114--loss_regr:0.0665--loss:0.4779\n",
      "Epoch: loss_cls:0.5900--loss_regr:0.1494--loss:0.7395\n",
      "\n",
      "Ep:7/29--Batch:1900/3832\n",
      "batch: loss_cls:0.3718--loss_regr:0.1669--loss:0.5387\n",
      "Epoch: loss_cls:0.5894--loss_regr:0.1534--loss:0.7428\n",
      "\n",
      "Ep:7/29--Batch:2000/3832\n",
      "batch: loss_cls:0.4609--loss_regr:0.1247--loss:0.5856\n",
      "Epoch: loss_cls:0.5895--loss_regr:0.1534--loss:0.7429\n",
      "\n",
      "Ep:7/29--Batch:2100/3832\n",
      "batch: loss_cls:0.4453--loss_regr:0.0385--loss:0.4839\n",
      "Epoch: loss_cls:0.5896--loss_regr:0.1533--loss:0.7429\n",
      "\n",
      "Ep:7/29--Batch:2200/3832\n",
      "batch: loss_cls:0.4977--loss_regr:0.1081--loss:0.6057\n",
      "Epoch: loss_cls:0.5876--loss_regr:0.1526--loss:0.7402\n",
      "\n",
      "Ep:7/29--Batch:2300/3832\n",
      "batch: loss_cls:0.6979--loss_regr:0.1427--loss:0.8405\n",
      "Epoch: loss_cls:0.5866--loss_regr:0.1523--loss:0.7389\n",
      "\n",
      "Ep:7/29--Batch:2400/3832\n",
      "batch: loss_cls:0.4861--loss_regr:0.0791--loss:0.5653\n",
      "Epoch: loss_cls:0.5870--loss_regr:0.1529--loss:0.7399\n",
      "\n",
      "Ep:7/29--Batch:2500/3832\n",
      "batch: loss_cls:0.4999--loss_regr:0.1094--loss:0.6093\n",
      "Epoch: loss_cls:0.5850--loss_regr:0.1519--loss:0.7369\n",
      "\n",
      "Ep:7/29--Batch:2600/3832\n",
      "batch: loss_cls:0.4169--loss_regr:2.1882--loss:2.6051\n",
      "Epoch: loss_cls:0.5850--loss_regr:0.1519--loss:0.7369\n",
      "\n",
      "Ep:7/29--Batch:2700/3832\n",
      "batch: loss_cls:0.6994--loss_regr:0.2098--loss:0.9092\n",
      "Epoch: loss_cls:0.5851--loss_regr:0.1517--loss:0.7368\n",
      "\n",
      "Ep:7/29--Batch:2800/3832\n",
      "batch: loss_cls:0.3792--loss_regr:0.0537--loss:0.4329\n",
      "Epoch: loss_cls:0.5854--loss_regr:0.1524--loss:0.7378\n",
      "\n",
      "Ep:7/29--Batch:2900/3832\n",
      "batch: loss_cls:0.6884--loss_regr:0.1217--loss:0.8101\n",
      "Epoch: loss_cls:0.5857--loss_regr:0.1521--loss:0.7378\n",
      "\n",
      "Ep:7/29--Batch:3000/3832\n",
      "batch: loss_cls:0.5084--loss_regr:0.1254--loss:0.6338\n",
      "Epoch: loss_cls:0.5845--loss_regr:0.1515--loss:0.7360\n",
      "\n",
      "Ep:7/29--Batch:3100/3832\n",
      "batch: loss_cls:0.6004--loss_regr:0.1107--loss:0.7111\n",
      "Epoch: loss_cls:0.5846--loss_regr:0.1526--loss:0.7371\n",
      "\n",
      "Ep:7/29--Batch:3200/3832\n",
      "batch: loss_cls:0.4311--loss_regr:0.0727--loss:0.5038\n",
      "Epoch: loss_cls:0.5849--loss_regr:0.1524--loss:0.7373\n",
      "\n",
      "Ep:7/29--Batch:3300/3832\n",
      "batch: loss_cls:0.6890--loss_regr:0.1471--loss:0.8361\n",
      "Epoch: loss_cls:0.5853--loss_regr:0.1517--loss:0.7370\n",
      "\n",
      "Ep:7/29--Batch:3400/3832\n",
      "batch: loss_cls:0.4236--loss_regr:0.0963--loss:0.5199\n",
      "Epoch: loss_cls:0.5855--loss_regr:0.1521--loss:0.7376\n",
      "\n",
      "Ep:7/29--Batch:3500/3832\n",
      "batch: loss_cls:0.3242--loss_regr:0.0397--loss:0.3640\n",
      "Epoch: loss_cls:0.5841--loss_regr:0.1516--loss:0.7357\n",
      "\n",
      "Ep:7/29--Batch:3600/3832\n",
      "batch: loss_cls:0.3844--loss_regr:0.1021--loss:0.4866\n",
      "Epoch: loss_cls:0.5847--loss_regr:0.1514--loss:0.7362\n",
      "\n",
      "Ep:7/29--Batch:3700/3832\n",
      "batch: loss_cls:0.3408--loss_regr:0.0601--loss:0.4009\n",
      "Epoch: loss_cls:0.5835--loss_regr:0.1515--loss:0.7350\n",
      "\n",
      "Ep:7/29--Batch:3800/3832\n",
      "batch: loss_cls:0.7692--loss_regr:0.1418--loss:0.9110\n",
      "Epoch: loss_cls:0.5842--loss_regr:0.1519--loss:0.7361\n",
      "\n",
      "Epoch:7--0.5844--0.1519--0.7363\n",
      "saving to ../../checkpoints/v3_ctpn_ep07_0.5844_0.1519_0.7363.pth\n",
      "Epoch 8/30\n",
      "##################################################\n",
      "Ep:8/29--Batch:0/3832\n",
      "batch: loss_cls:0.4836--loss_regr:0.0702--loss:0.5537\n",
      "Epoch: loss_cls:0.4836--loss_regr:0.0702--loss:0.5537\n",
      "\n",
      "Ep:8/29--Batch:100/3832\n",
      "batch: loss_cls:0.6098--loss_regr:0.0875--loss:0.6973\n",
      "Epoch: loss_cls:0.5769--loss_regr:0.1458--loss:0.7228\n",
      "\n",
      "Ep:8/29--Batch:200/3832\n",
      "batch: loss_cls:0.7993--loss_regr:0.2970--loss:1.0963\n",
      "Epoch: loss_cls:0.5777--loss_regr:0.1434--loss:0.7211\n",
      "\n",
      "Ep:8/29--Batch:300/3832\n",
      "batch: loss_cls:0.7020--loss_regr:0.0892--loss:0.7912\n",
      "Epoch: loss_cls:0.5841--loss_regr:0.1506--loss:0.7348\n",
      "\n",
      "Ep:8/29--Batch:400/3832\n",
      "batch: loss_cls:0.2793--loss_regr:0.0421--loss:0.3214\n",
      "Epoch: loss_cls:0.5829--loss_regr:0.1456--loss:0.7285\n",
      "\n",
      "Ep:8/29--Batch:500/3832\n",
      "batch: loss_cls:0.3750--loss_regr:0.0705--loss:0.4455\n",
      "Epoch: loss_cls:0.5718--loss_regr:0.1428--loss:0.7146\n",
      "\n",
      "Ep:8/29--Batch:600/3832\n",
      "batch: loss_cls:0.7989--loss_regr:0.2563--loss:1.0552\n",
      "Epoch: loss_cls:0.5677--loss_regr:0.1537--loss:0.7213\n",
      "\n",
      "Ep:8/29--Batch:700/3832\n",
      "batch: loss_cls:0.7452--loss_regr:0.0851--loss:0.8303\n",
      "Epoch: loss_cls:0.5743--loss_regr:0.1515--loss:0.7258\n",
      "\n",
      "Ep:8/29--Batch:800/3832\n",
      "batch: loss_cls:0.6096--loss_regr:0.0717--loss:0.6813\n",
      "Epoch: loss_cls:0.5749--loss_regr:0.1505--loss:0.7254\n",
      "\n",
      "Ep:8/29--Batch:900/3832\n",
      "batch: loss_cls:0.7444--loss_regr:0.1625--loss:0.9069\n",
      "Epoch: loss_cls:0.5778--loss_regr:0.1463--loss:0.7241\n",
      "\n",
      "Ep:8/29--Batch:1000/3832\n",
      "batch: loss_cls:0.3662--loss_regr:0.1812--loss:0.5475\n",
      "Epoch: loss_cls:0.5743--loss_regr:0.1456--loss:0.7199\n",
      "\n",
      "Ep:8/29--Batch:1200/3832\n",
      "batch: loss_cls:0.6976--loss_regr:0.0562--loss:0.7538\n",
      "Epoch: loss_cls:0.5762--loss_regr:0.1477--loss:0.7239\n",
      "\n",
      "Ep:8/29--Batch:1300/3832\n",
      "batch: loss_cls:0.4755--loss_regr:0.1618--loss:0.6373\n",
      "Epoch: loss_cls:0.5757--loss_regr:0.1468--loss:0.7224\n",
      "\n",
      "Ep:8/29--Batch:1400/3832\n",
      "batch: loss_cls:0.4402--loss_regr:0.1519--loss:0.5921\n",
      "Epoch: loss_cls:0.5735--loss_regr:0.1459--loss:0.7193\n",
      "\n",
      "Ep:8/29--Batch:1500/3832\n",
      "batch: loss_cls:0.3779--loss_regr:0.1164--loss:0.4943\n",
      "Epoch: loss_cls:0.5730--loss_regr:0.1446--loss:0.7176\n",
      "\n",
      "Ep:8/29--Batch:1600/3832\n",
      "batch: loss_cls:0.3474--loss_regr:0.1044--loss:0.4517\n",
      "Epoch: loss_cls:0.5725--loss_regr:0.1456--loss:0.7181\n",
      "\n",
      "Ep:8/29--Batch:1700/3832\n",
      "batch: loss_cls:0.7603--loss_regr:0.2239--loss:0.9841\n",
      "Epoch: loss_cls:0.5714--loss_regr:0.1470--loss:0.7184\n",
      "\n",
      "Ep:8/29--Batch:1800/3832\n",
      "batch: loss_cls:0.3447--loss_regr:0.0846--loss:0.4293\n",
      "Epoch: loss_cls:0.5716--loss_regr:0.1467--loss:0.7183\n",
      "\n",
      "Ep:8/29--Batch:1900/3832\n",
      "batch: loss_cls:0.3606--loss_regr:0.1652--loss:0.5258\n",
      "Epoch: loss_cls:0.5703--loss_regr:0.1507--loss:0.7210\n",
      "\n",
      "Ep:8/29--Batch:2000/3832\n",
      "batch: loss_cls:0.5462--loss_regr:0.1409--loss:0.6871\n",
      "Epoch: loss_cls:0.5701--loss_regr:0.1505--loss:0.7207\n",
      "\n",
      "Ep:8/29--Batch:2100/3832\n",
      "batch: loss_cls:0.4351--loss_regr:0.0457--loss:0.4807\n",
      "Epoch: loss_cls:0.5698--loss_regr:0.1502--loss:0.7200\n",
      "\n",
      "Ep:8/29--Batch:2200/3832\n",
      "batch: loss_cls:0.5163--loss_regr:0.1381--loss:0.6544\n",
      "Epoch: loss_cls:0.5683--loss_regr:0.1497--loss:0.7181\n",
      "\n",
      "Ep:8/29--Batch:2300/3832\n",
      "batch: loss_cls:0.6197--loss_regr:0.1397--loss:0.7594\n",
      "Epoch: loss_cls:0.5671--loss_regr:0.1493--loss:0.7164\n",
      "\n",
      "Ep:8/29--Batch:2400/3832\n",
      "batch: loss_cls:0.6195--loss_regr:0.0556--loss:0.6751\n",
      "Epoch: loss_cls:0.5674--loss_regr:0.1501--loss:0.7175\n",
      "\n",
      "Ep:8/29--Batch:2500/3832\n",
      "batch: loss_cls:0.4433--loss_regr:0.0912--loss:0.5345\n",
      "Epoch: loss_cls:0.5655--loss_regr:0.1491--loss:0.7146\n",
      "\n",
      "Ep:8/29--Batch:2600/3832\n",
      "batch: loss_cls:0.4025--loss_regr:2.2326--loss:2.6351\n",
      "Epoch: loss_cls:0.5666--loss_regr:0.1490--loss:0.7156\n",
      "\n",
      "Ep:8/29--Batch:2700/3832\n",
      "batch: loss_cls:0.6763--loss_regr:0.2202--loss:0.8965\n",
      "Epoch: loss_cls:0.5666--loss_regr:0.1486--loss:0.7152\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:8/29--Batch:2800/3832\n",
      "batch: loss_cls:0.3305--loss_regr:0.0471--loss:0.3776\n",
      "Epoch: loss_cls:0.5674--loss_regr:0.1495--loss:0.7169\n",
      "\n",
      "Ep:8/29--Batch:2900/3832\n",
      "batch: loss_cls:0.6276--loss_regr:0.1034--loss:0.7309\n",
      "Epoch: loss_cls:0.5680--loss_regr:0.1492--loss:0.7172\n",
      "\n",
      "Ep:8/29--Batch:3000/3832\n",
      "batch: loss_cls:0.5088--loss_regr:0.1260--loss:0.6348\n",
      "Epoch: loss_cls:0.5667--loss_regr:0.1486--loss:0.7153\n",
      "\n",
      "Ep:8/29--Batch:3100/3832\n",
      "batch: loss_cls:0.5680--loss_regr:0.1052--loss:0.6732\n",
      "Epoch: loss_cls:0.5672--loss_regr:0.1497--loss:0.7169\n",
      "\n",
      "Ep:8/29--Batch:3200/3832\n",
      "batch: loss_cls:0.5301--loss_regr:0.1197--loss:0.6498\n",
      "Epoch: loss_cls:0.5670--loss_regr:0.1495--loss:0.7165\n",
      "\n",
      "Ep:8/29--Batch:3300/3832\n",
      "batch: loss_cls:0.7032--loss_regr:0.1559--loss:0.8591\n",
      "Epoch: loss_cls:0.5671--loss_regr:0.1489--loss:0.7160\n",
      "\n",
      "Ep:8/29--Batch:3400/3832\n",
      "batch: loss_cls:0.4277--loss_regr:0.0952--loss:0.5229\n",
      "Epoch: loss_cls:0.5670--loss_regr:0.1492--loss:0.7162\n",
      "\n",
      "Ep:8/29--Batch:3500/3832\n",
      "batch: loss_cls:0.2559--loss_regr:0.0236--loss:0.2795\n",
      "Epoch: loss_cls:0.5659--loss_regr:0.1488--loss:0.7148\n",
      "\n",
      "Ep:8/29--Batch:3600/3832\n",
      "batch: loss_cls:0.5677--loss_regr:0.0614--loss:0.6291\n",
      "Epoch: loss_cls:0.5664--loss_regr:0.1488--loss:0.7152\n",
      "\n",
      "Ep:8/29--Batch:3700/3832\n",
      "batch: loss_cls:0.3341--loss_regr:0.0564--loss:0.3905\n",
      "Epoch: loss_cls:0.5653--loss_regr:0.1488--loss:0.7141\n",
      "\n",
      "Ep:8/29--Batch:3800/3832\n",
      "batch: loss_cls:0.7488--loss_regr:0.1267--loss:0.8755\n",
      "Epoch: loss_cls:0.5661--loss_regr:0.1491--loss:0.7152\n",
      "\n",
      "Epoch:8--0.5665--0.1491--0.7156\n",
      "saving to ../../checkpoints/v3_ctpn_ep08_0.5665_0.1491_0.7156.pth\n",
      "Epoch 9/30\n",
      "##################################################\n",
      "Ep:9/29--Batch:0/3832\n",
      "batch: loss_cls:0.5214--loss_regr:0.0957--loss:0.6171\n",
      "Epoch: loss_cls:0.5214--loss_regr:0.0957--loss:0.6171\n",
      "\n",
      "Ep:9/29--Batch:100/3832\n",
      "batch: loss_cls:0.5802--loss_regr:0.0903--loss:0.6705\n",
      "Epoch: loss_cls:0.5732--loss_regr:0.1353--loss:0.7084\n",
      "\n",
      "Ep:9/29--Batch:200/3832\n",
      "batch: loss_cls:0.8241--loss_regr:0.2867--loss:1.1108\n",
      "Epoch: loss_cls:0.5624--loss_regr:0.1344--loss:0.6968\n",
      "\n",
      "Ep:9/29--Batch:300/3832\n",
      "batch: loss_cls:0.6894--loss_regr:0.0827--loss:0.7721\n",
      "Epoch: loss_cls:0.5662--loss_regr:0.1443--loss:0.7105\n",
      "\n",
      "Ep:9/29--Batch:400/3832\n",
      "batch: loss_cls:0.2722--loss_regr:0.0608--loss:0.3330\n",
      "Epoch: loss_cls:0.5681--loss_regr:0.1408--loss:0.7089\n",
      "\n",
      "Ep:9/29--Batch:500/3832\n",
      "batch: loss_cls:0.2943--loss_regr:0.0522--loss:0.3465\n",
      "Epoch: loss_cls:0.5574--loss_regr:0.1387--loss:0.6961\n",
      "\n",
      "Ep:9/29--Batch:600/3832\n",
      "batch: loss_cls:0.8352--loss_regr:0.2893--loss:1.1245\n",
      "Epoch: loss_cls:0.5525--loss_regr:0.1487--loss:0.7012\n",
      "\n",
      "Ep:9/29--Batch:700/3832\n",
      "batch: loss_cls:0.7355--loss_regr:0.0703--loss:0.8057\n",
      "Epoch: loss_cls:0.5595--loss_regr:0.1475--loss:0.7071\n",
      "\n",
      "Ep:9/29--Batch:800/3832\n",
      "batch: loss_cls:0.5872--loss_regr:0.0842--loss:0.6714\n",
      "Epoch: loss_cls:0.5593--loss_regr:0.1465--loss:0.7058\n",
      "\n",
      "Ep:9/29--Batch:900/3832\n",
      "batch: loss_cls:0.6651--loss_regr:0.1461--loss:0.8112\n",
      "Epoch: loss_cls:0.5591--loss_regr:0.1419--loss:0.7010\n",
      "\n",
      "Ep:9/29--Batch:1000/3832\n",
      "batch: loss_cls:0.4633--loss_regr:0.1612--loss:0.6245\n",
      "Epoch: loss_cls:0.5557--loss_regr:0.1408--loss:0.6965\n",
      "\n",
      "Ep:9/29--Batch:1100/3832\n",
      "batch: loss_cls:0.5355--loss_regr:0.1114--loss:0.6469\n",
      "Epoch: loss_cls:0.5593--loss_regr:0.1433--loss:0.7026\n",
      "\n",
      "Ep:9/29--Batch:1200/3832\n",
      "batch: loss_cls:0.8053--loss_regr:0.2691--loss:1.0744\n",
      "Epoch: loss_cls:0.5579--loss_regr:0.1428--loss:0.7006\n",
      "\n",
      "Ep:9/29--Batch:1300/3832\n",
      "batch: loss_cls:0.4400--loss_regr:0.1459--loss:0.5859\n",
      "Epoch: loss_cls:0.5571--loss_regr:0.1421--loss:0.6992\n",
      "\n",
      "Ep:9/29--Batch:1400/3832\n",
      "batch: loss_cls:0.4447--loss_regr:0.1495--loss:0.5942\n",
      "Epoch: loss_cls:0.5551--loss_regr:0.1412--loss:0.6963\n",
      "\n",
      "Ep:9/29--Batch:1500/3832\n",
      "batch: loss_cls:0.3524--loss_regr:0.1047--loss:0.4571\n",
      "Epoch: loss_cls:0.5548--loss_regr:0.1400--loss:0.6949\n",
      "\n",
      "Ep:9/29--Batch:1600/3832\n",
      "batch: loss_cls:0.3496--loss_regr:0.0905--loss:0.4401\n",
      "Epoch: loss_cls:0.5553--loss_regr:0.1410--loss:0.6963\n",
      "\n",
      "Ep:9/29--Batch:1700/3832\n",
      "batch: loss_cls:0.7212--loss_regr:0.2484--loss:0.9696\n",
      "Epoch: loss_cls:0.5547--loss_regr:0.1419--loss:0.6966\n",
      "\n",
      "Ep:9/29--Batch:1900/3832\n",
      "batch: loss_cls:0.3168--loss_regr:0.2160--loss:0.5328\n",
      "Epoch: loss_cls:0.5541--loss_regr:0.1455--loss:0.6996\n",
      "\n",
      "Ep:9/29--Batch:2000/3832\n",
      "batch: loss_cls:0.4763--loss_regr:0.1220--loss:0.5983\n",
      "Epoch: loss_cls:0.5549--loss_regr:0.1454--loss:0.7002\n",
      "\n",
      "Ep:9/29--Batch:2100/3832\n",
      "batch: loss_cls:0.4116--loss_regr:0.0418--loss:0.4535\n",
      "Epoch: loss_cls:0.5559--loss_regr:0.1451--loss:0.7009\n",
      "\n",
      "Ep:9/29--Batch:2200/3832\n",
      "batch: loss_cls:0.6617--loss_regr:0.1257--loss:0.7874\n",
      "Epoch: loss_cls:0.5535--loss_regr:0.1444--loss:0.6979\n",
      "\n",
      "Ep:9/29--Batch:2300/3832\n",
      "batch: loss_cls:0.6400--loss_regr:0.1147--loss:0.7547\n",
      "Epoch: loss_cls:0.5518--loss_regr:0.1441--loss:0.6959\n",
      "\n",
      "Ep:9/29--Batch:2400/3832\n",
      "batch: loss_cls:0.5631--loss_regr:0.0503--loss:0.6134\n",
      "Epoch: loss_cls:0.5529--loss_regr:0.1449--loss:0.6978\n",
      "\n",
      "Ep:9/29--Batch:2500/3832\n",
      "batch: loss_cls:0.4514--loss_regr:0.1134--loss:0.5648\n",
      "Epoch: loss_cls:0.5506--loss_regr:0.1440--loss:0.6946\n",
      "\n",
      "Ep:9/29--Batch:2600/3832\n",
      "batch: loss_cls:0.3902--loss_regr:2.2212--loss:2.6114\n",
      "Epoch: loss_cls:0.5514--loss_regr:0.1439--loss:0.6953\n",
      "\n",
      "Ep:9/29--Batch:2700/3832\n",
      "batch: loss_cls:0.6879--loss_regr:0.2066--loss:0.8945\n",
      "Epoch: loss_cls:0.5515--loss_regr:0.1438--loss:0.6953\n",
      "\n",
      "Ep:9/29--Batch:2800/3832\n",
      "batch: loss_cls:0.3795--loss_regr:0.0724--loss:0.4519\n",
      "Epoch: loss_cls:0.5526--loss_regr:0.1446--loss:0.6971\n",
      "\n",
      "Ep:9/29--Batch:2900/3832\n",
      "batch: loss_cls:0.5830--loss_regr:0.1287--loss:0.7117\n",
      "Epoch: loss_cls:0.5526--loss_regr:0.1442--loss:0.6968\n",
      "\n",
      "Ep:9/29--Batch:3000/3832\n",
      "batch: loss_cls:0.4137--loss_regr:0.1310--loss:0.5447\n",
      "Epoch: loss_cls:0.5509--loss_regr:0.1435--loss:0.6944\n",
      "\n",
      "Ep:9/29--Batch:3100/3832\n",
      "batch: loss_cls:0.5595--loss_regr:0.1241--loss:0.6836\n",
      "Epoch: loss_cls:0.5516--loss_regr:0.1447--loss:0.6963\n",
      "\n",
      "Ep:9/29--Batch:3200/3832\n",
      "batch: loss_cls:0.5676--loss_regr:0.1230--loss:0.6906\n",
      "Epoch: loss_cls:0.5524--loss_regr:0.1449--loss:0.6973\n",
      "\n",
      "Ep:9/29--Batch:3300/3832\n",
      "batch: loss_cls:0.6640--loss_regr:0.1632--loss:0.8273\n",
      "Epoch: loss_cls:0.5523--loss_regr:0.1443--loss:0.6967\n",
      "\n",
      "Ep:9/29--Batch:3400/3832\n",
      "batch: loss_cls:0.3455--loss_regr:0.0810--loss:0.4264\n",
      "Epoch: loss_cls:0.5520--loss_regr:0.1446--loss:0.6966\n",
      "\n",
      "Ep:9/29--Batch:3500/3832\n",
      "batch: loss_cls:0.2075--loss_regr:0.0243--loss:0.2317\n",
      "Epoch: loss_cls:0.5504--loss_regr:0.1442--loss:0.6946\n",
      "\n",
      "Ep:9/29--Batch:3600/3832\n",
      "batch: loss_cls:0.3391--loss_regr:0.0756--loss:0.4147\n",
      "Epoch: loss_cls:0.5504--loss_regr:0.1441--loss:0.6945\n",
      "\n",
      "Ep:9/29--Batch:3700/3832\n",
      "batch: loss_cls:0.3143--loss_regr:0.0432--loss:0.3575\n",
      "Epoch: loss_cls:0.5497--loss_regr:0.1440--loss:0.6938\n",
      "\n",
      "Ep:9/29--Batch:3800/3832\n",
      "batch: loss_cls:0.5880--loss_regr:0.1014--loss:0.6894\n",
      "Epoch: loss_cls:0.5505--loss_regr:0.1445--loss:0.6950\n",
      "\n",
      "Epoch:9--0.5509--0.1444--0.6953\n",
      "saving to ../../checkpoints/v3_ctpn_ep09_0.5509_0.1444_0.6953.pth\n",
      "Epoch 10/30\n",
      "##################################################\n",
      "Ep:10/29--Batch:0/3832\n",
      "batch: loss_cls:0.5100--loss_regr:0.0769--loss:0.5870\n",
      "Epoch: loss_cls:0.5100--loss_regr:0.0769--loss:0.5870\n",
      "\n",
      "Ep:10/29--Batch:100/3832\n",
      "batch: loss_cls:0.6637--loss_regr:0.0895--loss:0.7532\n",
      "Epoch: loss_cls:0.5674--loss_regr:0.1311--loss:0.6985\n",
      "\n",
      "Ep:10/29--Batch:200/3832\n",
      "batch: loss_cls:0.8279--loss_regr:0.2094--loss:1.0373\n",
      "Epoch: loss_cls:0.5558--loss_regr:0.1300--loss:0.6858\n",
      "\n",
      "Ep:10/29--Batch:300/3832\n",
      "batch: loss_cls:0.6606--loss_regr:0.0832--loss:0.7438\n",
      "Epoch: loss_cls:0.5505--loss_regr:0.1361--loss:0.6866\n",
      "\n",
      "Ep:10/29--Batch:400/3832\n",
      "batch: loss_cls:0.2187--loss_regr:0.0264--loss:0.2451\n",
      "Epoch: loss_cls:0.5425--loss_regr:0.1300--loss:0.6725\n",
      "\n",
      "Ep:10/29--Batch:500/3832\n",
      "batch: loss_cls:0.2879--loss_regr:0.0401--loss:0.3280\n",
      "Epoch: loss_cls:0.5306--loss_regr:0.1264--loss:0.6569\n",
      "\n",
      "Ep:10/29--Batch:600/3832\n",
      "batch: loss_cls:0.7669--loss_regr:0.2671--loss:1.0340\n",
      "Epoch: loss_cls:0.5243--loss_regr:0.1352--loss:0.6594\n",
      "\n",
      "Ep:10/29--Batch:700/3832\n",
      "batch: loss_cls:0.6790--loss_regr:0.0870--loss:0.7660\n",
      "Epoch: loss_cls:0.5277--loss_regr:0.1335--loss:0.6612\n",
      "\n",
      "Ep:10/29--Batch:800/3832\n",
      "batch: loss_cls:0.5141--loss_regr:0.0555--loss:0.5696\n",
      "Epoch: loss_cls:0.5268--loss_regr:0.1322--loss:0.6590\n",
      "\n",
      "Ep:10/29--Batch:900/3832\n",
      "batch: loss_cls:0.5575--loss_regr:0.1381--loss:0.6955\n",
      "Epoch: loss_cls:0.5285--loss_regr:0.1280--loss:0.6565\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:10/29--Batch:1000/3832\n",
      "batch: loss_cls:0.3381--loss_regr:0.2142--loss:0.5523\n",
      "Epoch: loss_cls:0.5234--loss_regr:0.1265--loss:0.6499\n",
      "\n",
      "Ep:10/29--Batch:1100/3832\n",
      "batch: loss_cls:0.9093--loss_regr:0.1820--loss:1.0913\n",
      "Epoch: loss_cls:0.5273--loss_regr:0.1290--loss:0.6564\n",
      "\n",
      "Ep:10/29--Batch:1200/3832\n",
      "batch: loss_cls:0.7818--loss_regr:0.2100--loss:0.9919\n",
      "Epoch: loss_cls:0.5257--loss_regr:0.1285--loss:0.6542\n",
      "\n",
      "Ep:10/29--Batch:1300/3832\n",
      "batch: loss_cls:0.3600--loss_regr:0.0997--loss:0.4596\n",
      "Epoch: loss_cls:0.5246--loss_regr:0.1277--loss:0.6523\n",
      "\n",
      "Ep:10/29--Batch:1400/3832\n",
      "batch: loss_cls:0.3937--loss_regr:0.1405--loss:0.5341\n",
      "Epoch: loss_cls:0.5222--loss_regr:0.1271--loss:0.6493\n",
      "\n",
      "Ep:10/29--Batch:1500/3832\n",
      "batch: loss_cls:0.3304--loss_regr:0.0972--loss:0.4276\n",
      "Epoch: loss_cls:0.5210--loss_regr:0.1259--loss:0.6469\n",
      "\n",
      "Ep:10/29--Batch:1600/3832\n",
      "batch: loss_cls:0.3285--loss_regr:0.0845--loss:0.4130\n",
      "Epoch: loss_cls:0.5210--loss_regr:0.1268--loss:0.6479\n",
      "\n",
      "Ep:10/29--Batch:1700/3832\n",
      "batch: loss_cls:0.6737--loss_regr:0.1396--loss:0.8132\n",
      "Epoch: loss_cls:0.5197--loss_regr:0.1279--loss:0.6476\n",
      "\n",
      "Ep:10/29--Batch:1800/3832\n",
      "batch: loss_cls:0.3439--loss_regr:0.0631--loss:0.4070\n",
      "Epoch: loss_cls:0.5163--loss_regr:0.1276--loss:0.6438\n",
      "\n",
      "Ep:10/29--Batch:1900/3832\n",
      "batch: loss_cls:0.3251--loss_regr:0.2297--loss:0.5548\n",
      "Epoch: loss_cls:0.5158--loss_regr:0.1318--loss:0.6476\n",
      "\n",
      "Ep:10/29--Batch:2000/3832\n",
      "batch: loss_cls:0.4064--loss_regr:0.1409--loss:0.5472\n",
      "Epoch: loss_cls:0.5150--loss_regr:0.1318--loss:0.6468\n",
      "\n",
      "Ep:10/29--Batch:2100/3832\n",
      "batch: loss_cls:0.3801--loss_regr:0.0364--loss:0.4165\n",
      "Epoch: loss_cls:0.5161--loss_regr:0.1311--loss:0.6471\n",
      "\n",
      "Ep:10/29--Batch:2200/3832\n",
      "batch: loss_cls:0.4952--loss_regr:0.1061--loss:0.6013\n",
      "Epoch: loss_cls:0.5139--loss_regr:0.1303--loss:0.6441\n",
      "\n",
      "Ep:10/29--Batch:2300/3832\n",
      "batch: loss_cls:0.6098--loss_regr:0.1235--loss:0.7333\n",
      "Epoch: loss_cls:0.5126--loss_regr:0.1299--loss:0.6424\n",
      "\n",
      "Ep:10/29--Batch:2400/3832\n",
      "batch: loss_cls:0.3517--loss_regr:0.0678--loss:0.4194\n",
      "Epoch: loss_cls:0.5121--loss_regr:0.1306--loss:0.6428\n",
      "\n",
      "Ep:10/29--Batch:2500/3832\n",
      "batch: loss_cls:0.4327--loss_regr:0.1027--loss:0.5354\n",
      "Epoch: loss_cls:0.5100--loss_regr:0.1293--loss:0.6393\n",
      "\n",
      "Ep:10/29--Batch:2600/3832\n",
      "batch: loss_cls:0.3702--loss_regr:2.0026--loss:2.3728\n",
      "Epoch: loss_cls:0.5117--loss_regr:0.1292--loss:0.6410\n",
      "\n",
      "Ep:10/29--Batch:2700/3832\n",
      "batch: loss_cls:0.7355--loss_regr:0.1636--loss:0.8991\n",
      "Epoch: loss_cls:0.5118--loss_regr:0.1291--loss:0.6409\n",
      "\n",
      "Ep:10/29--Batch:2800/3832\n",
      "batch: loss_cls:0.2920--loss_regr:0.0433--loss:0.3353\n",
      "Epoch: loss_cls:0.5122--loss_regr:0.1298--loss:0.6420\n",
      "\n",
      "Ep:10/29--Batch:2900/3832\n",
      "batch: loss_cls:0.4752--loss_regr:0.0732--loss:0.5484\n",
      "Epoch: loss_cls:0.5125--loss_regr:0.1295--loss:0.6419\n",
      "\n",
      "Ep:10/29--Batch:3000/3832\n",
      "batch: loss_cls:0.3514--loss_regr:0.0815--loss:0.4329\n",
      "Epoch: loss_cls:0.5106--loss_regr:0.1288--loss:0.6395\n",
      "\n",
      "Ep:10/29--Batch:3100/3832\n",
      "batch: loss_cls:0.4556--loss_regr:0.1342--loss:0.5897\n",
      "Epoch: loss_cls:0.5112--loss_regr:0.1299--loss:0.6411\n",
      "\n",
      "Ep:10/29--Batch:3200/3832\n",
      "batch: loss_cls:0.3964--loss_regr:0.0961--loss:0.4925\n",
      "Epoch: loss_cls:0.5110--loss_regr:0.1296--loss:0.6406\n",
      "\n",
      "Ep:10/29--Batch:3300/3832\n",
      "batch: loss_cls:0.6576--loss_regr:0.1417--loss:0.7993\n",
      "Epoch: loss_cls:0.5112--loss_regr:0.1293--loss:0.6404\n",
      "\n",
      "Ep:10/29--Batch:3400/3832\n",
      "batch: loss_cls:0.3172--loss_regr:0.0812--loss:0.3984\n",
      "Epoch: loss_cls:0.5111--loss_regr:0.1295--loss:0.6406\n",
      "\n",
      "Ep:10/29--Batch:3500/3832\n",
      "batch: loss_cls:0.2451--loss_regr:0.0178--loss:0.2628\n",
      "Epoch: loss_cls:0.5096--loss_regr:0.1292--loss:0.6388\n",
      "\n",
      "Ep:10/29--Batch:3600/3832\n",
      "batch: loss_cls:0.3002--loss_regr:0.0546--loss:0.3548\n",
      "Epoch: loss_cls:0.5097--loss_regr:0.1292--loss:0.6390\n",
      "\n",
      "Ep:10/29--Batch:3700/3832\n",
      "batch: loss_cls:0.3116--loss_regr:0.0437--loss:0.3553\n",
      "Epoch: loss_cls:0.5096--loss_regr:0.1291--loss:0.6387\n",
      "\n",
      "Ep:10/29--Batch:3800/3832\n",
      "batch: loss_cls:0.6167--loss_regr:0.1253--loss:0.7420\n",
      "Epoch: loss_cls:0.5098--loss_regr:0.1296--loss:0.6394\n",
      "\n",
      "Epoch:10--0.5101--0.1296--0.6397\n",
      "saving to ../../checkpoints/v3_ctpn_ep10_0.5101_0.1296_0.6397.pth\n",
      "Epoch 11/30\n",
      "##################################################\n",
      "Ep:11/29--Batch:0/3832\n",
      "batch: loss_cls:0.3641--loss_regr:0.0771--loss:0.4412\n",
      "Epoch: loss_cls:0.3641--loss_regr:0.0771--loss:0.4412\n",
      "\n",
      "Ep:11/29--Batch:100/3832\n",
      "batch: loss_cls:0.6575--loss_regr:0.1085--loss:0.7660\n",
      "Epoch: loss_cls:0.5244--loss_regr:0.1250--loss:0.6494\n",
      "\n",
      "Ep:11/29--Batch:200/3832\n",
      "batch: loss_cls:0.8227--loss_regr:0.2157--loss:1.0383\n",
      "Epoch: loss_cls:0.5235--loss_regr:0.1244--loss:0.6479\n",
      "\n",
      "Ep:11/29--Batch:300/3832\n",
      "batch: loss_cls:0.7591--loss_regr:0.0705--loss:0.8296\n",
      "Epoch: loss_cls:0.5259--loss_regr:0.1304--loss:0.6563\n",
      "\n",
      "Ep:11/29--Batch:400/3832\n",
      "batch: loss_cls:0.1985--loss_regr:0.0262--loss:0.2247\n",
      "Epoch: loss_cls:0.5175--loss_regr:0.1247--loss:0.6422\n",
      "\n",
      "Ep:11/29--Batch:500/3832\n",
      "batch: loss_cls:0.2972--loss_regr:0.0431--loss:0.3403\n",
      "Epoch: loss_cls:0.5079--loss_regr:0.1220--loss:0.6298\n",
      "\n",
      "Ep:11/29--Batch:600/3832\n",
      "batch: loss_cls:0.8012--loss_regr:0.2529--loss:1.0541\n",
      "Epoch: loss_cls:0.5032--loss_regr:0.1318--loss:0.6350\n",
      "\n",
      "Ep:11/29--Batch:700/3832\n",
      "batch: loss_cls:0.5567--loss_regr:0.0915--loss:0.6481\n",
      "Epoch: loss_cls:0.5059--loss_regr:0.1306--loss:0.6365\n",
      "\n",
      "Ep:11/29--Batch:800/3832\n",
      "batch: loss_cls:0.4429--loss_regr:0.0655--loss:0.5084\n",
      "Epoch: loss_cls:0.5065--loss_regr:0.1296--loss:0.6362\n",
      "\n",
      "Ep:11/29--Batch:900/3832\n",
      "batch: loss_cls:0.6228--loss_regr:0.1339--loss:0.7567\n",
      "Epoch: loss_cls:0.5076--loss_regr:0.1254--loss:0.6329\n",
      "\n",
      "Ep:11/29--Batch:1000/3832\n",
      "batch: loss_cls:0.3184--loss_regr:0.1904--loss:0.5088\n",
      "Epoch: loss_cls:0.5026--loss_regr:0.1240--loss:0.6265\n",
      "\n",
      "Ep:11/29--Batch:1100/3832\n",
      "batch: loss_cls:0.5208--loss_regr:0.1234--loss:0.6442\n",
      "Epoch: loss_cls:0.5072--loss_regr:0.1264--loss:0.6336\n",
      "\n",
      "Ep:11/29--Batch:1200/3832\n",
      "batch: loss_cls:0.7109--loss_regr:0.0386--loss:0.7495\n",
      "Epoch: loss_cls:0.5084--loss_regr:0.1260--loss:0.6343\n",
      "\n",
      "Ep:11/29--Batch:1300/3832\n",
      "batch: loss_cls:0.3629--loss_regr:0.0979--loss:0.4608\n",
      "Epoch: loss_cls:0.5083--loss_regr:0.1253--loss:0.6337\n",
      "\n",
      "Ep:11/29--Batch:1400/3832\n",
      "batch: loss_cls:0.3367--loss_regr:0.1386--loss:0.4753\n",
      "Epoch: loss_cls:0.5053--loss_regr:0.1244--loss:0.6296\n",
      "\n",
      "Ep:11/29--Batch:1500/3832\n",
      "batch: loss_cls:0.3322--loss_regr:0.1047--loss:0.4369\n",
      "Epoch: loss_cls:0.5052--loss_regr:0.1233--loss:0.6285\n",
      "\n",
      "Ep:11/29--Batch:1600/3832\n",
      "batch: loss_cls:0.3160--loss_regr:0.0699--loss:0.3859\n",
      "Epoch: loss_cls:0.5059--loss_regr:0.1244--loss:0.6303\n",
      "\n",
      "Ep:11/29--Batch:1700/3832\n",
      "batch: loss_cls:0.6567--loss_regr:0.1303--loss:0.7869\n",
      "Epoch: loss_cls:0.5051--loss_regr:0.1252--loss:0.6303\n",
      "\n",
      "Ep:11/29--Batch:1800/3832\n",
      "batch: loss_cls:0.3302--loss_regr:0.0643--loss:0.3945\n",
      "Epoch: loss_cls:0.5024--loss_regr:0.1247--loss:0.6271\n",
      "\n",
      "Ep:11/29--Batch:1900/3832\n",
      "batch: loss_cls:0.3113--loss_regr:0.2165--loss:0.5279\n",
      "Epoch: loss_cls:0.5024--loss_regr:0.1287--loss:0.6311\n",
      "\n",
      "Ep:11/29--Batch:2000/3832\n",
      "batch: loss_cls:0.3958--loss_regr:0.1420--loss:0.5378\n",
      "Epoch: loss_cls:0.5022--loss_regr:0.1287--loss:0.6309\n",
      "\n",
      "Ep:11/29--Batch:2100/3832\n",
      "batch: loss_cls:0.3762--loss_regr:0.0311--loss:0.4073\n",
      "Epoch: loss_cls:0.5029--loss_regr:0.1280--loss:0.6310\n",
      "\n",
      "Ep:11/29--Batch:2200/3832\n",
      "batch: loss_cls:0.6099--loss_regr:0.0808--loss:0.6907\n",
      "Epoch: loss_cls:0.5014--loss_regr:0.1273--loss:0.6287\n",
      "\n",
      "Ep:11/29--Batch:2300/3832\n",
      "batch: loss_cls:0.6561--loss_regr:0.1288--loss:0.7848\n",
      "Epoch: loss_cls:0.5001--loss_regr:0.1269--loss:0.6270\n",
      "\n",
      "Ep:11/29--Batch:2400/3832\n",
      "batch: loss_cls:0.3474--loss_regr:0.0626--loss:0.4099\n",
      "Epoch: loss_cls:0.5007--loss_regr:0.1277--loss:0.6283\n",
      "\n",
      "Ep:11/29--Batch:2500/3832\n",
      "batch: loss_cls:0.4263--loss_regr:0.0886--loss:0.5149\n",
      "Epoch: loss_cls:0.4980--loss_regr:0.1263--loss:0.6243\n",
      "\n",
      "Ep:11/29--Batch:2600/3832\n",
      "batch: loss_cls:0.3599--loss_regr:1.9489--loss:2.3087\n",
      "Epoch: loss_cls:0.4995--loss_regr:0.1263--loss:0.6258\n",
      "\n",
      "Ep:11/29--Batch:2700/3832\n",
      "batch: loss_cls:0.7149--loss_regr:0.2213--loss:0.9362\n",
      "Epoch: loss_cls:0.4995--loss_regr:0.1262--loss:0.6256\n",
      "\n",
      "Ep:11/29--Batch:2800/3832\n",
      "batch: loss_cls:0.2534--loss_regr:0.0463--loss:0.2997\n",
      "Epoch: loss_cls:0.5000--loss_regr:0.1268--loss:0.6268\n",
      "\n",
      "Ep:11/29--Batch:2900/3832\n",
      "batch: loss_cls:0.4625--loss_regr:0.0711--loss:0.5335\n",
      "Epoch: loss_cls:0.5001--loss_regr:0.1266--loss:0.6267\n",
      "\n",
      "Ep:11/29--Batch:3000/3832\n",
      "batch: loss_cls:0.2889--loss_regr:0.0967--loss:0.3855\n",
      "Epoch: loss_cls:0.4990--loss_regr:0.1261--loss:0.6250\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:11/29--Batch:3100/3832\n",
      "batch: loss_cls:0.3727--loss_regr:0.1345--loss:0.5072\n",
      "Epoch: loss_cls:0.4995--loss_regr:0.1273--loss:0.6267\n",
      "\n",
      "Ep:11/29--Batch:3200/3832\n",
      "batch: loss_cls:0.3696--loss_regr:0.0925--loss:0.4621\n",
      "Epoch: loss_cls:0.5000--loss_regr:0.1271--loss:0.6270\n",
      "\n",
      "Ep:11/29--Batch:3300/3832\n",
      "batch: loss_cls:0.6404--loss_regr:0.1431--loss:0.7835\n",
      "Epoch: loss_cls:0.4997--loss_regr:0.1267--loss:0.6264\n",
      "\n",
      "Ep:11/29--Batch:3400/3832\n",
      "batch: loss_cls:0.2998--loss_regr:0.0620--loss:0.3618\n",
      "Epoch: loss_cls:0.4997--loss_regr:0.1269--loss:0.6266\n",
      "\n",
      "Ep:11/29--Batch:3500/3832\n",
      "batch: loss_cls:0.2382--loss_regr:0.0135--loss:0.2517\n",
      "Epoch: loss_cls:0.4982--loss_regr:0.1265--loss:0.6247\n",
      "\n",
      "Ep:11/29--Batch:3600/3832\n",
      "batch: loss_cls:0.8223--loss_regr:0.0593--loss:0.8815\n",
      "Epoch: loss_cls:0.4979--loss_regr:0.1265--loss:0.6244\n",
      "\n",
      "Ep:11/29--Batch:3700/3832\n",
      "batch: loss_cls:0.2538--loss_regr:0.0360--loss:0.2898\n",
      "Epoch: loss_cls:0.4971--loss_regr:0.1264--loss:0.6236\n",
      "\n",
      "Ep:11/29--Batch:3800/3832\n",
      "batch: loss_cls:0.6648--loss_regr:0.1388--loss:0.8036\n",
      "Epoch: loss_cls:0.4979--loss_regr:0.1268--loss:0.6248\n",
      "\n",
      "Epoch:11--0.4984--0.1268--0.6252\n",
      "saving to ../../checkpoints/v3_ctpn_ep11_0.4984_0.1268_0.6252.pth\n",
      "Epoch 12/30\n",
      "##################################################\n",
      "Ep:12/29--Batch:0/3832\n",
      "batch: loss_cls:0.3782--loss_regr:0.0678--loss:0.4460\n",
      "Epoch: loss_cls:0.3782--loss_regr:0.0678--loss:0.4460\n",
      "\n",
      "Ep:12/29--Batch:100/3832\n",
      "batch: loss_cls:0.6741--loss_regr:0.1137--loss:0.7878\n",
      "Epoch: loss_cls:0.5123--loss_regr:0.1241--loss:0.6365\n",
      "\n",
      "Ep:12/29--Batch:200/3832\n",
      "batch: loss_cls:0.8415--loss_regr:0.2912--loss:1.1327\n",
      "Epoch: loss_cls:0.5121--loss_regr:0.1224--loss:0.6345\n",
      "\n",
      "Ep:12/29--Batch:300/3832\n",
      "batch: loss_cls:0.7131--loss_regr:0.0705--loss:0.7836\n",
      "Epoch: loss_cls:0.5132--loss_regr:0.1273--loss:0.6404\n",
      "\n",
      "Ep:12/29--Batch:400/3832\n",
      "batch: loss_cls:0.1804--loss_regr:0.0317--loss:0.2121\n",
      "Epoch: loss_cls:0.5084--loss_regr:0.1215--loss:0.6299\n",
      "\n",
      "Ep:12/29--Batch:500/3832\n",
      "batch: loss_cls:0.2825--loss_regr:0.0369--loss:0.3194\n",
      "Epoch: loss_cls:0.4995--loss_regr:0.1193--loss:0.6188\n",
      "\n",
      "Ep:12/29--Batch:600/3832\n",
      "batch: loss_cls:0.8040--loss_regr:0.2554--loss:1.0595\n",
      "Epoch: loss_cls:0.4960--loss_regr:0.1284--loss:0.6244\n",
      "\n",
      "Ep:12/29--Batch:700/3832\n",
      "batch: loss_cls:0.6087--loss_regr:0.0831--loss:0.6918\n",
      "Epoch: loss_cls:0.4984--loss_regr:0.1270--loss:0.6254\n",
      "\n",
      "Ep:12/29--Batch:800/3832\n",
      "batch: loss_cls:0.4168--loss_regr:0.0560--loss:0.4729\n",
      "Epoch: loss_cls:0.4989--loss_regr:0.1262--loss:0.6251\n",
      "\n",
      "Ep:12/29--Batch:900/3832\n",
      "batch: loss_cls:0.5843--loss_regr:0.1420--loss:0.7262\n",
      "Epoch: loss_cls:0.5007--loss_regr:0.1223--loss:0.6230\n",
      "\n",
      "Ep:12/29--Batch:1000/3832\n",
      "batch: loss_cls:0.3097--loss_regr:0.1839--loss:0.4936\n",
      "Epoch: loss_cls:0.4960--loss_regr:0.1212--loss:0.6172\n",
      "\n",
      "Ep:12/29--Batch:1100/3832\n",
      "batch: loss_cls:0.9947--loss_regr:0.1279--loss:1.1226\n",
      "Epoch: loss_cls:0.5000--loss_regr:0.1237--loss:0.6236\n",
      "\n",
      "Ep:12/29--Batch:1200/3832\n",
      "batch: loss_cls:0.8000--loss_regr:0.1847--loss:0.9847\n",
      "Epoch: loss_cls:0.4988--loss_regr:0.1231--loss:0.6220\n",
      "\n",
      "Ep:12/29--Batch:1300/3832\n",
      "batch: loss_cls:0.3507--loss_regr:0.1104--loss:0.4611\n",
      "Epoch: loss_cls:0.4993--loss_regr:0.1226--loss:0.6219\n",
      "\n",
      "Ep:12/29--Batch:1400/3832\n",
      "batch: loss_cls:0.3266--loss_regr:0.1288--loss:0.4554\n",
      "Epoch: loss_cls:0.4961--loss_regr:0.1220--loss:0.6181\n",
      "\n",
      "Ep:12/29--Batch:1500/3832\n",
      "batch: loss_cls:0.3253--loss_regr:0.0863--loss:0.4115\n",
      "Epoch: loss_cls:0.4959--loss_regr:0.1210--loss:0.6169\n",
      "\n",
      "Ep:12/29--Batch:1600/3832\n",
      "batch: loss_cls:0.3085--loss_regr:0.0707--loss:0.3792\n",
      "Epoch: loss_cls:0.4964--loss_regr:0.1221--loss:0.6185\n",
      "\n",
      "Ep:12/29--Batch:1700/3832\n",
      "batch: loss_cls:0.6555--loss_regr:0.1351--loss:0.7906\n",
      "Epoch: loss_cls:0.4957--loss_regr:0.1231--loss:0.6187\n",
      "\n",
      "Ep:12/29--Batch:1800/3832\n",
      "batch: loss_cls:0.3245--loss_regr:0.0591--loss:0.3836\n",
      "Epoch: loss_cls:0.4934--loss_regr:0.1224--loss:0.6159\n",
      "\n",
      "Ep:12/29--Batch:1900/3832\n",
      "batch: loss_cls:0.3337--loss_regr:0.2414--loss:0.5752\n",
      "Epoch: loss_cls:0.4939--loss_regr:0.1267--loss:0.6206\n",
      "\n",
      "Ep:12/29--Batch:2000/3832\n",
      "batch: loss_cls:0.3919--loss_regr:0.1378--loss:0.5297\n",
      "Epoch: loss_cls:0.4939--loss_regr:0.1267--loss:0.6206\n",
      "\n",
      "Ep:12/29--Batch:2100/3832\n",
      "batch: loss_cls:0.3519--loss_regr:0.0356--loss:0.3874\n",
      "Epoch: loss_cls:0.4949--loss_regr:0.1259--loss:0.6208\n",
      "\n",
      "Ep:12/29--Batch:2200/3832\n",
      "batch: loss_cls:0.4632--loss_regr:0.1003--loss:0.5636\n",
      "Epoch: loss_cls:0.4931--loss_regr:0.1252--loss:0.6183\n",
      "\n",
      "Ep:12/29--Batch:2300/3832\n",
      "batch: loss_cls:0.6397--loss_regr:0.1037--loss:0.7434\n",
      "Epoch: loss_cls:0.4920--loss_regr:0.1248--loss:0.6168\n",
      "\n",
      "Ep:12/29--Batch:2400/3832\n",
      "batch: loss_cls:0.6316--loss_regr:0.0473--loss:0.6789\n",
      "Epoch: loss_cls:0.4925--loss_regr:0.1256--loss:0.6181\n",
      "\n",
      "Ep:12/29--Batch:2500/3832\n",
      "batch: loss_cls:0.3969--loss_regr:0.0948--loss:0.4917\n",
      "Epoch: loss_cls:0.4904--loss_regr:0.1243--loss:0.6146\n",
      "\n",
      "Ep:12/29--Batch:2600/3832\n",
      "batch: loss_cls:0.3517--loss_regr:1.9582--loss:2.3099\n",
      "Epoch: loss_cls:0.4918--loss_regr:0.1242--loss:0.6160\n",
      "\n",
      "Ep:12/29--Batch:2700/3832\n",
      "batch: loss_cls:0.7501--loss_regr:0.2368--loss:0.9870\n",
      "Epoch: loss_cls:0.4922--loss_regr:0.1241--loss:0.6162\n",
      "\n",
      "Ep:12/29--Batch:2800/3832\n",
      "batch: loss_cls:0.2517--loss_regr:0.0466--loss:0.2983\n",
      "Epoch: loss_cls:0.4928--loss_regr:0.1247--loss:0.6176\n",
      "\n",
      "Ep:12/29--Batch:2900/3832\n",
      "batch: loss_cls:0.4672--loss_regr:0.0715--loss:0.5387\n",
      "Epoch: loss_cls:0.4927--loss_regr:0.1245--loss:0.6172\n",
      "\n",
      "Ep:12/29--Batch:3000/3832\n",
      "batch: loss_cls:0.3357--loss_regr:0.0805--loss:0.4162\n",
      "Epoch: loss_cls:0.4913--loss_regr:0.1240--loss:0.6153\n",
      "\n",
      "Ep:12/29--Batch:3100/3832\n",
      "batch: loss_cls:0.5630--loss_regr:0.0996--loss:0.6626\n",
      "Epoch: loss_cls:0.4927--loss_regr:0.1251--loss:0.6178\n",
      "\n",
      "Ep:12/29--Batch:3200/3832\n",
      "batch: loss_cls:0.3573--loss_regr:0.0902--loss:0.4474\n",
      "Epoch: loss_cls:0.4929--loss_regr:0.1248--loss:0.6177\n",
      "\n",
      "Ep:12/29--Batch:3300/3832\n",
      "batch: loss_cls:0.6915--loss_regr:0.1243--loss:0.8158\n",
      "Epoch: loss_cls:0.4932--loss_regr:0.1244--loss:0.6176\n",
      "\n",
      "Ep:12/29--Batch:3400/3832\n",
      "batch: loss_cls:0.2941--loss_regr:0.0668--loss:0.3609\n",
      "Epoch: loss_cls:0.4932--loss_regr:0.1246--loss:0.6177\n",
      "\n",
      "Ep:12/29--Batch:3500/3832\n",
      "batch: loss_cls:0.2234--loss_regr:0.0268--loss:0.2503\n",
      "Epoch: loss_cls:0.4917--loss_regr:0.1241--loss:0.6158\n",
      "\n",
      "Ep:12/29--Batch:3600/3832\n",
      "batch: loss_cls:0.8018--loss_regr:0.0574--loss:0.8592\n",
      "Epoch: loss_cls:0.4916--loss_regr:0.1242--loss:0.6158\n",
      "\n",
      "Ep:12/29--Batch:3700/3832\n",
      "batch: loss_cls:0.2761--loss_regr:0.0424--loss:0.3184\n",
      "Epoch: loss_cls:0.4913--loss_regr:0.1241--loss:0.6155\n",
      "\n",
      "Ep:12/29--Batch:3800/3832\n",
      "batch: loss_cls:0.6447--loss_regr:0.1155--loss:0.7602\n",
      "Epoch: loss_cls:0.4920--loss_regr:0.1245--loss:0.6165\n",
      "\n",
      "Epoch:12--0.4924--0.1245--0.6169\n",
      "saving to ../../checkpoints/v3_ctpn_ep12_0.4924_0.1245_0.6169.pth\n",
      "Epoch 13/30\n",
      "##################################################\n",
      "Ep:13/29--Batch:0/3832\n",
      "batch: loss_cls:0.3748--loss_regr:0.0720--loss:0.4468\n",
      "Epoch: loss_cls:0.3748--loss_regr:0.0720--loss:0.4468\n",
      "\n",
      "Ep:13/29--Batch:100/3832\n",
      "batch: loss_cls:0.6294--loss_regr:0.1801--loss:0.8095\n",
      "Epoch: loss_cls:0.5060--loss_regr:0.1199--loss:0.6259\n",
      "\n",
      "Ep:13/29--Batch:200/3832\n",
      "batch: loss_cls:0.8515--loss_regr:0.2686--loss:1.1201\n",
      "Epoch: loss_cls:0.4954--loss_regr:0.1191--loss:0.6146\n",
      "\n",
      "Ep:13/29--Batch:300/3832\n",
      "batch: loss_cls:0.7204--loss_regr:0.0692--loss:0.7896\n",
      "Epoch: loss_cls:0.4945--loss_regr:0.1236--loss:0.6181\n",
      "\n",
      "Ep:13/29--Batch:400/3832\n",
      "batch: loss_cls:0.1724--loss_regr:0.0319--loss:0.2043\n",
      "Epoch: loss_cls:0.4888--loss_regr:0.1184--loss:0.6072\n",
      "\n",
      "Ep:13/29--Batch:500/3832\n",
      "batch: loss_cls:0.2818--loss_regr:0.0416--loss:0.3234\n",
      "Epoch: loss_cls:0.4809--loss_regr:0.1163--loss:0.5972\n",
      "\n",
      "Ep:13/29--Batch:600/3832\n",
      "batch: loss_cls:0.8050--loss_regr:0.2477--loss:1.0528\n",
      "Epoch: loss_cls:0.4768--loss_regr:0.1255--loss:0.6023\n",
      "\n",
      "Ep:13/29--Batch:700/3832\n",
      "batch: loss_cls:0.5583--loss_regr:0.0775--loss:0.6358\n",
      "Epoch: loss_cls:0.4812--loss_regr:0.1244--loss:0.6056\n",
      "\n",
      "Ep:13/29--Batch:800/3832\n",
      "batch: loss_cls:0.4132--loss_regr:0.0501--loss:0.4633\n",
      "Epoch: loss_cls:0.4832--loss_regr:0.1235--loss:0.6067\n",
      "\n",
      "Ep:13/29--Batch:900/3832\n",
      "batch: loss_cls:0.5893--loss_regr:0.1190--loss:0.7083\n",
      "Epoch: loss_cls:0.4849--loss_regr:0.1197--loss:0.6046\n",
      "\n",
      "Ep:13/29--Batch:1000/3832\n",
      "batch: loss_cls:0.3042--loss_regr:0.1732--loss:0.4773\n",
      "Epoch: loss_cls:0.4821--loss_regr:0.1188--loss:0.6009\n",
      "\n",
      "Ep:13/29--Batch:1100/3832\n",
      "batch: loss_cls:0.9751--loss_regr:0.1035--loss:1.0787\n",
      "Epoch: loss_cls:0.4860--loss_regr:0.1216--loss:0.6076\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:13/29--Batch:1200/3832\n",
      "batch: loss_cls:0.8045--loss_regr:0.1871--loss:0.9916\n",
      "Epoch: loss_cls:0.4863--loss_regr:0.1211--loss:0.6074\n",
      "\n",
      "Ep:13/29--Batch:1300/3832\n",
      "batch: loss_cls:0.3053--loss_regr:0.0902--loss:0.3955\n",
      "Epoch: loss_cls:0.4862--loss_regr:0.1207--loss:0.6069\n",
      "\n",
      "Ep:13/29--Batch:1400/3832\n",
      "batch: loss_cls:0.3389--loss_regr:0.1520--loss:0.4909\n",
      "Epoch: loss_cls:0.4840--loss_regr:0.1200--loss:0.6039\n",
      "\n",
      "Ep:13/29--Batch:1500/3832\n",
      "batch: loss_cls:0.2856--loss_regr:0.0876--loss:0.3732\n",
      "Epoch: loss_cls:0.4837--loss_regr:0.1191--loss:0.6028\n",
      "\n",
      "Ep:13/29--Batch:1600/3832\n",
      "batch: loss_cls:0.2963--loss_regr:0.0668--loss:0.3631\n",
      "Epoch: loss_cls:0.4849--loss_regr:0.1200--loss:0.6049\n",
      "\n",
      "Ep:13/29--Batch:1700/3832\n",
      "batch: loss_cls:0.6405--loss_regr:0.1439--loss:0.7844\n",
      "Epoch: loss_cls:0.4846--loss_regr:0.1208--loss:0.6054\n",
      "\n",
      "Ep:13/29--Batch:1800/3832\n",
      "batch: loss_cls:0.2801--loss_regr:0.0849--loss:0.3649\n",
      "Epoch: loss_cls:0.4833--loss_regr:0.1204--loss:0.6037\n",
      "\n",
      "Ep:13/29--Batch:1900/3832\n",
      "batch: loss_cls:0.3049--loss_regr:0.2164--loss:0.5213\n",
      "Epoch: loss_cls:0.4843--loss_regr:0.1244--loss:0.6087\n",
      "\n",
      "Ep:13/29--Batch:2000/3832\n",
      "batch: loss_cls:0.3901--loss_regr:0.1239--loss:0.5139\n",
      "Epoch: loss_cls:0.4849--loss_regr:0.1245--loss:0.6093\n",
      "\n",
      "Ep:13/29--Batch:2100/3832\n",
      "batch: loss_cls:0.3237--loss_regr:0.0367--loss:0.3603\n",
      "Epoch: loss_cls:0.4861--loss_regr:0.1237--loss:0.6099\n",
      "\n",
      "Ep:13/29--Batch:2200/3832\n",
      "batch: loss_cls:0.5788--loss_regr:0.0771--loss:0.6559\n",
      "Epoch: loss_cls:0.4845--loss_regr:0.1229--loss:0.6075\n",
      "\n",
      "Ep:13/29--Batch:2300/3832\n",
      "batch: loss_cls:0.6551--loss_regr:0.1338--loss:0.7889\n",
      "Epoch: loss_cls:0.4832--loss_regr:0.1226--loss:0.6058\n",
      "\n",
      "Ep:13/29--Batch:2400/3832\n",
      "batch: loss_cls:0.3346--loss_regr:0.0564--loss:0.3909\n",
      "Epoch: loss_cls:0.4839--loss_regr:0.1236--loss:0.6075\n",
      "\n",
      "Ep:13/29--Batch:2500/3832\n",
      "batch: loss_cls:0.3994--loss_regr:0.0923--loss:0.4916\n",
      "Epoch: loss_cls:0.4817--loss_regr:0.1224--loss:0.6041\n",
      "\n",
      "Ep:13/29--Batch:2600/3832\n",
      "batch: loss_cls:0.3534--loss_regr:2.0017--loss:2.3550\n",
      "Epoch: loss_cls:0.4828--loss_regr:0.1224--loss:0.6052\n",
      "\n",
      "Ep:13/29--Batch:2700/3832\n",
      "batch: loss_cls:0.7007--loss_regr:0.1688--loss:0.8695\n",
      "Epoch: loss_cls:0.4833--loss_regr:0.1222--loss:0.6056\n",
      "\n",
      "Ep:13/29--Batch:2800/3832\n",
      "batch: loss_cls:0.2572--loss_regr:0.0499--loss:0.3071\n",
      "Epoch: loss_cls:0.4843--loss_regr:0.1229--loss:0.6071\n",
      "\n",
      "Ep:13/29--Batch:2900/3832\n",
      "batch: loss_cls:0.4769--loss_regr:0.0734--loss:0.5502\n",
      "Epoch: loss_cls:0.4843--loss_regr:0.1226--loss:0.6069\n",
      "\n",
      "Ep:13/29--Batch:3000/3832\n",
      "batch: loss_cls:0.3320--loss_regr:0.0852--loss:0.4173\n",
      "Epoch: loss_cls:0.4832--loss_regr:0.1222--loss:0.6055\n",
      "\n",
      "Ep:13/29--Batch:3100/3832\n",
      "batch: loss_cls:0.4488--loss_regr:0.1298--loss:0.5786\n",
      "Epoch: loss_cls:0.4840--loss_regr:0.1233--loss:0.6073\n",
      "\n",
      "Ep:13/29--Batch:3200/3832\n",
      "batch: loss_cls:0.3506--loss_regr:0.0963--loss:0.4468\n",
      "Epoch: loss_cls:0.4836--loss_regr:0.1231--loss:0.6067\n",
      "\n",
      "Ep:13/29--Batch:3300/3832\n",
      "batch: loss_cls:0.6087--loss_regr:0.1311--loss:0.7398\n",
      "Epoch: loss_cls:0.4839--loss_regr:0.1227--loss:0.6066\n",
      "\n",
      "Ep:13/29--Batch:3400/3832\n",
      "batch: loss_cls:0.2771--loss_regr:0.0741--loss:0.3512\n",
      "Epoch: loss_cls:0.4837--loss_regr:0.1229--loss:0.6065\n",
      "\n",
      "Ep:13/29--Batch:3500/3832\n",
      "batch: loss_cls:0.2065--loss_regr:0.0144--loss:0.2209\n",
      "Epoch: loss_cls:0.4826--loss_regr:0.1223--loss:0.6049\n",
      "\n",
      "Ep:13/29--Batch:3600/3832\n",
      "batch: loss_cls:0.7572--loss_regr:0.0587--loss:0.8159\n",
      "Epoch: loss_cls:0.4827--loss_regr:0.1225--loss:0.6052\n",
      "\n",
      "Ep:13/29--Batch:3700/3832\n",
      "batch: loss_cls:0.2225--loss_regr:0.0347--loss:0.2571\n",
      "Epoch: loss_cls:0.4827--loss_regr:0.1224--loss:0.6051\n",
      "\n",
      "Ep:13/29--Batch:3800/3832\n",
      "batch: loss_cls:0.6458--loss_regr:0.1426--loss:0.7884\n",
      "Epoch: loss_cls:0.4838--loss_regr:0.1229--loss:0.6067\n",
      "\n",
      "Epoch:13--0.4843--0.1229--0.6071\n",
      "saving to ../../checkpoints/v3_ctpn_ep13_0.4843_0.1229_0.6071.pth\n",
      "Epoch 14/30\n",
      "##################################################\n",
      "Ep:14/29--Batch:0/3832\n",
      "batch: loss_cls:0.3500--loss_regr:0.0755--loss:0.4255\n",
      "Epoch: loss_cls:0.3500--loss_regr:0.0755--loss:0.4255\n",
      "\n",
      "Ep:14/29--Batch:100/3832\n",
      "batch: loss_cls:0.6583--loss_regr:0.1570--loss:0.8153\n",
      "Epoch: loss_cls:0.5005--loss_regr:0.1237--loss:0.6242\n",
      "\n",
      "Ep:14/29--Batch:200/3832\n",
      "batch: loss_cls:0.8232--loss_regr:0.2238--loss:1.0470\n",
      "Epoch: loss_cls:0.4935--loss_regr:0.1199--loss:0.6135\n",
      "\n",
      "Ep:14/29--Batch:300/3832\n",
      "batch: loss_cls:0.6377--loss_regr:0.0676--loss:0.7053\n",
      "Epoch: loss_cls:0.5017--loss_regr:0.1250--loss:0.6267\n",
      "\n",
      "Ep:14/29--Batch:400/3832\n",
      "batch: loss_cls:0.1757--loss_regr:0.0246--loss:0.2003\n",
      "Epoch: loss_cls:0.4918--loss_regr:0.1185--loss:0.6103\n",
      "\n",
      "Ep:14/29--Batch:500/3832\n",
      "batch: loss_cls:0.3008--loss_regr:0.0500--loss:0.3508\n",
      "Epoch: loss_cls:0.4824--loss_regr:0.1161--loss:0.5985\n",
      "\n",
      "Ep:14/29--Batch:600/3832\n",
      "batch: loss_cls:0.7986--loss_regr:0.2474--loss:1.0460\n",
      "Epoch: loss_cls:0.4782--loss_regr:0.1261--loss:0.6043\n",
      "\n",
      "Ep:14/29--Batch:700/3832\n",
      "batch: loss_cls:0.6142--loss_regr:0.0756--loss:0.6898\n",
      "Epoch: loss_cls:0.4811--loss_regr:0.1248--loss:0.6059\n",
      "\n",
      "Ep:14/29--Batch:800/3832\n",
      "batch: loss_cls:0.4243--loss_regr:0.0691--loss:0.4934\n",
      "Epoch: loss_cls:0.4817--loss_regr:0.1241--loss:0.6057\n",
      "\n",
      "Ep:14/29--Batch:900/3832\n",
      "batch: loss_cls:0.5438--loss_regr:0.1365--loss:0.6803\n",
      "Epoch: loss_cls:0.4834--loss_regr:0.1201--loss:0.6034\n",
      "\n",
      "Ep:14/29--Batch:1000/3832\n",
      "batch: loss_cls:0.4272--loss_regr:0.1351--loss:0.5623\n",
      "Epoch: loss_cls:0.4795--loss_regr:0.1188--loss:0.5983\n",
      "\n",
      "Ep:14/29--Batch:1100/3832\n",
      "batch: loss_cls:0.9726--loss_regr:0.0776--loss:1.0502\n",
      "Epoch: loss_cls:0.4850--loss_regr:0.1213--loss:0.6063\n",
      "\n",
      "Ep:14/29--Batch:1200/3832\n",
      "batch: loss_cls:0.7893--loss_regr:0.1463--loss:0.9356\n",
      "Epoch: loss_cls:0.4860--loss_regr:0.1206--loss:0.6065\n",
      "\n",
      "Ep:14/29--Batch:1300/3832\n",
      "batch: loss_cls:0.3171--loss_regr:0.0923--loss:0.4094\n",
      "Epoch: loss_cls:0.4872--loss_regr:0.1198--loss:0.6071\n",
      "\n",
      "Ep:14/29--Batch:1400/3832\n",
      "batch: loss_cls:0.3315--loss_regr:0.1498--loss:0.4813\n",
      "Epoch: loss_cls:0.4843--loss_regr:0.1190--loss:0.6033\n",
      "\n",
      "Ep:14/29--Batch:1500/3832\n",
      "batch: loss_cls:0.3027--loss_regr:0.0847--loss:0.3874\n",
      "Epoch: loss_cls:0.4840--loss_regr:0.1179--loss:0.6019\n",
      "\n",
      "Ep:14/29--Batch:1600/3832\n",
      "batch: loss_cls:0.2903--loss_regr:0.0530--loss:0.3433\n",
      "Epoch: loss_cls:0.4846--loss_regr:0.1189--loss:0.6034\n",
      "\n",
      "Ep:14/29--Batch:1700/3832\n",
      "batch: loss_cls:0.6490--loss_regr:0.1312--loss:0.7802\n",
      "Epoch: loss_cls:0.4837--loss_regr:0.1197--loss:0.6034\n",
      "\n",
      "Ep:14/29--Batch:1800/3832\n",
      "batch: loss_cls:0.2817--loss_regr:0.0712--loss:0.3530\n",
      "Epoch: loss_cls:0.4805--loss_regr:0.1191--loss:0.5997\n",
      "\n",
      "Ep:14/29--Batch:1900/3832\n",
      "batch: loss_cls:0.3112--loss_regr:0.2598--loss:0.5710\n",
      "Epoch: loss_cls:0.4808--loss_regr:0.1229--loss:0.6037\n",
      "\n",
      "Ep:14/29--Batch:2000/3832\n",
      "batch: loss_cls:0.3823--loss_regr:0.1368--loss:0.5192\n",
      "Epoch: loss_cls:0.4818--loss_regr:0.1232--loss:0.6050\n",
      "\n",
      "Ep:14/29--Batch:2100/3832\n",
      "batch: loss_cls:0.3709--loss_regr:0.0232--loss:0.3941\n",
      "Epoch: loss_cls:0.4832--loss_regr:0.1224--loss:0.6056\n",
      "\n",
      "Ep:14/29--Batch:2200/3832\n",
      "batch: loss_cls:0.5847--loss_regr:0.0727--loss:0.6574\n",
      "Epoch: loss_cls:0.4815--loss_regr:0.1217--loss:0.6032\n",
      "\n",
      "Ep:14/29--Batch:2300/3832\n",
      "batch: loss_cls:0.6310--loss_regr:0.1235--loss:0.7545\n",
      "Epoch: loss_cls:0.4804--loss_regr:0.1213--loss:0.6017\n",
      "\n",
      "Ep:14/29--Batch:2400/3832\n",
      "batch: loss_cls:0.3266--loss_regr:0.0584--loss:0.3850\n",
      "Epoch: loss_cls:0.4807--loss_regr:0.1221--loss:0.6028\n",
      "\n",
      "Ep:14/29--Batch:2500/3832\n",
      "batch: loss_cls:0.3887--loss_regr:0.0870--loss:0.4757\n",
      "Epoch: loss_cls:0.4778--loss_regr:0.1208--loss:0.5986\n",
      "\n",
      "Ep:14/29--Batch:2600/3832\n",
      "batch: loss_cls:0.3469--loss_regr:1.8911--loss:2.2380\n",
      "Epoch: loss_cls:0.4796--loss_regr:0.1209--loss:0.6005\n",
      "\n",
      "Ep:14/29--Batch:2700/3832\n",
      "batch: loss_cls:0.7385--loss_regr:0.1731--loss:0.9116\n",
      "Epoch: loss_cls:0.4800--loss_regr:0.1207--loss:0.6007\n",
      "\n",
      "Ep:14/29--Batch:2800/3832\n",
      "batch: loss_cls:0.2547--loss_regr:0.0533--loss:0.3080\n",
      "Epoch: loss_cls:0.4810--loss_regr:0.1215--loss:0.6025\n",
      "\n",
      "Ep:14/29--Batch:2900/3832\n",
      "batch: loss_cls:0.4760--loss_regr:0.0699--loss:0.5459\n",
      "Epoch: loss_cls:0.4812--loss_regr:0.1213--loss:0.6025\n",
      "\n",
      "Ep:14/29--Batch:3000/3832\n",
      "batch: loss_cls:0.2670--loss_regr:0.0903--loss:0.3574\n",
      "Epoch: loss_cls:0.4797--loss_regr:0.1208--loss:0.6005\n",
      "\n",
      "Ep:14/29--Batch:3100/3832\n",
      "batch: loss_cls:0.5783--loss_regr:0.1018--loss:0.6800\n",
      "Epoch: loss_cls:0.4806--loss_regr:0.1218--loss:0.6024\n",
      "\n",
      "Ep:14/29--Batch:3200/3832\n",
      "batch: loss_cls:0.3404--loss_regr:0.0985--loss:0.4389\n",
      "Epoch: loss_cls:0.4805--loss_regr:0.1216--loss:0.6021\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:14/29--Batch:3300/3832\n",
      "batch: loss_cls:0.6379--loss_regr:0.1156--loss:0.7535\n",
      "Epoch: loss_cls:0.4807--loss_regr:0.1212--loss:0.6019\n",
      "\n",
      "Ep:14/29--Batch:3400/3832\n",
      "batch: loss_cls:0.2762--loss_regr:0.0779--loss:0.3542\n",
      "Epoch: loss_cls:0.4802--loss_regr:0.1215--loss:0.6017\n",
      "\n",
      "Ep:14/29--Batch:3500/3832\n",
      "batch: loss_cls:0.1929--loss_regr:0.0235--loss:0.2164\n",
      "Epoch: loss_cls:0.4788--loss_regr:0.1210--loss:0.5998\n",
      "\n",
      "Ep:14/29--Batch:3600/3832\n",
      "batch: loss_cls:0.2717--loss_regr:0.0544--loss:0.3260\n",
      "Epoch: loss_cls:0.4786--loss_regr:0.1211--loss:0.5997\n",
      "\n",
      "Ep:14/29--Batch:3700/3832\n",
      "batch: loss_cls:0.2185--loss_regr:0.0385--loss:0.2570\n",
      "Epoch: loss_cls:0.4779--loss_regr:0.1210--loss:0.5989\n",
      "\n",
      "Ep:14/29--Batch:3800/3832\n",
      "batch: loss_cls:0.6253--loss_regr:0.1110--loss:0.7363\n",
      "Epoch: loss_cls:0.4782--loss_regr:0.1215--loss:0.5997\n",
      "\n",
      "Epoch:14--0.4785--0.1215--0.6000\n",
      "saving to ../../checkpoints/v3_ctpn_ep14_0.4785_0.1215_0.6000.pth\n",
      "Epoch 15/30\n",
      "##################################################\n",
      "Ep:15/29--Batch:0/3832\n",
      "batch: loss_cls:0.3817--loss_regr:0.0822--loss:0.4640\n",
      "Epoch: loss_cls:0.3817--loss_regr:0.0822--loss:0.4640\n",
      "\n",
      "Ep:15/29--Batch:100/3832\n",
      "batch: loss_cls:0.6392--loss_regr:0.1029--loss:0.7421\n",
      "Epoch: loss_cls:0.4936--loss_regr:0.1175--loss:0.6111\n",
      "\n",
      "Ep:15/29--Batch:200/3832\n",
      "batch: loss_cls:0.8200--loss_regr:0.2556--loss:1.0756\n",
      "Epoch: loss_cls:0.4952--loss_regr:0.1181--loss:0.6132\n",
      "\n",
      "Ep:15/29--Batch:300/3832\n",
      "batch: loss_cls:0.6100--loss_regr:0.0589--loss:0.6689\n",
      "Epoch: loss_cls:0.4936--loss_regr:0.1210--loss:0.6146\n",
      "\n",
      "Ep:15/29--Batch:400/3832\n",
      "batch: loss_cls:0.1664--loss_regr:0.0288--loss:0.1952\n",
      "Epoch: loss_cls:0.4916--loss_regr:0.1157--loss:0.6073\n",
      "\n",
      "Ep:15/29--Batch:500/3832\n",
      "batch: loss_cls:0.2760--loss_regr:0.0390--loss:0.3150\n",
      "Epoch: loss_cls:0.4796--loss_regr:0.1139--loss:0.5934\n",
      "\n",
      "Ep:15/29--Batch:600/3832\n",
      "batch: loss_cls:0.7867--loss_regr:0.2399--loss:1.0266\n",
      "Epoch: loss_cls:0.4746--loss_regr:0.1242--loss:0.5989\n",
      "\n",
      "Ep:15/29--Batch:700/3832\n",
      "batch: loss_cls:0.5639--loss_regr:0.0767--loss:0.6406\n",
      "Epoch: loss_cls:0.4776--loss_regr:0.1234--loss:0.6010\n",
      "\n",
      "Ep:15/29--Batch:800/3832\n",
      "batch: loss_cls:0.3638--loss_regr:0.0590--loss:0.4228\n",
      "Epoch: loss_cls:0.4790--loss_regr:0.1226--loss:0.6016\n",
      "\n",
      "Ep:15/29--Batch:900/3832\n",
      "batch: loss_cls:0.6534--loss_regr:0.1276--loss:0.7810\n",
      "Epoch: loss_cls:0.4806--loss_regr:0.1188--loss:0.5994\n",
      "\n",
      "Ep:15/29--Batch:1000/3832\n",
      "batch: loss_cls:0.4221--loss_regr:0.1264--loss:0.5485\n",
      "Epoch: loss_cls:0.4762--loss_regr:0.1176--loss:0.5939\n",
      "\n",
      "Ep:15/29--Batch:1100/3832\n",
      "batch: loss_cls:0.9216--loss_regr:0.0780--loss:0.9996\n",
      "Epoch: loss_cls:0.4807--loss_regr:0.1200--loss:0.6007\n",
      "\n",
      "Ep:15/29--Batch:1200/3832\n",
      "batch: loss_cls:0.7174--loss_regr:0.0448--loss:0.7622\n",
      "Epoch: loss_cls:0.4815--loss_regr:0.1190--loss:0.6005\n",
      "\n",
      "Ep:15/29--Batch:1300/3832\n",
      "batch: loss_cls:0.3142--loss_regr:0.0912--loss:0.4054\n",
      "Epoch: loss_cls:0.4829--loss_regr:0.1185--loss:0.6014\n",
      "\n",
      "Ep:15/29--Batch:1400/3832\n",
      "batch: loss_cls:0.2727--loss_regr:0.1336--loss:0.4063\n",
      "Epoch: loss_cls:0.4796--loss_regr:0.1177--loss:0.5973\n",
      "\n",
      "Ep:15/29--Batch:1500/3832\n",
      "batch: loss_cls:0.2925--loss_regr:0.0825--loss:0.3750\n",
      "Epoch: loss_cls:0.4795--loss_regr:0.1167--loss:0.5962\n",
      "\n",
      "Ep:15/29--Batch:1600/3832\n",
      "batch: loss_cls:0.2866--loss_regr:0.0541--loss:0.3407\n",
      "Epoch: loss_cls:0.4799--loss_regr:0.1177--loss:0.5976\n",
      "\n",
      "Ep:15/29--Batch:1700/3832\n",
      "batch: loss_cls:0.6450--loss_regr:0.1291--loss:0.7741\n",
      "Epoch: loss_cls:0.4792--loss_regr:0.1184--loss:0.5976\n",
      "\n",
      "Ep:15/29--Batch:1800/3832\n",
      "batch: loss_cls:0.2736--loss_regr:0.0827--loss:0.3563\n",
      "Epoch: loss_cls:0.4762--loss_regr:0.1180--loss:0.5942\n",
      "\n",
      "Ep:15/29--Batch:1900/3832\n",
      "batch: loss_cls:0.2759--loss_regr:0.2327--loss:0.5086\n",
      "Epoch: loss_cls:0.4770--loss_regr:0.1221--loss:0.5991\n",
      "\n",
      "Ep:15/29--Batch:2000/3832\n",
      "batch: loss_cls:0.3686--loss_regr:0.1351--loss:0.5036\n",
      "Epoch: loss_cls:0.4760--loss_regr:0.1221--loss:0.5981\n",
      "\n",
      "Ep:15/29--Batch:2100/3832\n",
      "batch: loss_cls:0.3218--loss_regr:0.0311--loss:0.3529\n",
      "Epoch: loss_cls:0.4777--loss_regr:0.1213--loss:0.5990\n",
      "\n",
      "Ep:15/29--Batch:2200/3832\n",
      "batch: loss_cls:0.4633--loss_regr:0.1006--loss:0.5638\n",
      "Epoch: loss_cls:0.4764--loss_regr:0.1206--loss:0.5971\n",
      "\n",
      "Ep:15/29--Batch:2300/3832\n",
      "batch: loss_cls:0.6139--loss_regr:0.1180--loss:0.7319\n",
      "Epoch: loss_cls:0.4754--loss_regr:0.1202--loss:0.5956\n",
      "\n",
      "Ep:15/29--Batch:2400/3832\n",
      "batch: loss_cls:0.3317--loss_regr:0.0574--loss:0.3890\n",
      "Epoch: loss_cls:0.4756--loss_regr:0.1209--loss:0.5965\n",
      "\n",
      "Ep:15/29--Batch:2500/3832\n",
      "batch: loss_cls:0.3956--loss_regr:0.0889--loss:0.4845\n",
      "Epoch: loss_cls:0.4727--loss_regr:0.1195--loss:0.5922\n",
      "\n",
      "Ep:15/29--Batch:2600/3832\n",
      "batch: loss_cls:0.3577--loss_regr:2.0000--loss:2.3578\n",
      "Epoch: loss_cls:0.4742--loss_regr:0.1195--loss:0.5937\n",
      "\n",
      "Ep:15/29--Batch:2700/3832\n",
      "batch: loss_cls:0.7345--loss_regr:0.1857--loss:0.9201\n",
      "Epoch: loss_cls:0.4744--loss_regr:0.1194--loss:0.5938\n",
      "\n",
      "Ep:15/29--Batch:2800/3832\n",
      "batch: loss_cls:0.2660--loss_regr:0.0527--loss:0.3187\n",
      "Epoch: loss_cls:0.4752--loss_regr:0.1202--loss:0.5954\n",
      "\n",
      "Ep:15/29--Batch:2900/3832\n",
      "batch: loss_cls:0.4491--loss_regr:0.0722--loss:0.5213\n",
      "Epoch: loss_cls:0.4758--loss_regr:0.1199--loss:0.5957\n",
      "\n",
      "Ep:15/29--Batch:3000/3832\n",
      "batch: loss_cls:0.3254--loss_regr:0.0786--loss:0.4040\n",
      "Epoch: loss_cls:0.4743--loss_regr:0.1195--loss:0.5938\n",
      "\n",
      "Ep:15/29--Batch:3100/3832\n",
      "batch: loss_cls:0.3982--loss_regr:0.1137--loss:0.5119\n",
      "Epoch: loss_cls:0.4754--loss_regr:0.1206--loss:0.5959\n",
      "\n",
      "Ep:15/29--Batch:3200/3832\n",
      "batch: loss_cls:0.3326--loss_regr:0.0873--loss:0.4199\n",
      "Epoch: loss_cls:0.4751--loss_regr:0.1205--loss:0.5957\n",
      "\n",
      "Ep:15/29--Batch:3300/3832\n",
      "batch: loss_cls:0.6269--loss_regr:0.1392--loss:0.7661\n",
      "Epoch: loss_cls:0.4750--loss_regr:0.1202--loss:0.5952\n",
      "\n",
      "Ep:15/29--Batch:3400/3832\n",
      "batch: loss_cls:0.2648--loss_regr:0.0711--loss:0.3359\n",
      "Epoch: loss_cls:0.4751--loss_regr:0.1203--loss:0.5954\n",
      "\n",
      "Ep:15/29--Batch:3500/3832\n",
      "batch: loss_cls:0.2109--loss_regr:0.0114--loss:0.2223\n",
      "Epoch: loss_cls:0.4737--loss_regr:0.1200--loss:0.5937\n",
      "\n",
      "Ep:15/29--Batch:3600/3832\n",
      "batch: loss_cls:0.2624--loss_regr:0.0530--loss:0.3154\n",
      "Epoch: loss_cls:0.4739--loss_regr:0.1201--loss:0.5940\n",
      "\n",
      "Ep:15/29--Batch:3700/3832\n",
      "batch: loss_cls:0.2097--loss_regr:0.0422--loss:0.2519\n",
      "Epoch: loss_cls:0.4744--loss_regr:0.1201--loss:0.5945\n",
      "\n",
      "Ep:15/29--Batch:3800/3832\n",
      "batch: loss_cls:0.6401--loss_regr:0.1281--loss:0.7682\n",
      "Epoch: loss_cls:0.4747--loss_regr:0.1206--loss:0.5953\n",
      "\n",
      "Epoch:15--0.4752--0.1206--0.5957\n",
      "saving to ../../checkpoints/v3_ctpn_ep15_0.4752_0.1206_0.5957.pth\n",
      "Epoch 16/30\n",
      "##################################################\n",
      "Ep:16/29--Batch:0/3832\n",
      "batch: loss_cls:0.3576--loss_regr:0.0750--loss:0.4326\n",
      "Epoch: loss_cls:0.3576--loss_regr:0.0750--loss:0.4326\n",
      "\n",
      "Ep:16/29--Batch:100/3832\n",
      "batch: loss_cls:0.6448--loss_regr:0.1319--loss:0.7767\n",
      "Epoch: loss_cls:0.4976--loss_regr:0.1151--loss:0.6127\n",
      "\n",
      "Ep:16/29--Batch:200/3832\n",
      "batch: loss_cls:0.7990--loss_regr:0.2479--loss:1.0469\n",
      "Epoch: loss_cls:0.4882--loss_regr:0.1155--loss:0.6037\n",
      "\n",
      "Ep:16/29--Batch:300/3832\n",
      "batch: loss_cls:0.6194--loss_regr:0.0647--loss:0.6841\n",
      "Epoch: loss_cls:0.4884--loss_regr:0.1188--loss:0.6071\n",
      "\n",
      "Ep:16/29--Batch:400/3832\n",
      "batch: loss_cls:0.1573--loss_regr:0.0376--loss:0.1949\n",
      "Epoch: loss_cls:0.4795--loss_regr:0.1133--loss:0.5928\n",
      "\n",
      "Ep:16/29--Batch:500/3832\n",
      "batch: loss_cls:0.2636--loss_regr:0.0310--loss:0.2946\n",
      "Epoch: loss_cls:0.4693--loss_regr:0.1114--loss:0.5807\n",
      "\n",
      "Ep:16/29--Batch:600/3832\n",
      "batch: loss_cls:0.7819--loss_regr:0.2354--loss:1.0173\n",
      "Epoch: loss_cls:0.4665--loss_regr:0.1204--loss:0.5869\n",
      "\n",
      "Ep:16/29--Batch:700/3832\n",
      "batch: loss_cls:0.5176--loss_regr:0.0698--loss:0.5874\n",
      "Epoch: loss_cls:0.4697--loss_regr:0.1200--loss:0.5897\n",
      "\n",
      "Ep:16/29--Batch:800/3832\n",
      "batch: loss_cls:0.4201--loss_regr:0.0543--loss:0.4744\n",
      "Epoch: loss_cls:0.4717--loss_regr:0.1191--loss:0.5909\n",
      "\n",
      "Ep:16/29--Batch:900/3832\n",
      "batch: loss_cls:0.4893--loss_regr:0.1119--loss:0.6012\n",
      "Epoch: loss_cls:0.4738--loss_regr:0.1156--loss:0.5893\n",
      "\n",
      "Ep:16/29--Batch:1000/3832\n",
      "batch: loss_cls:0.2923--loss_regr:0.1659--loss:0.4582\n",
      "Epoch: loss_cls:0.4694--loss_regr:0.1147--loss:0.5841\n",
      "\n",
      "Ep:16/29--Batch:1100/3832\n",
      "batch: loss_cls:0.5388--loss_regr:0.1042--loss:0.6429\n",
      "Epoch: loss_cls:0.4732--loss_regr:0.1173--loss:0.5905\n",
      "\n",
      "Ep:16/29--Batch:1200/3832\n",
      "batch: loss_cls:0.8088--loss_regr:0.1520--loss:0.9608\n",
      "Epoch: loss_cls:0.4726--loss_regr:0.1163--loss:0.5889\n",
      "\n",
      "Ep:16/29--Batch:1300/3832\n",
      "batch: loss_cls:0.2780--loss_regr:0.0978--loss:0.3758\n",
      "Epoch: loss_cls:0.4734--loss_regr:0.1160--loss:0.5894\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:16/29--Batch:1400/3832\n",
      "batch: loss_cls:0.2686--loss_regr:0.1227--loss:0.3913\n",
      "Epoch: loss_cls:0.4704--loss_regr:0.1154--loss:0.5857\n",
      "\n",
      "Ep:16/29--Batch:1500/3832\n",
      "batch: loss_cls:0.2670--loss_regr:0.0761--loss:0.3430\n",
      "Epoch: loss_cls:0.4707--loss_regr:0.1145--loss:0.5853\n",
      "\n",
      "Ep:16/29--Batch:1600/3832\n",
      "batch: loss_cls:0.2799--loss_regr:0.0514--loss:0.3313\n",
      "Epoch: loss_cls:0.4715--loss_regr:0.1155--loss:0.5870\n",
      "\n",
      "Ep:16/29--Batch:1700/3832\n",
      "batch: loss_cls:0.5967--loss_regr:0.1269--loss:0.7237\n",
      "Epoch: loss_cls:0.4713--loss_regr:0.1164--loss:0.5876\n",
      "\n",
      "Ep:16/29--Batch:1800/3832\n",
      "batch: loss_cls:0.2721--loss_regr:0.0694--loss:0.3415\n",
      "Epoch: loss_cls:0.4688--loss_regr:0.1159--loss:0.5847\n",
      "\n",
      "Ep:16/29--Batch:1900/3832\n",
      "batch: loss_cls:0.2976--loss_regr:0.2594--loss:0.5570\n",
      "Epoch: loss_cls:0.4689--loss_regr:0.1199--loss:0.5888\n",
      "\n",
      "Ep:16/29--Batch:2000/3832\n",
      "batch: loss_cls:0.3649--loss_regr:0.1210--loss:0.4859\n",
      "Epoch: loss_cls:0.4679--loss_regr:0.1200--loss:0.5879\n",
      "\n",
      "Ep:16/29--Batch:2100/3832\n",
      "batch: loss_cls:0.3684--loss_regr:0.0382--loss:0.4067\n",
      "Epoch: loss_cls:0.4691--loss_regr:0.1192--loss:0.5883\n",
      "\n",
      "Ep:16/29--Batch:2200/3832\n",
      "batch: loss_cls:0.4160--loss_regr:0.1030--loss:0.5190\n",
      "Epoch: loss_cls:0.4677--loss_regr:0.1184--loss:0.5861\n",
      "\n",
      "Ep:16/29--Batch:2300/3832\n",
      "batch: loss_cls:0.5783--loss_regr:0.1143--loss:0.6927\n",
      "Epoch: loss_cls:0.4672--loss_regr:0.1181--loss:0.5853\n",
      "\n",
      "Ep:16/29--Batch:2400/3832\n",
      "batch: loss_cls:0.3166--loss_regr:0.0561--loss:0.3726\n",
      "Epoch: loss_cls:0.4676--loss_regr:0.1189--loss:0.5865\n",
      "\n",
      "Ep:16/29--Batch:2500/3832\n",
      "batch: loss_cls:0.3820--loss_regr:0.0820--loss:0.4640\n",
      "Epoch: loss_cls:0.4648--loss_regr:0.1176--loss:0.5824\n",
      "\n",
      "Ep:16/29--Batch:2600/3832\n",
      "batch: loss_cls:0.3534--loss_regr:1.9439--loss:2.2973\n",
      "Epoch: loss_cls:0.4655--loss_regr:0.1176--loss:0.5832\n",
      "\n",
      "Ep:16/29--Batch:2700/3832\n",
      "batch: loss_cls:0.7532--loss_regr:0.2217--loss:0.9748\n",
      "Epoch: loss_cls:0.4659--loss_regr:0.1176--loss:0.5835\n",
      "\n",
      "Ep:16/29--Batch:2800/3832\n",
      "batch: loss_cls:0.2362--loss_regr:0.0529--loss:0.2891\n",
      "Epoch: loss_cls:0.4670--loss_regr:0.1184--loss:0.5853\n",
      "\n",
      "Ep:16/29--Batch:2900/3832\n",
      "batch: loss_cls:0.4739--loss_regr:0.0823--loss:0.5562\n",
      "Epoch: loss_cls:0.4676--loss_regr:0.1181--loss:0.5857\n",
      "\n",
      "Ep:16/29--Batch:3000/3832\n",
      "batch: loss_cls:0.3032--loss_regr:0.0685--loss:0.3716\n",
      "Epoch: loss_cls:0.4663--loss_regr:0.1177--loss:0.5840\n",
      "\n",
      "Ep:16/29--Batch:3100/3832\n",
      "batch: loss_cls:0.5839--loss_regr:0.1025--loss:0.6864\n",
      "Epoch: loss_cls:0.4672--loss_regr:0.1187--loss:0.5858\n",
      "\n",
      "Ep:16/29--Batch:3200/3832\n",
      "batch: loss_cls:0.3268--loss_regr:0.0907--loss:0.4176\n",
      "Epoch: loss_cls:0.4669--loss_regr:0.1186--loss:0.5854\n",
      "\n",
      "Ep:16/29--Batch:3300/3832\n",
      "batch: loss_cls:0.6799--loss_regr:0.1294--loss:0.8092\n",
      "Epoch: loss_cls:0.4667--loss_regr:0.1182--loss:0.5848\n",
      "\n",
      "Ep:16/29--Batch:3400/3832\n",
      "batch: loss_cls:0.2571--loss_regr:0.0689--loss:0.3260\n",
      "Epoch: loss_cls:0.4661--loss_regr:0.1185--loss:0.5845\n",
      "\n",
      "Ep:16/29--Batch:3500/3832\n",
      "batch: loss_cls:0.1809--loss_regr:0.0284--loss:0.2093\n",
      "Epoch: loss_cls:0.4650--loss_regr:0.1182--loss:0.5832\n",
      "\n",
      "Ep:16/29--Batch:3600/3832\n",
      "batch: loss_cls:0.8270--loss_regr:0.0630--loss:0.8899\n",
      "Epoch: loss_cls:0.4652--loss_regr:0.1183--loss:0.5835\n",
      "\n",
      "Ep:16/29--Batch:3700/3832\n",
      "batch: loss_cls:0.2456--loss_regr:0.0468--loss:0.2925\n",
      "Epoch: loss_cls:0.4656--loss_regr:0.1182--loss:0.5839\n",
      "\n",
      "Ep:16/29--Batch:3800/3832\n",
      "batch: loss_cls:0.7054--loss_regr:0.1308--loss:0.8363\n",
      "Epoch: loss_cls:0.4659--loss_regr:0.1187--loss:0.5846\n",
      "\n",
      "Epoch:16--0.4664--0.1186--0.5850\n",
      "saving to ../../checkpoints/v3_ctpn_ep16_0.4664_0.1186_0.5850.pth\n",
      "Epoch 17/30\n",
      "##################################################\n",
      "Ep:17/29--Batch:0/3832\n",
      "batch: loss_cls:0.3406--loss_regr:0.0817--loss:0.4223\n",
      "Epoch: loss_cls:0.3406--loss_regr:0.0817--loss:0.4223\n",
      "\n",
      "Ep:17/29--Batch:100/3832\n",
      "batch: loss_cls:0.5563--loss_regr:0.1421--loss:0.6984\n",
      "Epoch: loss_cls:0.4745--loss_regr:0.1213--loss:0.5958\n",
      "\n",
      "Ep:17/29--Batch:200/3832\n",
      "batch: loss_cls:0.8530--loss_regr:0.2955--loss:1.1485\n",
      "Epoch: loss_cls:0.4793--loss_regr:0.1181--loss:0.5973\n",
      "\n",
      "Ep:17/29--Batch:300/3832\n",
      "batch: loss_cls:0.5850--loss_regr:0.0645--loss:0.6495\n",
      "Epoch: loss_cls:0.4789--loss_regr:0.1205--loss:0.5994\n",
      "\n",
      "Ep:17/29--Batch:400/3832\n",
      "batch: loss_cls:0.1554--loss_regr:0.0311--loss:0.1865\n",
      "Epoch: loss_cls:0.4769--loss_regr:0.1142--loss:0.5911\n",
      "\n",
      "Ep:17/29--Batch:500/3832\n",
      "batch: loss_cls:0.2661--loss_regr:0.0436--loss:0.3097\n",
      "Epoch: loss_cls:0.4692--loss_regr:0.1122--loss:0.5815\n",
      "\n",
      "Ep:17/29--Batch:600/3832\n",
      "batch: loss_cls:0.8174--loss_regr:0.2344--loss:1.0518\n",
      "Epoch: loss_cls:0.4667--loss_regr:0.1221--loss:0.5888\n",
      "\n",
      "Ep:17/29--Batch:700/3832\n",
      "batch: loss_cls:0.5486--loss_regr:0.0818--loss:0.6304\n",
      "Epoch: loss_cls:0.4691--loss_regr:0.1205--loss:0.5896\n",
      "\n",
      "Ep:17/29--Batch:800/3832\n",
      "batch: loss_cls:0.3449--loss_regr:0.0511--loss:0.3961\n",
      "Epoch: loss_cls:0.4688--loss_regr:0.1194--loss:0.5881\n",
      "\n",
      "Ep:17/29--Batch:900/3832\n",
      "batch: loss_cls:0.4862--loss_regr:0.1161--loss:0.6023\n",
      "Epoch: loss_cls:0.4687--loss_regr:0.1159--loss:0.5845\n",
      "\n",
      "Ep:17/29--Batch:1000/3832\n",
      "batch: loss_cls:0.2863--loss_regr:0.1524--loss:0.4387\n",
      "Epoch: loss_cls:0.4643--loss_regr:0.1146--loss:0.5789\n",
      "\n",
      "Ep:17/29--Batch:1100/3832\n",
      "batch: loss_cls:0.5123--loss_regr:0.0910--loss:0.6033\n",
      "Epoch: loss_cls:0.4674--loss_regr:0.1168--loss:0.5842\n",
      "\n",
      "Ep:17/29--Batch:1200/3832\n",
      "batch: loss_cls:0.7253--loss_regr:0.0376--loss:0.7628\n",
      "Epoch: loss_cls:0.4676--loss_regr:0.1157--loss:0.5833\n",
      "\n",
      "Ep:17/29--Batch:1300/3832\n",
      "batch: loss_cls:0.2923--loss_regr:0.0811--loss:0.3734\n",
      "Epoch: loss_cls:0.4685--loss_regr:0.1153--loss:0.5839\n",
      "\n",
      "Ep:17/29--Batch:1400/3832\n",
      "batch: loss_cls:0.2690--loss_regr:0.1475--loss:0.4165\n",
      "Epoch: loss_cls:0.4660--loss_regr:0.1146--loss:0.5806\n",
      "\n",
      "Ep:17/29--Batch:1500/3832\n",
      "batch: loss_cls:0.2764--loss_regr:0.0780--loss:0.3544\n",
      "Epoch: loss_cls:0.4661--loss_regr:0.1136--loss:0.5797\n",
      "\n",
      "Ep:17/29--Batch:1600/3832\n",
      "batch: loss_cls:0.2764--loss_regr:0.0449--loss:0.3213\n",
      "Epoch: loss_cls:0.4671--loss_regr:0.1146--loss:0.5817\n",
      "\n",
      "Ep:17/29--Batch:1700/3832\n",
      "batch: loss_cls:0.6061--loss_regr:0.1260--loss:0.7320\n",
      "Epoch: loss_cls:0.4666--loss_regr:0.1152--loss:0.5818\n",
      "\n",
      "Ep:17/29--Batch:1800/3832\n",
      "batch: loss_cls:0.2947--loss_regr:0.0586--loss:0.3534\n",
      "Epoch: loss_cls:0.4643--loss_regr:0.1147--loss:0.5790\n",
      "\n",
      "Ep:17/29--Batch:1900/3832\n",
      "batch: loss_cls:0.3066--loss_regr:0.2637--loss:0.5702\n",
      "Epoch: loss_cls:0.4651--loss_regr:0.1186--loss:0.5837\n",
      "\n",
      "Ep:17/29--Batch:2000/3832\n",
      "batch: loss_cls:0.3666--loss_regr:0.1276--loss:0.4943\n",
      "Epoch: loss_cls:0.4637--loss_regr:0.1185--loss:0.5823\n",
      "\n",
      "Ep:17/29--Batch:2100/3832\n",
      "batch: loss_cls:0.3279--loss_regr:0.0346--loss:0.3625\n",
      "Epoch: loss_cls:0.4649--loss_regr:0.1176--loss:0.5825\n",
      "\n",
      "Ep:17/29--Batch:2200/3832\n",
      "batch: loss_cls:0.6048--loss_regr:0.0763--loss:0.6811\n",
      "Epoch: loss_cls:0.4628--loss_regr:0.1169--loss:0.5797\n",
      "\n",
      "Ep:17/29--Batch:2300/3832\n",
      "batch: loss_cls:0.6445--loss_regr:0.1145--loss:0.7590\n",
      "Epoch: loss_cls:0.4621--loss_regr:0.1166--loss:0.5787\n",
      "\n",
      "Ep:17/29--Batch:2400/3832\n",
      "batch: loss_cls:0.6009--loss_regr:0.0411--loss:0.6420\n",
      "Epoch: loss_cls:0.4631--loss_regr:0.1175--loss:0.5806\n",
      "\n",
      "Ep:17/29--Batch:2500/3832\n",
      "batch: loss_cls:0.3691--loss_regr:0.0827--loss:0.4518\n",
      "Epoch: loss_cls:0.4605--loss_regr:0.1162--loss:0.5767\n",
      "\n",
      "Ep:17/29--Batch:2600/3832\n",
      "batch: loss_cls:0.3550--loss_regr:1.9539--loss:2.3088\n",
      "Epoch: loss_cls:0.4618--loss_regr:0.1163--loss:0.5781\n",
      "\n",
      "Ep:17/29--Batch:2700/3832\n",
      "batch: loss_cls:0.7685--loss_regr:0.1967--loss:0.9651\n",
      "Epoch: loss_cls:0.4625--loss_regr:0.1163--loss:0.5788\n",
      "\n",
      "Ep:17/29--Batch:2800/3832\n",
      "batch: loss_cls:0.2433--loss_regr:0.0474--loss:0.2907\n",
      "Epoch: loss_cls:0.4635--loss_regr:0.1170--loss:0.5805\n",
      "\n",
      "Ep:17/29--Batch:2900/3832\n",
      "batch: loss_cls:0.4557--loss_regr:0.0829--loss:0.5386\n",
      "Epoch: loss_cls:0.4635--loss_regr:0.1168--loss:0.5803\n",
      "\n",
      "Ep:17/29--Batch:3000/3832\n",
      "batch: loss_cls:0.2356--loss_regr:0.0923--loss:0.3279\n",
      "Epoch: loss_cls:0.4621--loss_regr:0.1164--loss:0.5785\n",
      "\n",
      "Ep:17/29--Batch:3100/3832\n",
      "batch: loss_cls:0.5753--loss_regr:0.1022--loss:0.6775\n",
      "Epoch: loss_cls:0.4633--loss_regr:0.1174--loss:0.5807\n",
      "\n",
      "Ep:17/29--Batch:3200/3832\n",
      "batch: loss_cls:0.3264--loss_regr:0.0896--loss:0.4160\n",
      "Epoch: loss_cls:0.4626--loss_regr:0.1174--loss:0.5800\n",
      "\n",
      "Ep:17/29--Batch:3300/3832\n",
      "batch: loss_cls:0.6478--loss_regr:0.1202--loss:0.7680\n",
      "Epoch: loss_cls:0.4628--loss_regr:0.1170--loss:0.5798\n",
      "\n",
      "Ep:17/29--Batch:3400/3832\n",
      "batch: loss_cls:0.2559--loss_regr:0.0687--loss:0.3247\n",
      "Epoch: loss_cls:0.4630--loss_regr:0.1173--loss:0.5803\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:17/29--Batch:3500/3832\n",
      "batch: loss_cls:0.1837--loss_regr:0.0270--loss:0.2107\n",
      "Epoch: loss_cls:0.4617--loss_regr:0.1168--loss:0.5785\n",
      "\n",
      "Ep:17/29--Batch:3600/3832\n",
      "batch: loss_cls:0.2539--loss_regr:0.0542--loss:0.3082\n",
      "Epoch: loss_cls:0.4614--loss_regr:0.1169--loss:0.5783\n",
      "\n",
      "Ep:17/29--Batch:3700/3832\n",
      "batch: loss_cls:0.1933--loss_regr:0.0358--loss:0.2291\n",
      "Epoch: loss_cls:0.4608--loss_regr:0.1170--loss:0.5779\n",
      "\n",
      "Ep:17/29--Batch:3800/3832\n",
      "batch: loss_cls:0.5989--loss_regr:0.1137--loss:0.7126\n",
      "Epoch: loss_cls:0.4614--loss_regr:0.1174--loss:0.5788\n",
      "\n",
      "Epoch:17--0.4618--0.1173--0.5791\n",
      "saving to ../../checkpoints/v3_ctpn_ep17_0.4618_0.1173_0.5791.pth\n",
      "Epoch 18/30\n",
      "##################################################\n",
      "Ep:18/29--Batch:0/3832\n",
      "batch: loss_cls:0.3664--loss_regr:0.0868--loss:0.4532\n",
      "Epoch: loss_cls:0.3664--loss_regr:0.0868--loss:0.4532\n",
      "\n",
      "Ep:18/29--Batch:100/3832\n",
      "batch: loss_cls:0.6364--loss_regr:0.1833--loss:0.8197\n",
      "Epoch: loss_cls:0.4665--loss_regr:0.1172--loss:0.5838\n",
      "\n",
      "Ep:18/29--Batch:200/3832\n",
      "batch: loss_cls:0.7860--loss_regr:0.2449--loss:1.0309\n",
      "Epoch: loss_cls:0.4740--loss_regr:0.1163--loss:0.5903\n",
      "\n",
      "Ep:18/29--Batch:300/3832\n",
      "batch: loss_cls:0.5093--loss_regr:0.0676--loss:0.5769\n",
      "Epoch: loss_cls:0.4761--loss_regr:0.1179--loss:0.5940\n",
      "\n",
      "Ep:18/29--Batch:400/3832\n",
      "batch: loss_cls:0.1535--loss_regr:0.0331--loss:0.1865\n",
      "Epoch: loss_cls:0.4706--loss_regr:0.1110--loss:0.5816\n",
      "\n",
      "Ep:18/29--Batch:500/3832\n",
      "batch: loss_cls:0.2823--loss_regr:0.0446--loss:0.3270\n",
      "Epoch: loss_cls:0.4605--loss_regr:0.1099--loss:0.5704\n",
      "\n",
      "Ep:18/29--Batch:600/3832\n",
      "batch: loss_cls:0.7737--loss_regr:0.2288--loss:1.0025\n",
      "Epoch: loss_cls:0.4560--loss_regr:0.1192--loss:0.5751\n",
      "\n",
      "Ep:18/29--Batch:700/3832\n",
      "batch: loss_cls:0.5061--loss_regr:0.0752--loss:0.5812\n",
      "Epoch: loss_cls:0.4601--loss_regr:0.1186--loss:0.5787\n",
      "\n",
      "Ep:18/29--Batch:800/3832\n",
      "batch: loss_cls:0.4121--loss_regr:0.0563--loss:0.4684\n",
      "Epoch: loss_cls:0.4610--loss_regr:0.1175--loss:0.5785\n",
      "\n",
      "Ep:18/29--Batch:900/3832\n",
      "batch: loss_cls:0.5089--loss_regr:0.1157--loss:0.6246\n",
      "Epoch: loss_cls:0.4644--loss_regr:0.1136--loss:0.5780\n",
      "\n",
      "Ep:18/29--Batch:1000/3832\n",
      "batch: loss_cls:0.4218--loss_regr:0.1321--loss:0.5539\n",
      "Epoch: loss_cls:0.4599--loss_regr:0.1127--loss:0.5726\n",
      "\n",
      "Ep:18/29--Batch:1100/3832\n",
      "batch: loss_cls:0.4342--loss_regr:0.0842--loss:0.5184\n",
      "Epoch: loss_cls:0.4619--loss_regr:0.1152--loss:0.5771\n",
      "\n",
      "Ep:18/29--Batch:1200/3832\n",
      "batch: loss_cls:0.7220--loss_regr:0.0488--loss:0.7708\n",
      "Epoch: loss_cls:0.4628--loss_regr:0.1141--loss:0.5770\n",
      "\n",
      "Ep:18/29--Batch:1300/3832\n",
      "batch: loss_cls:0.2688--loss_regr:0.0984--loss:0.3672\n",
      "Epoch: loss_cls:0.4644--loss_regr:0.1139--loss:0.5783\n",
      "\n",
      "Ep:18/29--Batch:1400/3832\n",
      "batch: loss_cls:0.2461--loss_regr:0.1480--loss:0.3941\n",
      "Epoch: loss_cls:0.4618--loss_regr:0.1133--loss:0.5751\n",
      "\n",
      "Ep:18/29--Batch:1500/3832\n",
      "batch: loss_cls:0.2567--loss_regr:0.0695--loss:0.3262\n",
      "Epoch: loss_cls:0.4616--loss_regr:0.1124--loss:0.5741\n",
      "\n",
      "Ep:18/29--Batch:1600/3832\n",
      "batch: loss_cls:0.2747--loss_regr:0.0469--loss:0.3216\n",
      "Epoch: loss_cls:0.4630--loss_regr:0.1134--loss:0.5764\n",
      "\n",
      "Ep:18/29--Batch:1700/3832\n",
      "batch: loss_cls:0.6050--loss_regr:0.1420--loss:0.7470\n",
      "Epoch: loss_cls:0.4624--loss_regr:0.1141--loss:0.5764\n",
      "\n",
      "Ep:18/29--Batch:1800/3832\n",
      "batch: loss_cls:0.2514--loss_regr:0.0799--loss:0.3314\n",
      "Epoch: loss_cls:0.4603--loss_regr:0.1135--loss:0.5738\n",
      "\n",
      "Ep:18/29--Batch:1900/3832\n",
      "batch: loss_cls:0.2785--loss_regr:0.2326--loss:0.5112\n",
      "Epoch: loss_cls:0.4611--loss_regr:0.1173--loss:0.5784\n",
      "\n",
      "Ep:18/29--Batch:2000/3832\n",
      "batch: loss_cls:0.3667--loss_regr:0.1264--loss:0.4931\n",
      "Epoch: loss_cls:0.4610--loss_regr:0.1172--loss:0.5783\n",
      "\n",
      "Ep:18/29--Batch:2100/3832\n",
      "batch: loss_cls:0.3127--loss_regr:0.0337--loss:0.3465\n",
      "Epoch: loss_cls:0.4623--loss_regr:0.1165--loss:0.5787\n",
      "\n",
      "Ep:18/29--Batch:2200/3832\n",
      "batch: loss_cls:0.4206--loss_regr:0.1059--loss:0.5266\n",
      "Epoch: loss_cls:0.4604--loss_regr:0.1158--loss:0.5762\n",
      "\n",
      "Ep:18/29--Batch:2300/3832\n",
      "batch: loss_cls:0.6555--loss_regr:0.1214--loss:0.7768\n",
      "Epoch: loss_cls:0.4595--loss_regr:0.1153--loss:0.5748\n",
      "\n",
      "Ep:18/29--Batch:2400/3832\n",
      "batch: loss_cls:0.3153--loss_regr:0.0568--loss:0.3721\n",
      "Epoch: loss_cls:0.4605--loss_regr:0.1162--loss:0.5767\n",
      "\n",
      "Ep:18/29--Batch:2500/3832\n",
      "batch: loss_cls:0.3516--loss_regr:0.0803--loss:0.4320\n",
      "Epoch: loss_cls:0.4580--loss_regr:0.1149--loss:0.5729\n",
      "\n",
      "Ep:18/29--Batch:2600/3832\n",
      "batch: loss_cls:0.3552--loss_regr:1.8828--loss:2.2380\n",
      "Epoch: loss_cls:0.4592--loss_regr:0.1149--loss:0.5740\n",
      "\n",
      "Ep:18/29--Batch:2700/3832\n",
      "batch: loss_cls:0.7087--loss_regr:0.1481--loss:0.8567\n",
      "Epoch: loss_cls:0.4597--loss_regr:0.1148--loss:0.5744\n",
      "\n",
      "Ep:18/29--Batch:2800/3832\n",
      "batch: loss_cls:0.2655--loss_regr:0.0542--loss:0.3197\n",
      "Epoch: loss_cls:0.4608--loss_regr:0.1156--loss:0.5764\n",
      "\n",
      "Ep:18/29--Batch:2900/3832\n",
      "batch: loss_cls:0.4560--loss_regr:0.0809--loss:0.5370\n",
      "Epoch: loss_cls:0.4611--loss_regr:0.1155--loss:0.5766\n",
      "\n",
      "Ep:18/29--Batch:3000/3832\n",
      "batch: loss_cls:0.2967--loss_regr:0.0688--loss:0.3655\n",
      "Epoch: loss_cls:0.4598--loss_regr:0.1151--loss:0.5749\n",
      "\n",
      "Ep:18/29--Batch:3100/3832\n",
      "batch: loss_cls:0.5562--loss_regr:0.0974--loss:0.6536\n",
      "Epoch: loss_cls:0.4612--loss_regr:0.1161--loss:0.5773\n",
      "\n",
      "Ep:18/29--Batch:3200/3832\n",
      "batch: loss_cls:0.3195--loss_regr:0.0850--loss:0.4045\n",
      "Epoch: loss_cls:0.4602--loss_regr:0.1160--loss:0.5762\n",
      "\n",
      "Ep:18/29--Batch:3300/3832\n",
      "batch: loss_cls:0.6992--loss_regr:0.1205--loss:0.8197\n",
      "Epoch: loss_cls:0.4606--loss_regr:0.1157--loss:0.5763\n",
      "\n",
      "Ep:18/29--Batch:3400/3832\n",
      "batch: loss_cls:0.2493--loss_regr:0.0564--loss:0.3058\n",
      "Epoch: loss_cls:0.4606--loss_regr:0.1159--loss:0.5765\n",
      "\n",
      "Ep:18/29--Batch:3500/3832\n",
      "batch: loss_cls:0.1960--loss_regr:0.0161--loss:0.2121\n",
      "Epoch: loss_cls:0.4594--loss_regr:0.1157--loss:0.5751\n",
      "\n",
      "Ep:18/29--Batch:3600/3832\n",
      "batch: loss_cls:0.7631--loss_regr:0.0623--loss:0.8255\n",
      "Epoch: loss_cls:0.4596--loss_regr:0.1158--loss:0.5754\n",
      "\n",
      "Ep:18/29--Batch:3700/3832\n",
      "batch: loss_cls:0.1958--loss_regr:0.0411--loss:0.2369\n",
      "Epoch: loss_cls:0.4599--loss_regr:0.1158--loss:0.5758\n",
      "\n",
      "Ep:18/29--Batch:3800/3832\n",
      "batch: loss_cls:0.6452--loss_regr:0.1034--loss:0.7485\n",
      "Epoch: loss_cls:0.4600--loss_regr:0.1163--loss:0.5763\n",
      "\n",
      "Epoch:18--0.4605--0.1162--0.5767\n",
      "saving to ../../checkpoints/v3_ctpn_ep18_0.4605_0.1162_0.5767.pth\n",
      "Epoch 19/30\n",
      "##################################################\n",
      "Ep:19/29--Batch:0/3832\n",
      "batch: loss_cls:0.3499--loss_regr:0.0835--loss:0.4334\n",
      "Epoch: loss_cls:0.3499--loss_regr:0.0835--loss:0.4334\n",
      "\n",
      "Ep:19/29--Batch:100/3832\n",
      "batch: loss_cls:0.6316--loss_regr:0.1912--loss:0.8228\n",
      "Epoch: loss_cls:0.4700--loss_regr:0.1164--loss:0.5864\n",
      "\n",
      "Ep:19/29--Batch:200/3832\n",
      "batch: loss_cls:0.7723--loss_regr:0.2495--loss:1.0218\n",
      "Epoch: loss_cls:0.4665--loss_regr:0.1140--loss:0.5806\n",
      "\n",
      "Ep:19/29--Batch:300/3832\n",
      "batch: loss_cls:0.9547--loss_regr:0.0802--loss:1.0349\n",
      "Epoch: loss_cls:0.4682--loss_regr:0.1155--loss:0.5837\n",
      "\n",
      "Ep:19/29--Batch:400/3832\n",
      "batch: loss_cls:0.1586--loss_regr:0.0307--loss:0.1893\n",
      "Epoch: loss_cls:0.4646--loss_regr:0.1096--loss:0.5742\n",
      "\n",
      "Ep:19/29--Batch:500/3832\n",
      "batch: loss_cls:0.2522--loss_regr:0.0403--loss:0.2924\n",
      "Epoch: loss_cls:0.4561--loss_regr:0.1079--loss:0.5640\n",
      "\n",
      "Ep:19/29--Batch:600/3832\n",
      "batch: loss_cls:0.7859--loss_regr:0.2272--loss:1.0131\n",
      "Epoch: loss_cls:0.4527--loss_regr:0.1168--loss:0.5695\n",
      "\n",
      "Ep:19/29--Batch:700/3832\n",
      "batch: loss_cls:0.5640--loss_regr:0.0725--loss:0.6366\n",
      "Epoch: loss_cls:0.4572--loss_regr:0.1163--loss:0.5734\n",
      "\n",
      "Ep:19/29--Batch:800/3832\n",
      "batch: loss_cls:0.4332--loss_regr:0.0625--loss:0.4957\n",
      "Epoch: loss_cls:0.4573--loss_regr:0.1152--loss:0.5725\n",
      "\n",
      "Ep:19/29--Batch:900/3832\n",
      "batch: loss_cls:0.4253--loss_regr:0.1119--loss:0.5371\n",
      "Epoch: loss_cls:0.4579--loss_regr:0.1117--loss:0.5695\n",
      "\n",
      "Ep:19/29--Batch:1000/3832\n",
      "batch: loss_cls:0.4218--loss_regr:0.1226--loss:0.5443\n",
      "Epoch: loss_cls:0.4531--loss_regr:0.1106--loss:0.5638\n",
      "\n",
      "Ep:19/29--Batch:1100/3832\n",
      "batch: loss_cls:0.4258--loss_regr:0.0828--loss:0.5087\n",
      "Epoch: loss_cls:0.4559--loss_regr:0.1128--loss:0.5687\n",
      "\n",
      "Ep:19/29--Batch:1200/3832\n",
      "batch: loss_cls:0.8087--loss_regr:0.1887--loss:0.9974\n",
      "Epoch: loss_cls:0.4554--loss_regr:0.1115--loss:0.5670\n",
      "\n",
      "Ep:19/29--Batch:1300/3832\n",
      "batch: loss_cls:0.2558--loss_regr:0.1043--loss:0.3600\n",
      "Epoch: loss_cls:0.4568--loss_regr:0.1114--loss:0.5683\n",
      "\n",
      "Ep:19/29--Batch:1400/3832\n",
      "batch: loss_cls:0.2599--loss_regr:0.1518--loss:0.4117\n",
      "Epoch: loss_cls:0.4536--loss_regr:0.1108--loss:0.5644\n",
      "\n",
      "Ep:19/29--Batch:1500/3832\n",
      "batch: loss_cls:0.2716--loss_regr:0.0680--loss:0.3397\n",
      "Epoch: loss_cls:0.4532--loss_regr:0.1100--loss:0.5632\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:19/29--Batch:1600/3832\n",
      "batch: loss_cls:0.2729--loss_regr:0.0555--loss:0.3284\n",
      "Epoch: loss_cls:0.4548--loss_regr:0.1110--loss:0.5658\n",
      "\n",
      "Ep:19/29--Batch:1700/3832\n",
      "batch: loss_cls:0.6079--loss_regr:0.1493--loss:0.7573\n",
      "Epoch: loss_cls:0.4540--loss_regr:0.1116--loss:0.5656\n",
      "\n",
      "Ep:19/29--Batch:1800/3832\n",
      "batch: loss_cls:0.2808--loss_regr:0.0562--loss:0.3370\n",
      "Epoch: loss_cls:0.4517--loss_regr:0.1111--loss:0.5628\n",
      "\n",
      "Ep:19/29--Batch:1900/3832\n",
      "batch: loss_cls:0.2622--loss_regr:0.2260--loss:0.4882\n",
      "Epoch: loss_cls:0.4524--loss_regr:0.1145--loss:0.5669\n",
      "\n",
      "Ep:19/29--Batch:2000/3832\n",
      "batch: loss_cls:0.3490--loss_regr:0.1176--loss:0.4666\n",
      "Epoch: loss_cls:0.4509--loss_regr:0.1145--loss:0.5654\n",
      "\n",
      "Ep:19/29--Batch:2100/3832\n",
      "batch: loss_cls:0.3529--loss_regr:0.0365--loss:0.3894\n",
      "Epoch: loss_cls:0.4523--loss_regr:0.1138--loss:0.5661\n",
      "\n",
      "Ep:19/29--Batch:2200/3832\n",
      "batch: loss_cls:0.5683--loss_regr:0.0723--loss:0.6405\n",
      "Epoch: loss_cls:0.4509--loss_regr:0.1132--loss:0.5640\n",
      "\n",
      "Ep:19/29--Batch:2300/3832\n",
      "batch: loss_cls:0.6305--loss_regr:0.1146--loss:0.7451\n",
      "Epoch: loss_cls:0.4504--loss_regr:0.1129--loss:0.5633\n",
      "\n",
      "Ep:19/29--Batch:2400/3832\n",
      "batch: loss_cls:0.5867--loss_regr:0.0421--loss:0.6288\n",
      "Epoch: loss_cls:0.4516--loss_regr:0.1136--loss:0.5652\n",
      "\n",
      "Ep:19/29--Batch:2500/3832\n",
      "batch: loss_cls:0.3424--loss_regr:0.0872--loss:0.4296\n",
      "Epoch: loss_cls:0.4490--loss_regr:0.1125--loss:0.5615\n",
      "\n",
      "Ep:19/29--Batch:2600/3832\n",
      "batch: loss_cls:0.3522--loss_regr:1.8358--loss:2.1880\n",
      "Epoch: loss_cls:0.4500--loss_regr:0.1127--loss:0.5627\n",
      "\n",
      "Ep:19/29--Batch:2700/3832\n",
      "batch: loss_cls:0.7813--loss_regr:0.1842--loss:0.9655\n",
      "Epoch: loss_cls:0.4506--loss_regr:0.1126--loss:0.5633\n",
      "\n",
      "Ep:19/29--Batch:2800/3832\n",
      "batch: loss_cls:0.2368--loss_regr:0.0574--loss:0.2942\n",
      "Epoch: loss_cls:0.4517--loss_regr:0.1135--loss:0.5652\n",
      "\n",
      "Ep:19/29--Batch:2900/3832\n",
      "batch: loss_cls:0.4884--loss_regr:0.0814--loss:0.5699\n",
      "Epoch: loss_cls:0.4526--loss_regr:0.1134--loss:0.5661\n",
      "\n",
      "Ep:19/29--Batch:3000/3832\n",
      "batch: loss_cls:0.2866--loss_regr:0.0623--loss:0.3489\n",
      "Epoch: loss_cls:0.4516--loss_regr:0.1130--loss:0.5645\n",
      "\n",
      "Ep:19/29--Batch:3100/3832\n",
      "batch: loss_cls:0.3501--loss_regr:0.1294--loss:0.4795\n",
      "Epoch: loss_cls:0.4524--loss_regr:0.1140--loss:0.5664\n",
      "\n",
      "Ep:19/29--Batch:3200/3832\n",
      "batch: loss_cls:0.3179--loss_regr:0.0956--loss:0.4135\n",
      "Epoch: loss_cls:0.4524--loss_regr:0.1139--loss:0.5663\n",
      "\n",
      "Ep:19/29--Batch:3300/3832\n",
      "batch: loss_cls:0.6612--loss_regr:0.1281--loss:0.7893\n",
      "Epoch: loss_cls:0.4529--loss_regr:0.1136--loss:0.5665\n",
      "\n",
      "Ep:19/29--Batch:3400/3832\n",
      "batch: loss_cls:0.2369--loss_regr:0.0577--loss:0.2946\n",
      "Epoch: loss_cls:0.4524--loss_regr:0.1140--loss:0.5664\n",
      "\n",
      "Ep:19/29--Batch:3500/3832\n",
      "batch: loss_cls:0.1885--loss_regr:0.0183--loss:0.2068\n",
      "Epoch: loss_cls:0.4509--loss_regr:0.1136--loss:0.5645\n",
      "\n",
      "Ep:19/29--Batch:3600/3832\n",
      "batch: loss_cls:0.7535--loss_regr:0.0579--loss:0.8114\n",
      "Epoch: loss_cls:0.4510--loss_regr:0.1138--loss:0.5648\n",
      "\n",
      "Ep:19/29--Batch:3700/3832\n",
      "batch: loss_cls:0.2208--loss_regr:0.0415--loss:0.2624\n",
      "Epoch: loss_cls:0.4512--loss_regr:0.1139--loss:0.5652\n",
      "\n",
      "Ep:19/29--Batch:3800/3832\n",
      "batch: loss_cls:0.6316--loss_regr:0.1150--loss:0.7466\n",
      "Epoch: loss_cls:0.4516--loss_regr:0.1143--loss:0.5658\n",
      "\n",
      "Epoch:19--0.4519--0.1142--0.5662\n",
      "saving to ../../checkpoints/v3_ctpn_ep19_0.4519_0.1142_0.5662.pth\n",
      "Epoch 20/30\n",
      "##################################################\n",
      "Ep:20/29--Batch:0/3832\n",
      "batch: loss_cls:0.3350--loss_regr:0.0742--loss:0.4092\n",
      "Epoch: loss_cls:0.3350--loss_regr:0.0742--loss:0.4092\n",
      "\n",
      "Ep:20/29--Batch:100/3832\n",
      "batch: loss_cls:0.6794--loss_regr:0.1093--loss:0.7887\n",
      "Epoch: loss_cls:0.4556--loss_regr:0.1118--loss:0.5674\n",
      "\n",
      "Ep:20/29--Batch:200/3832\n",
      "batch: loss_cls:0.7902--loss_regr:0.2634--loss:1.0536\n",
      "Epoch: loss_cls:0.4542--loss_regr:0.1088--loss:0.5630\n",
      "\n",
      "Ep:20/29--Batch:300/3832\n",
      "batch: loss_cls:0.5577--loss_regr:0.0677--loss:0.6255\n",
      "Epoch: loss_cls:0.4557--loss_regr:0.1112--loss:0.5669\n",
      "\n",
      "Ep:20/29--Batch:400/3832\n",
      "batch: loss_cls:0.1539--loss_regr:0.0230--loss:0.1769\n",
      "Epoch: loss_cls:0.4546--loss_regr:0.1054--loss:0.5600\n",
      "\n",
      "Ep:20/29--Batch:500/3832\n",
      "batch: loss_cls:0.2571--loss_regr:0.0381--loss:0.2952\n",
      "Epoch: loss_cls:0.4449--loss_regr:0.1049--loss:0.5498\n",
      "\n",
      "Ep:20/29--Batch:600/3832\n",
      "batch: loss_cls:0.7488--loss_regr:0.2222--loss:0.9710\n",
      "Epoch: loss_cls:0.4392--loss_regr:0.1136--loss:0.5529\n",
      "\n",
      "Ep:20/29--Batch:700/3832\n",
      "batch: loss_cls:0.5594--loss_regr:0.0789--loss:0.6383\n",
      "Epoch: loss_cls:0.4438--loss_regr:0.1127--loss:0.5565\n",
      "\n",
      "Ep:20/29--Batch:800/3832\n",
      "batch: loss_cls:0.3281--loss_regr:0.0720--loss:0.4001\n",
      "Epoch: loss_cls:0.4465--loss_regr:0.1118--loss:0.5583\n",
      "\n",
      "Ep:20/29--Batch:900/3832\n",
      "batch: loss_cls:0.4403--loss_regr:0.0994--loss:0.5397\n",
      "Epoch: loss_cls:0.4483--loss_regr:0.1086--loss:0.5569\n",
      "\n",
      "Ep:20/29--Batch:1000/3832\n",
      "batch: loss_cls:0.4082--loss_regr:0.1265--loss:0.5346\n",
      "Epoch: loss_cls:0.4440--loss_regr:0.1078--loss:0.5518\n",
      "\n",
      "Ep:20/29--Batch:1100/3832\n",
      "batch: loss_cls:1.1853--loss_regr:0.0700--loss:1.2553\n",
      "Epoch: loss_cls:0.4498--loss_regr:0.1107--loss:0.5604\n",
      "\n",
      "Ep:20/29--Batch:1200/3832\n",
      "batch: loss_cls:0.8196--loss_regr:0.1576--loss:0.9772\n",
      "Epoch: loss_cls:0.4490--loss_regr:0.1096--loss:0.5586\n",
      "\n",
      "Ep:20/29--Batch:1300/3832\n",
      "batch: loss_cls:0.2669--loss_regr:0.1000--loss:0.3669\n",
      "Epoch: loss_cls:0.4509--loss_regr:0.1094--loss:0.5602\n",
      "\n",
      "Ep:20/29--Batch:1400/3832\n",
      "batch: loss_cls:0.2842--loss_regr:0.1530--loss:0.4372\n",
      "Epoch: loss_cls:0.4480--loss_regr:0.1087--loss:0.5567\n",
      "\n",
      "Ep:20/29--Batch:1500/3832\n",
      "batch: loss_cls:0.2203--loss_regr:0.0706--loss:0.2909\n",
      "Epoch: loss_cls:0.4485--loss_regr:0.1078--loss:0.5563\n",
      "\n",
      "Ep:20/29--Batch:1600/3832\n",
      "batch: loss_cls:0.2588--loss_regr:0.0347--loss:0.2935\n",
      "Epoch: loss_cls:0.4492--loss_regr:0.1084--loss:0.5577\n",
      "\n",
      "Ep:20/29--Batch:1700/3832\n",
      "batch: loss_cls:0.5394--loss_regr:0.1159--loss:0.6552\n",
      "Epoch: loss_cls:0.4478--loss_regr:0.1092--loss:0.5570\n",
      "\n",
      "Ep:20/29--Batch:1800/3832\n",
      "batch: loss_cls:0.2947--loss_regr:0.0623--loss:0.3569\n",
      "Epoch: loss_cls:0.4451--loss_regr:0.1087--loss:0.5538\n",
      "\n",
      "Ep:20/29--Batch:1900/3832\n",
      "batch: loss_cls:0.2990--loss_regr:0.2581--loss:0.5571\n",
      "Epoch: loss_cls:0.4460--loss_regr:0.1121--loss:0.5581\n",
      "\n",
      "Ep:20/29--Batch:2000/3832\n",
      "batch: loss_cls:0.3603--loss_regr:0.1104--loss:0.4707\n",
      "Epoch: loss_cls:0.4466--loss_regr:0.1122--loss:0.5588\n",
      "\n",
      "Ep:20/29--Batch:2100/3832\n",
      "batch: loss_cls:0.2964--loss_regr:0.0321--loss:0.3285\n",
      "Epoch: loss_cls:0.4475--loss_regr:0.1114--loss:0.5589\n",
      "\n",
      "Ep:20/29--Batch:2200/3832\n",
      "batch: loss_cls:0.4211--loss_regr:0.1004--loss:0.5215\n",
      "Epoch: loss_cls:0.4460--loss_regr:0.1108--loss:0.5568\n",
      "\n",
      "Ep:20/29--Batch:2300/3832\n",
      "batch: loss_cls:0.6746--loss_regr:0.1258--loss:0.8004\n",
      "Epoch: loss_cls:0.4457--loss_regr:0.1105--loss:0.5561\n",
      "\n",
      "Ep:20/29--Batch:2400/3832\n",
      "batch: loss_cls:0.6140--loss_regr:0.0369--loss:0.6509\n",
      "Epoch: loss_cls:0.4466--loss_regr:0.1112--loss:0.5578\n",
      "\n",
      "Ep:20/29--Batch:2500/3832\n",
      "batch: loss_cls:0.4222--loss_regr:0.0966--loss:0.5188\n",
      "Epoch: loss_cls:0.4432--loss_regr:0.1100--loss:0.5532\n",
      "\n",
      "Ep:20/29--Batch:2600/3832\n",
      "batch: loss_cls:0.3592--loss_regr:1.5994--loss:1.9586\n",
      "Epoch: loss_cls:0.4446--loss_regr:0.1100--loss:0.5546\n",
      "\n",
      "Ep:20/29--Batch:2700/3832\n",
      "batch: loss_cls:0.7889--loss_regr:0.2061--loss:0.9949\n",
      "Epoch: loss_cls:0.4448--loss_regr:0.1099--loss:0.5546\n",
      "\n",
      "Ep:20/29--Batch:2800/3832\n",
      "batch: loss_cls:0.2155--loss_regr:0.0430--loss:0.2585\n",
      "Epoch: loss_cls:0.4453--loss_regr:0.1106--loss:0.5560\n",
      "\n",
      "Ep:20/29--Batch:2900/3832\n",
      "batch: loss_cls:0.4517--loss_regr:0.0657--loss:0.5175\n",
      "Epoch: loss_cls:0.4460--loss_regr:0.1105--loss:0.5565\n",
      "\n",
      "Ep:20/29--Batch:3000/3832\n",
      "batch: loss_cls:0.2667--loss_regr:0.0557--loss:0.3223\n",
      "Epoch: loss_cls:0.4446--loss_regr:0.1101--loss:0.5547\n",
      "\n",
      "Ep:20/29--Batch:3100/3832\n",
      "batch: loss_cls:0.4011--loss_regr:0.1435--loss:0.5446\n",
      "Epoch: loss_cls:0.4456--loss_regr:0.1110--loss:0.5566\n",
      "\n",
      "Ep:20/29--Batch:3200/3832\n",
      "batch: loss_cls:0.3087--loss_regr:0.0892--loss:0.3979\n",
      "Epoch: loss_cls:0.4450--loss_regr:0.1107--loss:0.5558\n",
      "\n",
      "Ep:20/29--Batch:3300/3832\n",
      "batch: loss_cls:0.6666--loss_regr:0.1127--loss:0.7793\n",
      "Epoch: loss_cls:0.4453--loss_regr:0.1105--loss:0.5558\n",
      "\n",
      "Ep:20/29--Batch:3400/3832\n",
      "batch: loss_cls:0.2375--loss_regr:0.0568--loss:0.2943\n",
      "Epoch: loss_cls:0.4450--loss_regr:0.1108--loss:0.5557\n",
      "\n",
      "Ep:20/29--Batch:3500/3832\n",
      "batch: loss_cls:0.2764--loss_regr:0.0115--loss:0.2879\n",
      "Epoch: loss_cls:0.4438--loss_regr:0.1104--loss:0.5542\n",
      "\n",
      "Ep:20/29--Batch:3600/3832\n",
      "batch: loss_cls:0.2431--loss_regr:0.0499--loss:0.2930\n",
      "Epoch: loss_cls:0.4440--loss_regr:0.1105--loss:0.5545\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:20/29--Batch:3700/3832\n",
      "batch: loss_cls:0.2646--loss_regr:0.0577--loss:0.3224\n",
      "Epoch: loss_cls:0.4438--loss_regr:0.1104--loss:0.5542\n",
      "\n",
      "Ep:20/29--Batch:3800/3832\n",
      "batch: loss_cls:0.5413--loss_regr:0.1105--loss:0.6517\n",
      "Epoch: loss_cls:0.4441--loss_regr:0.1107--loss:0.5548\n",
      "\n",
      "Epoch:20--0.4444--0.1107--0.5551\n",
      "saving to ../../checkpoints/v3_ctpn_ep20_0.4444_0.1107_0.5551.pth\n",
      "Epoch 21/30\n",
      "##################################################\n",
      "Ep:21/29--Batch:0/3832\n",
      "batch: loss_cls:0.2765--loss_regr:0.0778--loss:0.3543\n",
      "Epoch: loss_cls:0.2765--loss_regr:0.0778--loss:0.3543\n",
      "\n",
      "Ep:21/29--Batch:100/3832\n",
      "batch: loss_cls:0.6547--loss_regr:0.1912--loss:0.8459\n",
      "Epoch: loss_cls:0.4621--loss_regr:0.1131--loss:0.5752\n",
      "\n",
      "Ep:21/29--Batch:200/3832\n",
      "batch: loss_cls:0.7900--loss_regr:0.2397--loss:1.0297\n",
      "Epoch: loss_cls:0.4490--loss_regr:0.1078--loss:0.5568\n",
      "\n",
      "Ep:21/29--Batch:300/3832\n",
      "batch: loss_cls:0.7354--loss_regr:0.0581--loss:0.7935\n",
      "Epoch: loss_cls:0.4514--loss_regr:0.1080--loss:0.5595\n",
      "\n",
      "Ep:21/29--Batch:400/3832\n",
      "batch: loss_cls:0.1449--loss_regr:0.0285--loss:0.1734\n",
      "Epoch: loss_cls:0.4476--loss_regr:0.1031--loss:0.5506\n",
      "\n",
      "Ep:21/29--Batch:500/3832\n",
      "batch: loss_cls:0.2477--loss_regr:0.0407--loss:0.2884\n",
      "Epoch: loss_cls:0.4370--loss_regr:0.1018--loss:0.5389\n",
      "\n",
      "Ep:21/29--Batch:600/3832\n",
      "batch: loss_cls:0.7432--loss_regr:0.2172--loss:0.9604\n",
      "Epoch: loss_cls:0.4319--loss_regr:0.1122--loss:0.5440\n",
      "\n",
      "Ep:21/29--Batch:700/3832\n",
      "batch: loss_cls:0.5504--loss_regr:0.0786--loss:0.6290\n",
      "Epoch: loss_cls:0.4367--loss_regr:0.1119--loss:0.5486\n",
      "\n",
      "Ep:21/29--Batch:800/3832\n",
      "batch: loss_cls:0.3022--loss_regr:0.0603--loss:0.3625\n",
      "Epoch: loss_cls:0.4385--loss_regr:0.1110--loss:0.5495\n",
      "\n",
      "Ep:21/29--Batch:900/3832\n",
      "batch: loss_cls:0.4518--loss_regr:0.1001--loss:0.5519\n",
      "Epoch: loss_cls:0.4425--loss_regr:0.1074--loss:0.5499\n",
      "\n",
      "Ep:21/29--Batch:1000/3832\n",
      "batch: loss_cls:0.2701--loss_regr:0.1424--loss:0.4125\n",
      "Epoch: loss_cls:0.4387--loss_regr:0.1065--loss:0.5452\n",
      "\n",
      "Ep:21/29--Batch:1100/3832\n",
      "batch: loss_cls:1.1601--loss_regr:0.0690--loss:1.2291\n",
      "Epoch: loss_cls:0.4419--loss_regr:0.1094--loss:0.5513\n",
      "\n",
      "Ep:21/29--Batch:1200/3832\n",
      "batch: loss_cls:0.7214--loss_regr:0.0393--loss:0.7607\n",
      "Epoch: loss_cls:0.4430--loss_regr:0.1080--loss:0.5510\n",
      "\n",
      "Ep:21/29--Batch:1300/3832\n",
      "batch: loss_cls:0.2308--loss_regr:0.1001--loss:0.3309\n",
      "Epoch: loss_cls:0.4443--loss_regr:0.1079--loss:0.5522\n",
      "\n",
      "Ep:21/29--Batch:1400/3832\n",
      "batch: loss_cls:0.2574--loss_regr:0.1280--loss:0.3854\n",
      "Epoch: loss_cls:0.4419--loss_regr:0.1074--loss:0.5493\n",
      "\n",
      "Ep:21/29--Batch:1500/3832\n",
      "batch: loss_cls:0.2203--loss_regr:0.0562--loss:0.2765\n",
      "Epoch: loss_cls:0.4423--loss_regr:0.1067--loss:0.5491\n",
      "\n",
      "Ep:21/29--Batch:1600/3832\n",
      "batch: loss_cls:0.2510--loss_regr:0.0342--loss:0.2852\n",
      "Epoch: loss_cls:0.4432--loss_regr:0.1073--loss:0.5504\n",
      "\n",
      "Ep:21/29--Batch:1700/3832\n",
      "batch: loss_cls:0.6860--loss_regr:0.1336--loss:0.8195\n",
      "Epoch: loss_cls:0.4423--loss_regr:0.1081--loss:0.5504\n",
      "\n",
      "Ep:21/29--Batch:1800/3832\n",
      "batch: loss_cls:0.2964--loss_regr:0.0622--loss:0.3586\n",
      "Epoch: loss_cls:0.4387--loss_regr:0.1078--loss:0.5464\n",
      "\n",
      "Ep:21/29--Batch:1900/3832\n",
      "batch: loss_cls:0.2576--loss_regr:0.2257--loss:0.4833\n",
      "Epoch: loss_cls:0.4389--loss_regr:0.1115--loss:0.5505\n",
      "\n",
      "Ep:21/29--Batch:2000/3832\n",
      "batch: loss_cls:0.3424--loss_regr:0.1152--loss:0.4575\n",
      "Epoch: loss_cls:0.4397--loss_regr:0.1114--loss:0.5511\n",
      "\n",
      "Ep:21/29--Batch:2100/3832\n",
      "batch: loss_cls:0.2998--loss_regr:0.0281--loss:0.3279\n",
      "Epoch: loss_cls:0.4412--loss_regr:0.1107--loss:0.5518\n",
      "\n",
      "Ep:21/29--Batch:2200/3832\n",
      "batch: loss_cls:0.4194--loss_regr:0.1010--loss:0.5205\n",
      "Epoch: loss_cls:0.4398--loss_regr:0.1100--loss:0.5498\n",
      "\n",
      "Ep:21/29--Batch:2300/3832\n",
      "batch: loss_cls:0.7172--loss_regr:0.1105--loss:0.8277\n",
      "Epoch: loss_cls:0.4397--loss_regr:0.1096--loss:0.5493\n",
      "\n",
      "Ep:21/29--Batch:2400/3832\n",
      "batch: loss_cls:0.2834--loss_regr:0.0549--loss:0.3383\n",
      "Epoch: loss_cls:0.4405--loss_regr:0.1104--loss:0.5509\n",
      "\n",
      "Ep:21/29--Batch:2500/3832\n",
      "batch: loss_cls:0.4409--loss_regr:0.0977--loss:0.5386\n",
      "Epoch: loss_cls:0.4373--loss_regr:0.1092--loss:0.5465\n",
      "\n",
      "Ep:21/29--Batch:2600/3832\n",
      "batch: loss_cls:0.3597--loss_regr:1.5681--loss:1.9278\n",
      "Epoch: loss_cls:0.4385--loss_regr:0.1091--loss:0.5476\n",
      "\n",
      "Ep:21/29--Batch:2700/3832\n",
      "batch: loss_cls:0.7704--loss_regr:0.1891--loss:0.9595\n",
      "Epoch: loss_cls:0.4388--loss_regr:0.1091--loss:0.5479\n",
      "\n",
      "Ep:21/29--Batch:2800/3832\n",
      "batch: loss_cls:0.2081--loss_regr:0.0448--loss:0.2529\n",
      "Epoch: loss_cls:0.4396--loss_regr:0.1099--loss:0.5495\n",
      "\n",
      "Ep:21/29--Batch:2900/3832\n",
      "batch: loss_cls:0.4305--loss_regr:0.0576--loss:0.4881\n",
      "Epoch: loss_cls:0.4404--loss_regr:0.1098--loss:0.5502\n",
      "\n",
      "Ep:21/29--Batch:3000/3832\n",
      "batch: loss_cls:0.2082--loss_regr:0.0830--loss:0.2911\n",
      "Epoch: loss_cls:0.4396--loss_regr:0.1094--loss:0.5490\n",
      "\n",
      "Ep:21/29--Batch:3100/3832\n",
      "batch: loss_cls:0.3714--loss_regr:0.1169--loss:0.4884\n",
      "Epoch: loss_cls:0.4405--loss_regr:0.1101--loss:0.5507\n",
      "\n",
      "Ep:21/29--Batch:3200/3832\n",
      "batch: loss_cls:0.3083--loss_regr:0.0911--loss:0.3994\n",
      "Epoch: loss_cls:0.4399--loss_regr:0.1100--loss:0.5499\n",
      "\n",
      "Ep:21/29--Batch:3300/3832\n",
      "batch: loss_cls:0.6308--loss_regr:0.1047--loss:0.7355\n",
      "Epoch: loss_cls:0.4398--loss_regr:0.1097--loss:0.5496\n",
      "\n",
      "Ep:21/29--Batch:3400/3832\n",
      "batch: loss_cls:0.2440--loss_regr:0.0730--loss:0.3171\n",
      "Epoch: loss_cls:0.4395--loss_regr:0.1100--loss:0.5495\n",
      "\n",
      "Ep:21/29--Batch:3500/3832\n",
      "batch: loss_cls:0.2804--loss_regr:0.0119--loss:0.2923\n",
      "Epoch: loss_cls:0.4380--loss_regr:0.1096--loss:0.5476\n",
      "\n",
      "Ep:21/29--Batch:3600/3832\n",
      "batch: loss_cls:0.2415--loss_regr:0.0496--loss:0.2911\n",
      "Epoch: loss_cls:0.4379--loss_regr:0.1097--loss:0.5476\n",
      "\n",
      "Ep:21/29--Batch:3700/3832\n",
      "batch: loss_cls:0.2515--loss_regr:0.0479--loss:0.2993\n",
      "Epoch: loss_cls:0.4382--loss_regr:0.1096--loss:0.5478\n",
      "\n",
      "Ep:21/29--Batch:3800/3832\n",
      "batch: loss_cls:0.5589--loss_regr:0.1049--loss:0.6638\n",
      "Epoch: loss_cls:0.4387--loss_regr:0.1099--loss:0.5486\n",
      "\n",
      "Epoch:21--0.4392--0.1099--0.5491\n",
      "saving to ../../checkpoints/v3_ctpn_ep21_0.4392_0.1099_0.5491.pth\n",
      "Epoch 22/30\n",
      "##################################################\n",
      "Ep:22/29--Batch:0/3832\n",
      "batch: loss_cls:0.3047--loss_regr:0.0821--loss:0.3868\n",
      "Epoch: loss_cls:0.3047--loss_regr:0.0821--loss:0.3868\n",
      "\n",
      "Ep:22/29--Batch:100/3832\n",
      "batch: loss_cls:0.6608--loss_regr:0.0933--loss:0.7541\n",
      "Epoch: loss_cls:0.4605--loss_regr:0.1056--loss:0.5660\n",
      "\n",
      "Ep:22/29--Batch:200/3832\n",
      "batch: loss_cls:0.7756--loss_regr:0.2288--loss:1.0044\n",
      "Epoch: loss_cls:0.4476--loss_regr:0.1054--loss:0.5530\n",
      "\n",
      "Ep:22/29--Batch:300/3832\n",
      "batch: loss_cls:0.5127--loss_regr:0.0631--loss:0.5758\n",
      "Epoch: loss_cls:0.4514--loss_regr:0.1075--loss:0.5589\n",
      "\n",
      "Ep:22/29--Batch:400/3832\n",
      "batch: loss_cls:0.1421--loss_regr:0.0237--loss:0.1657\n",
      "Epoch: loss_cls:0.4486--loss_regr:0.1025--loss:0.5512\n",
      "\n",
      "Ep:22/29--Batch:500/3832\n",
      "batch: loss_cls:0.2601--loss_regr:0.0313--loss:0.2914\n",
      "Epoch: loss_cls:0.4394--loss_regr:0.1012--loss:0.5405\n",
      "\n",
      "Ep:22/29--Batch:600/3832\n",
      "batch: loss_cls:0.7923--loss_regr:0.2221--loss:1.0144\n",
      "Epoch: loss_cls:0.4353--loss_regr:0.1112--loss:0.5465\n",
      "\n",
      "Ep:22/29--Batch:700/3832\n",
      "batch: loss_cls:0.5998--loss_regr:0.0702--loss:0.6700\n",
      "Epoch: loss_cls:0.4398--loss_regr:0.1108--loss:0.5506\n",
      "\n",
      "Ep:22/29--Batch:800/3832\n",
      "batch: loss_cls:0.3559--loss_regr:0.0714--loss:0.4273\n",
      "Epoch: loss_cls:0.4403--loss_regr:0.1099--loss:0.5501\n",
      "\n",
      "Ep:22/29--Batch:900/3832\n",
      "batch: loss_cls:0.4539--loss_regr:0.1146--loss:0.5685\n",
      "Epoch: loss_cls:0.4441--loss_regr:0.1065--loss:0.5506\n",
      "\n",
      "Ep:22/29--Batch:1000/3832\n",
      "batch: loss_cls:0.4082--loss_regr:0.1263--loss:0.5345\n",
      "Epoch: loss_cls:0.4393--loss_regr:0.1057--loss:0.5449\n",
      "\n",
      "Ep:22/29--Batch:1100/3832\n",
      "batch: loss_cls:0.4845--loss_regr:0.0850--loss:0.5695\n",
      "Epoch: loss_cls:0.4410--loss_regr:0.1084--loss:0.5494\n",
      "\n",
      "Ep:22/29--Batch:1200/3832\n",
      "batch: loss_cls:0.8700--loss_regr:0.1495--loss:1.0195\n",
      "Epoch: loss_cls:0.4423--loss_regr:0.1074--loss:0.5497\n",
      "\n",
      "Ep:22/29--Batch:1300/3832\n",
      "batch: loss_cls:0.2687--loss_regr:0.0964--loss:0.3651\n",
      "Epoch: loss_cls:0.4446--loss_regr:0.1077--loss:0.5522\n",
      "\n",
      "Ep:22/29--Batch:1400/3832\n",
      "batch: loss_cls:0.2336--loss_regr:0.1418--loss:0.3754\n",
      "Epoch: loss_cls:0.4421--loss_regr:0.1070--loss:0.5492\n",
      "\n",
      "Ep:22/29--Batch:1500/3832\n",
      "batch: loss_cls:0.2178--loss_regr:0.0602--loss:0.2779\n",
      "Epoch: loss_cls:0.4426--loss_regr:0.1062--loss:0.5489\n",
      "\n",
      "Ep:22/29--Batch:1600/3832\n",
      "batch: loss_cls:0.2505--loss_regr:0.0336--loss:0.2841\n",
      "Epoch: loss_cls:0.4440--loss_regr:0.1069--loss:0.5509\n",
      "\n",
      "Ep:22/29--Batch:1700/3832\n",
      "batch: loss_cls:0.6047--loss_regr:0.1270--loss:0.7317\n",
      "Epoch: loss_cls:0.4433--loss_regr:0.1076--loss:0.5509\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:22/29--Batch:1800/3832\n",
      "batch: loss_cls:0.2165--loss_regr:0.0717--loss:0.2882\n",
      "Epoch: loss_cls:0.4404--loss_regr:0.1074--loss:0.5478\n",
      "\n",
      "Ep:22/29--Batch:1900/3832\n",
      "batch: loss_cls:0.3080--loss_regr:0.2540--loss:0.5620\n",
      "Epoch: loss_cls:0.4413--loss_regr:0.1106--loss:0.5519\n",
      "\n",
      "Ep:22/29--Batch:2000/3832\n",
      "batch: loss_cls:0.3613--loss_regr:0.1077--loss:0.4689\n",
      "Epoch: loss_cls:0.4400--loss_regr:0.1107--loss:0.5507\n",
      "\n",
      "Ep:22/29--Batch:2100/3832\n",
      "batch: loss_cls:0.3160--loss_regr:0.0286--loss:0.3445\n",
      "Epoch: loss_cls:0.4413--loss_regr:0.1100--loss:0.5513\n",
      "\n",
      "Ep:22/29--Batch:2200/3832\n",
      "batch: loss_cls:0.4113--loss_regr:0.1020--loss:0.5133\n",
      "Epoch: loss_cls:0.4395--loss_regr:0.1095--loss:0.5490\n",
      "\n",
      "Ep:22/29--Batch:2300/3832\n",
      "batch: loss_cls:0.6225--loss_regr:0.1275--loss:0.7500\n",
      "Epoch: loss_cls:0.4392--loss_regr:0.1091--loss:0.5482\n",
      "\n",
      "Ep:22/29--Batch:2400/3832\n",
      "batch: loss_cls:0.6324--loss_regr:0.0406--loss:0.6730\n",
      "Epoch: loss_cls:0.4402--loss_regr:0.1099--loss:0.5500\n",
      "\n",
      "Ep:22/29--Batch:2500/3832\n",
      "batch: loss_cls:0.4129--loss_regr:0.0886--loss:0.5015\n",
      "Epoch: loss_cls:0.4381--loss_regr:0.1087--loss:0.5468\n",
      "\n",
      "Ep:22/29--Batch:2600/3832\n",
      "batch: loss_cls:0.3602--loss_regr:1.5602--loss:1.9204\n",
      "Epoch: loss_cls:0.4389--loss_regr:0.1087--loss:0.5476\n",
      "\n",
      "Ep:22/29--Batch:2700/3832\n",
      "batch: loss_cls:0.7692--loss_regr:0.1625--loss:0.9317\n",
      "Epoch: loss_cls:0.4395--loss_regr:0.1087--loss:0.5482\n",
      "\n",
      "Ep:22/29--Batch:2800/3832\n",
      "batch: loss_cls:0.2310--loss_regr:0.0477--loss:0.2787\n",
      "Epoch: loss_cls:0.4401--loss_regr:0.1095--loss:0.5496\n",
      "\n",
      "Ep:22/29--Batch:2900/3832\n",
      "batch: loss_cls:0.4344--loss_regr:0.0620--loss:0.4964\n",
      "Epoch: loss_cls:0.4408--loss_regr:0.1093--loss:0.5502\n",
      "\n",
      "Ep:22/29--Batch:3000/3832\n",
      "batch: loss_cls:0.2053--loss_regr:0.0882--loss:0.2935\n",
      "Epoch: loss_cls:0.4397--loss_regr:0.1090--loss:0.5488\n",
      "\n",
      "Ep:22/29--Batch:3100/3832\n",
      "batch: loss_cls:0.3786--loss_regr:0.1070--loss:0.4856\n",
      "Epoch: loss_cls:0.4407--loss_regr:0.1098--loss:0.5505\n",
      "\n",
      "Ep:22/29--Batch:3200/3832\n",
      "batch: loss_cls:0.3019--loss_regr:0.0829--loss:0.3848\n",
      "Epoch: loss_cls:0.4403--loss_regr:0.1096--loss:0.5499\n",
      "\n",
      "Ep:22/29--Batch:3300/3832\n",
      "batch: loss_cls:0.6442--loss_regr:0.1204--loss:0.7647\n",
      "Epoch: loss_cls:0.4405--loss_regr:0.1094--loss:0.5499\n",
      "\n",
      "Ep:22/29--Batch:3400/3832\n",
      "batch: loss_cls:0.2415--loss_regr:0.0702--loss:0.3116\n",
      "Epoch: loss_cls:0.4400--loss_regr:0.1096--loss:0.5495\n",
      "\n",
      "Ep:22/29--Batch:3500/3832\n",
      "batch: loss_cls:0.2693--loss_regr:0.0124--loss:0.2818\n",
      "Epoch: loss_cls:0.4387--loss_regr:0.1092--loss:0.5479\n",
      "\n",
      "Ep:22/29--Batch:3600/3832\n",
      "batch: loss_cls:0.2388--loss_regr:0.0489--loss:0.2877\n",
      "Epoch: loss_cls:0.4390--loss_regr:0.1094--loss:0.5483\n",
      "\n",
      "Ep:22/29--Batch:3700/3832\n",
      "batch: loss_cls:0.2451--loss_regr:0.0547--loss:0.2999\n",
      "Epoch: loss_cls:0.4388--loss_regr:0.1093--loss:0.5481\n",
      "\n",
      "Ep:22/29--Batch:3800/3832\n",
      "batch: loss_cls:0.5775--loss_regr:0.1122--loss:0.6897\n",
      "Epoch: loss_cls:0.4392--loss_regr:0.1097--loss:0.5489\n",
      "\n",
      "Epoch:22--0.4395--0.1096--0.5491\n",
      "saving to ../../checkpoints/v3_ctpn_ep22_0.4395_0.1096_0.5491.pth\n",
      "Epoch 23/30\n",
      "##################################################\n",
      "Ep:23/29--Batch:0/3832\n",
      "batch: loss_cls:0.3122--loss_regr:0.0802--loss:0.3924\n",
      "Epoch: loss_cls:0.3122--loss_regr:0.0802--loss:0.3924\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e4cd16df1b38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregrs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# print(imgs.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/envs/dl/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/envs/dl/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/remote-home/my/final/Code/OCR-code(CTPN+CRNN+CTC Loss)-baidu/train_code/train_ctpn/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mgtbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnewx2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_anchors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcal_rpn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgtbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0;31m# debug_img = self.draw_boxes(img.copy(),cls,base_anchors,gtbox)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;31m# cv2.imwrite('debug/{}'.format(img_name),debug_img)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/remote-home/my/final/Code/OCR-code(CTPN+CRNN+CTC Loss)-baidu/train_code/train_ctpn/ctpn_utils.py\u001b[0m in \u001b[0;36mcal_rpn\u001b[0;34m(imgsize, featuresize, scale, gtboxes)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;31m# calculate iou\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m     \u001b[0moverlaps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcal_overlaps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_anchor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgtboxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;31m# init labels -1 don't care  0 is negative  1 is positive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/remote-home/my/final/Code/OCR-code(CTPN+CRNN+CTC Loss)-baidu/train_code/train_ctpn/ctpn_utils.py\u001b[0m in \u001b[0;36mcal_overlaps\u001b[0;34m(boxes1, boxes2)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;31m# calculate the intersection of  boxes1(anchor) and boxes2(GT box)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0moverlaps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcal_iou\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marea1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboxes2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marea2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moverlaps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/remote-home/my/final/Code/OCR-code(CTPN+CRNN+CTC Loss)-baidu/train_code/train_ctpn/ctpn_utils.py\u001b[0m in \u001b[0;36mcal_iou\u001b[0;34m(box1, box1_area, boxes2, boxes2_area)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0mintersection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0miou\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mintersection\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbox1_area\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mboxes2_area\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mintersection\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0miou\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if os.path.exists(checkpoints_weight):\n",
    "    print('using pretrained weight: {}'.format(checkpoints_weight))\n",
    "    cc = torch.load(checkpoints_weight, map_location=device)\n",
    "    model.load_state_dict(cc['model_state_dict'])\n",
    "    resume_epoch = cc['epoch']\n",
    "else:\n",
    "    model.apply(weights_init)\n",
    "\n",
    "params_to_uodate = model.parameters()\n",
    "optimizer = optim.SGD(params_to_uodate, lr=lr, momentum=0.9)\n",
    "\n",
    "critetion_cls = RPN_CLS_Loss(device)\n",
    "critetion_regr = RPN_REGR_Loss(device)\n",
    "\n",
    "best_loss_cls = 100\n",
    "best_loss_regr = 100\n",
    "best_loss = 100\n",
    "best_model = None\n",
    "epochs += resume_epoch\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "for epoch in range(resume_epoch+1, epochs):\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f'Epoch {epoch}/{epochs}')\n",
    "    print('#'*50)\n",
    "    epoch_size = len(dataset) // 1\n",
    "    model.train()\n",
    "    epoch_loss_cls = 0\n",
    "    epoch_loss_regr = 0\n",
    "    epoch_loss = 0\n",
    "    scheduler.step(epoch)\n",
    "\n",
    "    for batch_i, (imgs, clss, regrs) in enumerate(dataloader):\n",
    "        torch.cuda.empty_cache()\n",
    "        # print(imgs.shape)\n",
    "        imgs = imgs.to(device)\n",
    "        clss = clss.to(device)\n",
    "        regrs = regrs.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        out_cls, out_regr = model(imgs)\n",
    "        loss_cls = critetion_cls(out_cls, clss)\n",
    "        loss_regr = critetion_regr(out_regr, regrs)\n",
    "\n",
    "        loss = loss_cls + loss_regr  # total loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss_cls += loss_cls.item()\n",
    "        epoch_loss_regr += loss_regr.item()\n",
    "        epoch_loss += loss.item()\n",
    "        mmp = batch_i+1\n",
    "        \n",
    "        if batch_i%100 == 0:\n",
    "            print(f'Ep:{epoch}/{epochs-1}--'\n",
    "              f'Batch:{batch_i}/{epoch_size}\\n'\n",
    "              f'batch: loss_cls:{loss_cls.item():.4f}--loss_regr:{loss_regr.item():.4f}--loss:{loss.item():.4f}\\n'\n",
    "              f'Epoch: loss_cls:{epoch_loss_cls/mmp:.4f}--loss_regr:{epoch_loss_regr/mmp:.4f}--'\n",
    "              f'loss:{epoch_loss/mmp:.4f}\\n')\n",
    "\n",
    "    epoch_loss_cls /= epoch_size\n",
    "    epoch_loss_regr /= epoch_size\n",
    "    epoch_loss /= epoch_size\n",
    "    print(f'Epoch:{epoch}--{epoch_loss_cls:.4f}--{epoch_loss_regr:.4f}--{epoch_loss:.4f}')\n",
    "    if best_loss_cls > epoch_loss_cls or best_loss_regr > epoch_loss_regr or best_loss > epoch_loss:\n",
    "        best_loss = epoch_loss\n",
    "        best_loss_regr = epoch_loss_regr\n",
    "        best_loss_cls = epoch_loss_cls\n",
    "        best_model = model\n",
    "        save_checkpoint({'model_state_dict': best_model.state_dict(),\n",
    "                         'epoch': epoch},\n",
    "                        epoch,\n",
    "                        best_loss_cls,\n",
    "                        best_loss_regr,\n",
    "                        best_loss)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2913, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!fuser -v /dev/nvidia*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
